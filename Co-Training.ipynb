{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "lined-joyce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "still-scholar",
   "metadata": {},
   "source": [
    "## Load Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "democratic-direction",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "current-confidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"tfidf.pk\", 'rb') as fin:\n",
    "    tfidf = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "celtic-finish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(max_df=5, ngram_range=(1, 3), stop_words='english')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adult-precipitation",
   "metadata": {},
   "source": [
    "### Word2Vec CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "pursuant-production",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbow = Word2Vec.load(\"cbow.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bronze-ordinance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x1be39380f70>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norman-pleasure",
   "metadata": {},
   "source": [
    "### Word2Vec SkipGram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "crazy-smith",
   "metadata": {},
   "outputs": [],
   "source": [
    "skg = Word2Vec.load(\"skg.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "presidential-rebound",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x1be3ba4b5e0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "existing-ebony",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "knowing-phone",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"processed_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dedicated-browser",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>subtask_b</th>\n",
       "      <th>subtask_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>86426</td>\n",
       "      <td>['ask', 'native', 'american', 'take']</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>90194</td>\n",
       "      <td>['go', 'home', '‚Äô', 'drunk', 'maga', 'trump', ...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>16820</td>\n",
       "      <td>['amazon', 'investigating', 'chinese', 'employ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>62688</td>\n",
       "      <td>['someone', 'shouldve', 'taken', 'piece', 'shi...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>43605</td>\n",
       "      <td>['obama', 'wanted', 'liberal', 'amp', 'illegal...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13235</th>\n",
       "      <td>13235</td>\n",
       "      <td>95338</td>\n",
       "      <td>['sometimes', 'get', 'strong', 'vibe', 'people...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13236</th>\n",
       "      <td>13236</td>\n",
       "      <td>67210</td>\n",
       "      <td>['benidorm', '‚úÖ', 'creamfields', '‚úÖ', 'maga', ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13237</th>\n",
       "      <td>13237</td>\n",
       "      <td>82921</td>\n",
       "      <td>['report', 'garbage', 'dont', 'give', 'crap']</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>OTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13238</th>\n",
       "      <td>13238</td>\n",
       "      <td>27429</td>\n",
       "      <td>['pussy']</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13239</th>\n",
       "      <td>13239</td>\n",
       "      <td>46552</td>\n",
       "      <td>['spanishrevenge', 'v', 'justice', 'human', 'r...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13240 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0     id                                              tweet  \\\n",
       "0               0  86426              ['ask', 'native', 'american', 'take']   \n",
       "1               1  90194  ['go', 'home', '‚Äô', 'drunk', 'maga', 'trump', ...   \n",
       "2               2  16820  ['amazon', 'investigating', 'chinese', 'employ...   \n",
       "3               3  62688  ['someone', 'shouldve', 'taken', 'piece', 'shi...   \n",
       "4               4  43605  ['obama', 'wanted', 'liberal', 'amp', 'illegal...   \n",
       "...           ...    ...                                                ...   \n",
       "13235       13235  95338  ['sometimes', 'get', 'strong', 'vibe', 'people...   \n",
       "13236       13236  67210  ['benidorm', '‚úÖ', 'creamfields', '‚úÖ', 'maga', ...   \n",
       "13237       13237  82921      ['report', 'garbage', 'dont', 'give', 'crap']   \n",
       "13238       13238  27429                                          ['pussy']   \n",
       "13239       13239  46552  ['spanishrevenge', 'v', 'justice', 'human', 'r...   \n",
       "\n",
       "      subtask_a subtask_b subtask_c  \n",
       "0           OFF       UNT       NaN  \n",
       "1           OFF       TIN       IND  \n",
       "2           NOT       NaN       NaN  \n",
       "3           OFF       UNT       NaN  \n",
       "4           NOT       NaN       NaN  \n",
       "...         ...       ...       ...  \n",
       "13235       OFF       TIN       IND  \n",
       "13236       NOT       NaN       NaN  \n",
       "13237       OFF       TIN       OTH  \n",
       "13238       OFF       UNT       NaN  \n",
       "13239       NOT       NaN       NaN  \n",
       "\n",
       "[13240 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "universal-tobago",
   "metadata": {},
   "source": [
    "### Removing Redundant Axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "later-gabriel",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Unnamed: 0', 'subtask_b', 'subtask_c', 'id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "present-craft",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['ask', 'native', 'american', 'take']</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['go', 'home', '‚Äô', 'drunk', 'maga', 'trump', ...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['amazon', 'investigating', 'chinese', 'employ...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['someone', 'shouldve', 'taken', 'piece', 'shi...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['obama', 'wanted', 'liberal', 'amp', 'illegal...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13235</th>\n",
       "      <td>['sometimes', 'get', 'strong', 'vibe', 'people...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13236</th>\n",
       "      <td>['benidorm', '‚úÖ', 'creamfields', '‚úÖ', 'maga', ...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13237</th>\n",
       "      <td>['report', 'garbage', 'dont', 'give', 'crap']</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13238</th>\n",
       "      <td>['pussy']</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13239</th>\n",
       "      <td>['spanishrevenge', 'v', 'justice', 'human', 'r...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13240 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet subtask_a\n",
       "0                  ['ask', 'native', 'american', 'take']       OFF\n",
       "1      ['go', 'home', '‚Äô', 'drunk', 'maga', 'trump', ...       OFF\n",
       "2      ['amazon', 'investigating', 'chinese', 'employ...       NOT\n",
       "3      ['someone', 'shouldve', 'taken', 'piece', 'shi...       OFF\n",
       "4      ['obama', 'wanted', 'liberal', 'amp', 'illegal...       NOT\n",
       "...                                                  ...       ...\n",
       "13235  ['sometimes', 'get', 'strong', 'vibe', 'people...       OFF\n",
       "13236  ['benidorm', '‚úÖ', 'creamfields', '‚úÖ', 'maga', ...       NOT\n",
       "13237      ['report', 'garbage', 'dont', 'give', 'crap']       OFF\n",
       "13238                                          ['pussy']       OFF\n",
       "13239  ['spanishrevenge', 'v', 'justice', 'human', 'r...       NOT\n",
       "\n",
       "[13240 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bronze-ebony",
   "metadata": {},
   "source": [
    "### Renaming Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "expected-anthropology",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'subtask_a': 'Offensive'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "catholic-payment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>Offensive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['ask', 'native', 'american', 'take']</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['go', 'home', '‚Äô', 'drunk', 'maga', 'trump', ...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['amazon', 'investigating', 'chinese', 'employ...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['someone', 'shouldve', 'taken', 'piece', 'shi...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['obama', 'wanted', 'liberal', 'amp', 'illegal...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13235</th>\n",
       "      <td>['sometimes', 'get', 'strong', 'vibe', 'people...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13236</th>\n",
       "      <td>['benidorm', '‚úÖ', 'creamfields', '‚úÖ', 'maga', ...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13237</th>\n",
       "      <td>['report', 'garbage', 'dont', 'give', 'crap']</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13238</th>\n",
       "      <td>['pussy']</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13239</th>\n",
       "      <td>['spanishrevenge', 'v', 'justice', 'human', 'r...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13240 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet Offensive\n",
       "0                  ['ask', 'native', 'american', 'take']       OFF\n",
       "1      ['go', 'home', '‚Äô', 'drunk', 'maga', 'trump', ...       OFF\n",
       "2      ['amazon', 'investigating', 'chinese', 'employ...       NOT\n",
       "3      ['someone', 'shouldve', 'taken', 'piece', 'shi...       OFF\n",
       "4      ['obama', 'wanted', 'liberal', 'amp', 'illegal...       NOT\n",
       "...                                                  ...       ...\n",
       "13235  ['sometimes', 'get', 'strong', 'vibe', 'people...       OFF\n",
       "13236  ['benidorm', '‚úÖ', 'creamfields', '‚úÖ', 'maga', ...       NOT\n",
       "13237      ['report', 'garbage', 'dont', 'give', 'crap']       OFF\n",
       "13238                                          ['pussy']       OFF\n",
       "13239  ['spanishrevenge', 'v', 'justice', 'human', 'r...       NOT\n",
       "\n",
       "[13240 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statutory-vacation",
   "metadata": {},
   "source": [
    "### Converting Offensive to Numerical Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "proper-jordan",
   "metadata": {},
   "outputs": [],
   "source": [
    "def off(cls):\n",
    "    if cls =='OFF':\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "egyptian-length",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Offensive\"] = df[\"Offensive\"].apply(off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "noted-reducing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>Offensive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['ask', 'native', 'american', 'take']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['go', 'home', '‚Äô', 'drunk', 'maga', 'trump', ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['amazon', 'investigating', 'chinese', 'employ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['someone', 'shouldve', 'taken', 'piece', 'shi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['obama', 'wanted', 'liberal', 'amp', 'illegal...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13235</th>\n",
       "      <td>['sometimes', 'get', 'strong', 'vibe', 'people...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13236</th>\n",
       "      <td>['benidorm', '‚úÖ', 'creamfields', '‚úÖ', 'maga', ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13237</th>\n",
       "      <td>['report', 'garbage', 'dont', 'give', 'crap']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13238</th>\n",
       "      <td>['pussy']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13239</th>\n",
       "      <td>['spanishrevenge', 'v', 'justice', 'human', 'r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13240 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet  Offensive\n",
       "0                  ['ask', 'native', 'american', 'take']          1\n",
       "1      ['go', 'home', '‚Äô', 'drunk', 'maga', 'trump', ...          1\n",
       "2      ['amazon', 'investigating', 'chinese', 'employ...          0\n",
       "3      ['someone', 'shouldve', 'taken', 'piece', 'shi...          1\n",
       "4      ['obama', 'wanted', 'liberal', 'amp', 'illegal...          0\n",
       "...                                                  ...        ...\n",
       "13235  ['sometimes', 'get', 'strong', 'vibe', 'people...          1\n",
       "13236  ['benidorm', '‚úÖ', 'creamfields', '‚úÖ', 'maga', ...          0\n",
       "13237      ['report', 'garbage', 'dont', 'give', 'crap']          1\n",
       "13238                                          ['pussy']          1\n",
       "13239  ['spanishrevenge', 'v', 'justice', 'human', 'r...          0\n",
       "\n",
       "[13240 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "respected-disposition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    ['ask', 'native', 'american', 'take']\n",
       "1        ['go', 'home', '‚Äô', 'drunk', 'maga', 'trump', ...\n",
       "2        ['amazon', 'investigating', 'chinese', 'employ...\n",
       "3        ['someone', 'shouldve', 'taken', 'piece', 'shi...\n",
       "4        ['obama', 'wanted', 'liberal', 'amp', 'illegal...\n",
       "                               ...                        \n",
       "13235    ['sometimes', 'get', 'strong', 'vibe', 'people...\n",
       "13236    ['benidorm', '‚úÖ', 'creamfields', '‚úÖ', 'maga', ...\n",
       "13237        ['report', 'garbage', 'dont', 'give', 'crap']\n",
       "13238                                            ['pussy']\n",
       "13239    ['spanishrevenge', 'v', 'justice', 'human', 'r...\n",
       "Name: tweet, Length: 13240, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secure-nicaragua",
   "metadata": {},
   "source": [
    "## Fitting Word Models on Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "steady-rebecca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['tweet'], df['Offensive'], stratify=df['Offensive'], random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "miniature-guest",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "relevant-health",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tf = tfidf.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aggressive-complex",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tf = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polyphonic-flash",
   "metadata": {},
   "source": [
    "### Sentence Vectoriser\n",
    "\n",
    "Finding the average vector for a given document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "lasting-night",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_vect(sent, model):\n",
    "    vec = np.zeros(400)\n",
    "    num = 0\n",
    "    for w in sent:\n",
    "        temp_vec = model.wv.get_vector(w)\n",
    "        #print(temp_vec)\n",
    "        vec = np.add(vec, temp_vec)\n",
    "        num += 1\n",
    "        \n",
    "    return vec / np.sqrt(vec.dot(vec))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beginning-madagascar",
   "metadata": {},
   "source": [
    "### CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "boring-wheat",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"word '[' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-af2bb0b6c043>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train_cbow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msent_vect\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcbow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   4136\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4137\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4138\u001b[1;33m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4140\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mf\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   4121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4122\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4123\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4125\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-27-77a847e99481>\u001b[0m in \u001b[0;36msent_vect\u001b[1;34m(sent, model)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mnum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mtemp_vec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[1;31m#print(temp_vec)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mvec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp_vec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[1;34m(self, word)\u001b[0m\n\u001b[0;32m    469\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 471\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    472\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwords_closer_than\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[1;34m(self, word, use_norm)\u001b[0m\n\u001b[0;32m    466\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 468\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    469\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"word '[' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "X_train_cbow = X_train.apply(sent_vect, model=cbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "textile-payroll",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3759     [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...\n",
       "1623     [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...\n",
       "8650     [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...\n",
       "7897     [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...\n",
       "365      [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...\n",
       "                               ...                        \n",
       "11365    [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...\n",
       "8409     [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...\n",
       "7883     [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...\n",
       "10443    [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...\n",
       "10972    [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...\n",
       "Name: tweet, Length: 9930, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "sound-sport",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3759             ['friend', 'father', 'safe', 'talk', '‚Äù']\n",
       "1623                                   ['president', 'im']\n",
       "8650     ['depending', 'government', 'politician', 'fur...\n",
       "7897     ['im', 'sure', 'really', 'low', 'carb', 'diet'...\n",
       "365                   ['welcome', 'why', 'james', 'cryin']\n",
       "                               ...                        \n",
       "11365    ['nra', 'supported', 'gun', 'control', 'reagan...\n",
       "8409     ['quite', 'good', 'faking', 'must', 'done', 'n...\n",
       "7883                                             ['thank']\n",
       "10443    ['abundantly', 'clear', 'lack', 'common', 'sen...\n",
       "10972                 ['there', 'brexit', 'üëá', 'üèª', 'url']\n",
       "Name: tweet, Length: 9930, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "removed-salon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df[\"tweet\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "typical-helen",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-ef0a14eb220b>:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return vec / np.sqrt(vec.dot(vec))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_vect(df[\"tweet\"][0], cbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "steady-patrol",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
