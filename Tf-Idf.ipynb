{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "indonesian-bhutan",
   "metadata": {},
   "source": [
    "# Tf-Idf Model\n",
    "\n",
    "\n",
    "\n",
    "Calculates the term frequency or the number of occurences of a word in a document, and the idf of a word which is the Log(Number of Documents/Number of documents the word appears in. On multiplying the two, one gets Tf-Idf. Tf-Idf is similar to how relevant a word is to a documents class as it calculates the number of times in occurs in a particular document and the number of documents it occurs in as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "plastic-breeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, learning_curve\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tribal-container",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dutch-minority",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"processed_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "conventional-deviation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>subtask_b</th>\n",
       "      <th>subtask_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>86426</td>\n",
       "      <td>['ask', 'native', 'american', 'take']</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>90194</td>\n",
       "      <td>['go', 'home', '’', 'drunk', 'maga', 'trump', ...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>16820</td>\n",
       "      <td>['amazon', 'investigating', 'chinese', 'employ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>62688</td>\n",
       "      <td>['someone', 'shouldve', 'taken', 'piece', 'shi...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>43605</td>\n",
       "      <td>['obama', 'wanted', 'liberal', 'amp', 'illegal...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13235</th>\n",
       "      <td>13235</td>\n",
       "      <td>95338</td>\n",
       "      <td>['sometimes', 'get', 'strong', 'vibe', 'people...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13236</th>\n",
       "      <td>13236</td>\n",
       "      <td>67210</td>\n",
       "      <td>['benidorm', '✅', 'creamfields', '✅', 'maga', ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13237</th>\n",
       "      <td>13237</td>\n",
       "      <td>82921</td>\n",
       "      <td>['report', 'garbage', 'dont', 'give', 'crap']</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>OTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13238</th>\n",
       "      <td>13238</td>\n",
       "      <td>27429</td>\n",
       "      <td>['pussy']</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13239</th>\n",
       "      <td>13239</td>\n",
       "      <td>46552</td>\n",
       "      <td>['spanishrevenge', 'v', 'justice', 'human', 'r...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13240 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0     id                                              tweet  \\\n",
       "0               0  86426              ['ask', 'native', 'american', 'take']   \n",
       "1               1  90194  ['go', 'home', '’', 'drunk', 'maga', 'trump', ...   \n",
       "2               2  16820  ['amazon', 'investigating', 'chinese', 'employ...   \n",
       "3               3  62688  ['someone', 'shouldve', 'taken', 'piece', 'shi...   \n",
       "4               4  43605  ['obama', 'wanted', 'liberal', 'amp', 'illegal...   \n",
       "...           ...    ...                                                ...   \n",
       "13235       13235  95338  ['sometimes', 'get', 'strong', 'vibe', 'people...   \n",
       "13236       13236  67210  ['benidorm', '✅', 'creamfields', '✅', 'maga', ...   \n",
       "13237       13237  82921      ['report', 'garbage', 'dont', 'give', 'crap']   \n",
       "13238       13238  27429                                          ['pussy']   \n",
       "13239       13239  46552  ['spanishrevenge', 'v', 'justice', 'human', 'r...   \n",
       "\n",
       "      subtask_a subtask_b subtask_c  \n",
       "0           OFF       UNT       NaN  \n",
       "1           OFF       TIN       IND  \n",
       "2           NOT       NaN       NaN  \n",
       "3           OFF       UNT       NaN  \n",
       "4           NOT       NaN       NaN  \n",
       "...         ...       ...       ...  \n",
       "13235       OFF       TIN       IND  \n",
       "13236       NOT       NaN       NaN  \n",
       "13237       OFF       TIN       OTH  \n",
       "13238       OFF       UNT       NaN  \n",
       "13239       NOT       NaN       NaN  \n",
       "\n",
       "[13240 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hearing-mainland",
   "metadata": {},
   "source": [
    "## Removing Redundant Axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "contained-emergency",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Unnamed: 0', 'subtask_b', 'subtask_c', 'id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "stone-quilt",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['ask', 'native', 'american', 'take']</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['go', 'home', '’', 'drunk', 'maga', 'trump', ...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['amazon', 'investigating', 'chinese', 'employ...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['someone', 'shouldve', 'taken', 'piece', 'shi...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['obama', 'wanted', 'liberal', 'amp', 'illegal...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13235</th>\n",
       "      <td>['sometimes', 'get', 'strong', 'vibe', 'people...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13236</th>\n",
       "      <td>['benidorm', '✅', 'creamfields', '✅', 'maga', ...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13237</th>\n",
       "      <td>['report', 'garbage', 'dont', 'give', 'crap']</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13238</th>\n",
       "      <td>['pussy']</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13239</th>\n",
       "      <td>['spanishrevenge', 'v', 'justice', 'human', 'r...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13240 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet subtask_a\n",
       "0                  ['ask', 'native', 'american', 'take']       OFF\n",
       "1      ['go', 'home', '’', 'drunk', 'maga', 'trump', ...       OFF\n",
       "2      ['amazon', 'investigating', 'chinese', 'employ...       NOT\n",
       "3      ['someone', 'shouldve', 'taken', 'piece', 'shi...       OFF\n",
       "4      ['obama', 'wanted', 'liberal', 'amp', 'illegal...       NOT\n",
       "...                                                  ...       ...\n",
       "13235  ['sometimes', 'get', 'strong', 'vibe', 'people...       OFF\n",
       "13236  ['benidorm', '✅', 'creamfields', '✅', 'maga', ...       NOT\n",
       "13237      ['report', 'garbage', 'dont', 'give', 'crap']       OFF\n",
       "13238                                          ['pussy']       OFF\n",
       "13239  ['spanishrevenge', 'v', 'justice', 'human', 'r...       NOT\n",
       "\n",
       "[13240 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contained-essence",
   "metadata": {},
   "source": [
    "## Renaming Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "higher-absorption",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'subtask_a': 'Offensive'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "future-annex",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>Offensive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['ask', 'native', 'american', 'take']</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['go', 'home', '’', 'drunk', 'maga', 'trump', ...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['amazon', 'investigating', 'chinese', 'employ...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['someone', 'shouldve', 'taken', 'piece', 'shi...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['obama', 'wanted', 'liberal', 'amp', 'illegal...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13235</th>\n",
       "      <td>['sometimes', 'get', 'strong', 'vibe', 'people...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13236</th>\n",
       "      <td>['benidorm', '✅', 'creamfields', '✅', 'maga', ...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13237</th>\n",
       "      <td>['report', 'garbage', 'dont', 'give', 'crap']</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13238</th>\n",
       "      <td>['pussy']</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13239</th>\n",
       "      <td>['spanishrevenge', 'v', 'justice', 'human', 'r...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13240 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet Offensive\n",
       "0                  ['ask', 'native', 'american', 'take']       OFF\n",
       "1      ['go', 'home', '’', 'drunk', 'maga', 'trump', ...       OFF\n",
       "2      ['amazon', 'investigating', 'chinese', 'employ...       NOT\n",
       "3      ['someone', 'shouldve', 'taken', 'piece', 'shi...       OFF\n",
       "4      ['obama', 'wanted', 'liberal', 'amp', 'illegal...       NOT\n",
       "...                                                  ...       ...\n",
       "13235  ['sometimes', 'get', 'strong', 'vibe', 'people...       OFF\n",
       "13236  ['benidorm', '✅', 'creamfields', '✅', 'maga', ...       NOT\n",
       "13237      ['report', 'garbage', 'dont', 'give', 'crap']       OFF\n",
       "13238                                          ['pussy']       OFF\n",
       "13239  ['spanishrevenge', 'v', 'justice', 'human', 'r...       NOT\n",
       "\n",
       "[13240 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrow-objective",
   "metadata": {},
   "source": [
    "## Converting Offensive to Numerical Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "proof-newport",
   "metadata": {},
   "outputs": [],
   "source": [
    "def off(cls):\n",
    "    if cls =='OFF':\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "promising-product",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Offensive'] = df['Offensive'].apply(off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "designed-reason",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>Offensive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['ask', 'native', 'american', 'take']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['go', 'home', '’', 'drunk', 'maga', 'trump', ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['amazon', 'investigating', 'chinese', 'employ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['someone', 'shouldve', 'taken', 'piece', 'shi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['obama', 'wanted', 'liberal', 'amp', 'illegal...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13235</th>\n",
       "      <td>['sometimes', 'get', 'strong', 'vibe', 'people...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13236</th>\n",
       "      <td>['benidorm', '✅', 'creamfields', '✅', 'maga', ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13237</th>\n",
       "      <td>['report', 'garbage', 'dont', 'give', 'crap']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13238</th>\n",
       "      <td>['pussy']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13239</th>\n",
       "      <td>['spanishrevenge', 'v', 'justice', 'human', 'r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13240 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet  Offensive\n",
       "0                  ['ask', 'native', 'american', 'take']          1\n",
       "1      ['go', 'home', '’', 'drunk', 'maga', 'trump', ...          1\n",
       "2      ['amazon', 'investigating', 'chinese', 'employ...          0\n",
       "3      ['someone', 'shouldve', 'taken', 'piece', 'shi...          1\n",
       "4      ['obama', 'wanted', 'liberal', 'amp', 'illegal...          0\n",
       "...                                                  ...        ...\n",
       "13235  ['sometimes', 'get', 'strong', 'vibe', 'people...          1\n",
       "13236  ['benidorm', '✅', 'creamfields', '✅', 'maga', ...          0\n",
       "13237      ['report', 'garbage', 'dont', 'give', 'crap']          1\n",
       "13238                                          ['pussy']          1\n",
       "13239  ['spanishrevenge', 'v', 'justice', 'human', 'r...          0\n",
       "\n",
       "[13240 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "billion-nutrition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    ['ask', 'native', 'american', 'take']\n",
       "1        ['go', 'home', '’', 'drunk', 'maga', 'trump', ...\n",
       "2        ['amazon', 'investigating', 'chinese', 'employ...\n",
       "3        ['someone', 'shouldve', 'taken', 'piece', 'shi...\n",
       "4        ['obama', 'wanted', 'liberal', 'amp', 'illegal...\n",
       "                               ...                        \n",
       "13235    ['sometimes', 'get', 'strong', 'vibe', 'people...\n",
       "13236    ['benidorm', '✅', 'creamfields', '✅', 'maga', ...\n",
       "13237        ['report', 'garbage', 'dont', 'give', 'crap']\n",
       "13238                                            ['pussy']\n",
       "13239    ['spanishrevenge', 'v', 'justice', 'human', 'r...\n",
       "Name: tweet, Length: 13240, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satellite-nowhere",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "afraid-jewelry",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['tweet'], df['Offensive'], stratify=df['Offensive'], shuffle=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "demonstrated-administration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3532     ['bro', 'twinsie', 'resemblance', 'brother', '...\n",
       "440      ['believe', 'correct', 'chico', 'wise', 'chihu...\n",
       "11656    ['agree', 'amp', 'please', 'go', 'work', 'that...\n",
       "3905     ['doubt', 'greatest', 'female', 'athlete', 'so...\n",
       "6843     ['sure', 'lot', 'folk', 'arent', 'actually', '...\n",
       "                               ...                        \n",
       "7947     ['outrage', 'something', 'credible', 'instead'...\n",
       "8099     ['name', 'one', 'democratic', 'leader', 'endor...\n",
       "2387                              ['lmfaoo', '😭', 'bitch']\n",
       "1675     ['’', 'remember', 'clothes', 'clothes', 'house...\n",
       "10394    ['thank', 'america', 'respected', 'maga', 'kag...\n",
       "Name: tweet, Length: 9930, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "normal-microwave",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3532     0\n",
       "440      0\n",
       "11656    0\n",
       "3905     1\n",
       "6843     0\n",
       "        ..\n",
       "7947     1\n",
       "8099     0\n",
       "2387     1\n",
       "1675     1\n",
       "10394    0\n",
       "Name: Offensive, Length: 9930, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entertaining-treasury",
   "metadata": {},
   "source": [
    "## Tf-Idf Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "prime-forum",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(analyzer='word', stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "congressional-modification",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vect = vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "coastal-stomach",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<9930x14445 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 89415 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "rapid-formation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aa',\n",
       " 'aaa',\n",
       " 'aaah',\n",
       " 'aaahh',\n",
       " 'aalayah',\n",
       " 'aand',\n",
       " 'aaron',\n",
       " 'aasertions',\n",
       " 'ab',\n",
       " 'ababzhah',\n",
       " 'aback',\n",
       " 'abandon',\n",
       " 'abbott',\n",
       " 'abc',\n",
       " 'abcnews',\n",
       " 'abducted',\n",
       " 'abetterway',\n",
       " 'abhorrent',\n",
       " 'abhorres',\n",
       " 'abide',\n",
       " 'abiding',\n",
       " 'ability',\n",
       " 'abject',\n",
       " 'able',\n",
       " 'ableg',\n",
       " 'abnormal',\n",
       " 'aboard',\n",
       " 'abolish',\n",
       " 'abolition',\n",
       " 'abominable',\n",
       " 'abomination',\n",
       " 'aborting',\n",
       " 'abortion',\n",
       " 'abortionbecause',\n",
       " 'abortionnot',\n",
       " 'abortive',\n",
       " 'abound',\n",
       " 'abroad',\n",
       " 'absentee',\n",
       " 'abso',\n",
       " 'absofuckinglutely',\n",
       " 'absolute',\n",
       " 'absolutecriminals',\n",
       " 'absolutely',\n",
       " 'absolutist',\n",
       " 'absurd',\n",
       " 'abt',\n",
       " 'abundance',\n",
       " 'abundantly',\n",
       " 'abuse',\n",
       " 'abused',\n",
       " 'abuser',\n",
       " 'abusing',\n",
       " 'abusive',\n",
       " 'abusuve',\n",
       " 'abysmal',\n",
       " 'ac',\n",
       " 'aca',\n",
       " 'academic',\n",
       " 'academy',\n",
       " 'acc',\n",
       " 'accent',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'acceptance',\n",
       " 'accepted',\n",
       " 'accepting',\n",
       " 'accepts',\n",
       " 'access',\n",
       " 'accessory',\n",
       " 'accident',\n",
       " 'accidental',\n",
       " 'accidentally',\n",
       " 'accommodate',\n",
       " 'accommodating',\n",
       " 'accomplish',\n",
       " 'accomplished',\n",
       " 'accomplishment',\n",
       " 'accord',\n",
       " 'according',\n",
       " 'accordingly',\n",
       " 'accordinglyyou',\n",
       " 'account',\n",
       " 'accountability',\n",
       " 'accountable',\n",
       " 'acct',\n",
       " 'accts',\n",
       " 'accuracy',\n",
       " 'accurate',\n",
       " 'accurately',\n",
       " 'accusation',\n",
       " 'accuse',\n",
       " 'accused',\n",
       " 'accuser',\n",
       " 'accusersever',\n",
       " 'accuses',\n",
       " 'accusing',\n",
       " 'ace',\n",
       " 'acedemia',\n",
       " 'achance',\n",
       " 'ache',\n",
       " 'achieve',\n",
       " 'achievement',\n",
       " 'achieving',\n",
       " 'achtung',\n",
       " 'ack',\n",
       " 'acknowledge',\n",
       " 'acknowledged',\n",
       " 'aclu',\n",
       " 'acorn',\n",
       " 'acosta',\n",
       " 'acowboy',\n",
       " 'acquainted',\n",
       " 'acquiring',\n",
       " 'acrimony',\n",
       " 'acrookedlettercrookedletter',\n",
       " 'act',\n",
       " 'acta',\n",
       " 'actaca',\n",
       " 'acted',\n",
       " 'acting',\n",
       " 'action',\n",
       " 'activates',\n",
       " 'active',\n",
       " 'actively',\n",
       " 'activism',\n",
       " 'activist',\n",
       " 'activity',\n",
       " 'actor',\n",
       " 'actress',\n",
       " 'actressbut',\n",
       " 'actual',\n",
       " 'actuality',\n",
       " 'actually',\n",
       " 'actualy',\n",
       " 'actully',\n",
       " 'acussed',\n",
       " 'ad',\n",
       " 'adam',\n",
       " 'adamand',\n",
       " 'add',\n",
       " 'added',\n",
       " 'addict',\n",
       " 'addicted',\n",
       " 'addiction',\n",
       " 'addictssites',\n",
       " 'adding',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'address',\n",
       " 'addressed',\n",
       " 'addressing',\n",
       " 'adearfriendnjust',\n",
       " 'adefenders',\n",
       " 'adelaide',\n",
       " 'adequately',\n",
       " 'adhere',\n",
       " 'adhered',\n",
       " 'adi',\n",
       " 'adicionei',\n",
       " 'adifferent',\n",
       " 'adjust',\n",
       " 'adjustment',\n",
       " 'admin',\n",
       " 'administer',\n",
       " 'administration',\n",
       " 'administrative',\n",
       " 'admins',\n",
       " 'admirable',\n",
       " 'admire',\n",
       " 'admissible',\n",
       " 'admission',\n",
       " 'admit',\n",
       " 'admits',\n",
       " 'admitshe',\n",
       " 'admitted',\n",
       " 'admitting',\n",
       " 'admonish',\n",
       " 'admonished',\n",
       " 'admonishment',\n",
       " 'adolf',\n",
       " 'adopt',\n",
       " 'adopted',\n",
       " 'adopting',\n",
       " 'adoption',\n",
       " 'adoptive',\n",
       " 'adorable',\n",
       " 'adorably',\n",
       " 'adore',\n",
       " 'adult',\n",
       " 'adulterer',\n",
       " 'adulting',\n",
       " 'advance',\n",
       " 'advanced',\n",
       " 'advantage',\n",
       " 'adversary',\n",
       " 'advertise',\n",
       " 'advertisement',\n",
       " 'advertiser',\n",
       " 'advertises',\n",
       " 'advertising',\n",
       " 'advice',\n",
       " 'advise',\n",
       " 'advised',\n",
       " 'adviser',\n",
       " 'advising',\n",
       " 'advisor',\n",
       " 'advocacy',\n",
       " 'advocate',\n",
       " 'advocating',\n",
       " 'aesir',\n",
       " 'af',\n",
       " 'affair',\n",
       " 'affect',\n",
       " 'affected',\n",
       " 'affecting',\n",
       " 'affection',\n",
       " 'affectionate',\n",
       " 'affiliate',\n",
       " 'affiliated',\n",
       " 'affiliation',\n",
       " 'affirm',\n",
       " 'affirmative',\n",
       " 'affluent',\n",
       " 'afford',\n",
       " 'affordable',\n",
       " 'afforded',\n",
       " 'afloat',\n",
       " 'afp',\n",
       " 'afraid',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'africanamerican',\n",
       " 'aftermath',\n",
       " 'afterward',\n",
       " 'afterwardswas',\n",
       " 'ag',\n",
       " 'againespecially',\n",
       " 'againoh',\n",
       " 'againstbthe',\n",
       " 'againtske',\n",
       " 'age',\n",
       " 'aged',\n",
       " 'agency',\n",
       " 'agenda',\n",
       " 'agent',\n",
       " 'agentof',\n",
       " 'aggers',\n",
       " 'aggie',\n",
       " 'aggression',\n",
       " 'aggressive',\n",
       " 'agholor',\n",
       " 'aging',\n",
       " 'agitated',\n",
       " 'aglabtintulog',\n",
       " 'ago',\n",
       " 'agree',\n",
       " 'agreeable',\n",
       " 'agreebut',\n",
       " 'agreed',\n",
       " 'agreedhe',\n",
       " 'agreeing',\n",
       " 'agreement',\n",
       " 'agrees',\n",
       " 'agressive',\n",
       " 'agt',\n",
       " 'agtresults',\n",
       " 'agw',\n",
       " 'ah',\n",
       " 'ahahaha',\n",
       " 'ahead',\n",
       " 'ahh',\n",
       " 'ahha',\n",
       " 'ahhh',\n",
       " 'ahole',\n",
       " 'ai',\n",
       " 'aid',\n",
       " 'aide',\n",
       " 'aiding',\n",
       " 'aim',\n",
       " 'aimed',\n",
       " 'aiming',\n",
       " 'ainge',\n",
       " 'aint',\n",
       " 'air',\n",
       " 'aired',\n",
       " 'airforce',\n",
       " 'airplane',\n",
       " 'airport',\n",
       " 'airtime',\n",
       " 'airwave',\n",
       " 'airy',\n",
       " 'aisa',\n",
       " 'aisha',\n",
       " 'aishwarya',\n",
       " 'aisle',\n",
       " 'aj',\n",
       " 'ajsjjsjdkkdjdk',\n",
       " 'ajsvsnsksjsj',\n",
       " 'aka',\n",
       " 'akal',\n",
       " 'akb',\n",
       " 'akimoto',\n",
       " 'akin',\n",
       " 'akkad',\n",
       " 'aknee',\n",
       " 'al',\n",
       " 'ala',\n",
       " 'alabama',\n",
       " 'alamo',\n",
       " 'alan',\n",
       " 'alanna',\n",
       " 'alarm',\n",
       " 'alaye',\n",
       " 'albans',\n",
       " 'albeit',\n",
       " 'albert',\n",
       " 'alberta',\n",
       " 'album',\n",
       " 'alcantara',\n",
       " 'alcatraz',\n",
       " 'alcohol',\n",
       " 'alcoholic',\n",
       " 'alec',\n",
       " 'alejandro',\n",
       " 'alert',\n",
       " 'alex',\n",
       " 'alexis',\n",
       " 'alexs',\n",
       " 'algae',\n",
       " 'algorithm',\n",
       " 'ali',\n",
       " 'alia',\n",
       " 'aliar',\n",
       " 'alien',\n",
       " 'alienate',\n",
       " 'alienating',\n",
       " 'align',\n",
       " 'aligned',\n",
       " 'aligns',\n",
       " 'alihan',\n",
       " 'alike',\n",
       " 'alinaae',\n",
       " 'alinsky',\n",
       " 'alinskyite',\n",
       " 'alinskys',\n",
       " 'alinskysrules',\n",
       " 'alive',\n",
       " 'allaying',\n",
       " 'allbut',\n",
       " 'allegation',\n",
       " 'allege',\n",
       " 'alleged',\n",
       " 'allegedly',\n",
       " 'allergy',\n",
       " 'alleslev',\n",
       " 'alleslve',\n",
       " 'alleyway',\n",
       " 'allfucking',\n",
       " 'allhe',\n",
       " 'alliancewhat',\n",
       " 'alligator',\n",
       " 'allinon',\n",
       " 'alll',\n",
       " 'allnow',\n",
       " 'allocated',\n",
       " 'alloutpolitics',\n",
       " 'allow',\n",
       " 'allowed',\n",
       " 'allowing',\n",
       " 'allows',\n",
       " 'allready',\n",
       " 'allsup',\n",
       " 'allusion',\n",
       " 'ally',\n",
       " 'almighty',\n",
       " 'alongside',\n",
       " 'alooot',\n",
       " 'alot',\n",
       " 'aloud',\n",
       " 'alp',\n",
       " 'alpoli',\n",
       " 'alpolitics',\n",
       " 'alqaeda',\n",
       " 'alright',\n",
       " 'alrighty',\n",
       " 'alt',\n",
       " 'altar',\n",
       " 'altc',\n",
       " 'alterando',\n",
       " 'altered',\n",
       " 'alternate',\n",
       " 'alternative',\n",
       " 'altho',\n",
       " 'altleft',\n",
       " 'altltlt',\n",
       " 'altmedia',\n",
       " 'altnews',\n",
       " 'altright',\n",
       " 'alum',\n",
       " 'alumn',\n",
       " 'alumnus',\n",
       " 'alyssa',\n",
       " 'alzheimers',\n",
       " 'ama',\n",
       " 'amai',\n",
       " 'amara',\n",
       " 'amassed',\n",
       " 'amateur',\n",
       " 'amature',\n",
       " 'amazed',\n",
       " 'amazes',\n",
       " 'amazing',\n",
       " 'amazingly',\n",
       " 'amazon',\n",
       " 'ambassador',\n",
       " 'ambiguity',\n",
       " 'ambition',\n",
       " 'ambitious',\n",
       " 'ambrose',\n",
       " 'ambulance',\n",
       " 'ambush',\n",
       " 'amdor',\n",
       " 'amen',\n",
       " 'amenadiels',\n",
       " 'amendment',\n",
       " 'amendmentreaches',\n",
       " 'amends',\n",
       " 'amental',\n",
       " 'america',\n",
       " 'americafirst',\n",
       " 'american',\n",
       " 'americaphobes',\n",
       " 'americatheyre',\n",
       " 'amid',\n",
       " 'amidst',\n",
       " 'amiright',\n",
       " 'amirite',\n",
       " 'amiryou',\n",
       " 'amish',\n",
       " 'ammo',\n",
       " 'ammunition',\n",
       " 'amnesia',\n",
       " 'amnesty',\n",
       " 'amo',\n",
       " 'amorality',\n",
       " 'amorphous',\n",
       " 'amounting',\n",
       " 'amp',\n",
       " 'ampall',\n",
       " 'ampcolombian',\n",
       " 'ampdisgraced',\n",
       " 'ample',\n",
       " 'ampnazis',\n",
       " 'ampthe',\n",
       " 'ampthose',\n",
       " 'amputee',\n",
       " 'amrinder',\n",
       " 'amusing',\n",
       " 'amy',\n",
       " 'anal',\n",
       " 'analog',\n",
       " 'analogy',\n",
       " 'analysis',\n",
       " 'analytica',\n",
       " 'analyzing',\n",
       " 'anarchist',\n",
       " 'anarchy',\n",
       " 'anatomy',\n",
       " 'anc',\n",
       " 'ancaps',\n",
       " 'ancestor',\n",
       " 'anchor',\n",
       " 'ancient',\n",
       " 'anderson',\n",
       " 'andfu',\n",
       " 'andor',\n",
       " 'andover',\n",
       " 'andre',\n",
       " 'andrea',\n",
       " 'andrew',\n",
       " 'andrewboff',\n",
       " 'android',\n",
       " 'andsadly',\n",
       " 'andwhat',\n",
       " 'andy',\n",
       " 'anfield',\n",
       " 'ang',\n",
       " 'angeela',\n",
       " 'angel',\n",
       " 'angela',\n",
       " 'angelina',\n",
       " 'anger',\n",
       " 'angerits',\n",
       " 'angie',\n",
       " 'angle',\n",
       " 'angling',\n",
       " 'anglophones',\n",
       " 'anglosaxon',\n",
       " 'angry',\n",
       " 'angy',\n",
       " 'animal',\n",
       " 'animate',\n",
       " 'animated',\n",
       " 'animation',\n",
       " 'anime',\n",
       " 'animic',\n",
       " 'anita',\n",
       " 'ann',\n",
       " 'anna',\n",
       " 'annie',\n",
       " 'annnd',\n",
       " 'announce',\n",
       " 'announced',\n",
       " 'announcement',\n",
       " 'announces',\n",
       " 'announcing',\n",
       " 'annoy',\n",
       " 'annoyance',\n",
       " 'annoying',\n",
       " 'anns',\n",
       " 'annual',\n",
       " 'annually',\n",
       " 'annulled',\n",
       " 'anon',\n",
       " 'anons',\n",
       " 'anonymity',\n",
       " 'anonymous',\n",
       " 'anothers',\n",
       " 'anqueefa',\n",
       " 'answer',\n",
       " 'answered',\n",
       " 'answering',\n",
       " 'ant',\n",
       " 'antagonist',\n",
       " 'anthem',\n",
       " 'anthony',\n",
       " 'anthro',\n",
       " 'anti',\n",
       " 'antiamerica',\n",
       " 'antiamerican',\n",
       " 'antiamericans',\n",
       " 'antiantifa',\n",
       " 'antibiotic',\n",
       " 'antiborder',\n",
       " 'antic',\n",
       " 'anticorruption',\n",
       " 'antidepressant',\n",
       " 'antideutsch',\n",
       " 'antidrug',\n",
       " 'antifa',\n",
       " 'antifaand',\n",
       " 'antifablmows',\n",
       " 'antifacurrently',\n",
       " 'antifaetc',\n",
       " 'antifagoons',\n",
       " 'antifagreat',\n",
       " 'antifahaters',\n",
       " 'antifair',\n",
       " 'antifaits',\n",
       " 'antifajust',\n",
       " 'antifakkk',\n",
       " 'antifalike',\n",
       " 'antifaloving',\n",
       " 'antifamomentum',\n",
       " 'antifaresist',\n",
       " 'antifas',\n",
       " 'antifaschismus',\n",
       " 'antifascism',\n",
       " 'antifascist',\n",
       " 'antifascists',\n",
       " 'antifatypes',\n",
       " 'antifawho',\n",
       " 'antifederalists',\n",
       " 'antifreedom',\n",
       " 'antigun',\n",
       " 'antiguncontrol',\n",
       " 'antijujubes',\n",
       " 'antikavanaugh',\n",
       " 'antinatalist',\n",
       " 'antinationalism',\n",
       " 'antinationalist',\n",
       " 'antinazi',\n",
       " 'antiopenborders',\n",
       " 'antipernickety',\n",
       " 'antipresident',\n",
       " 'antiquated',\n",
       " 'antiscience',\n",
       " 'antisemite',\n",
       " 'antisemitic',\n",
       " 'antisemitism',\n",
       " 'antiserena',\n",
       " 'antisjws',\n",
       " 'antitrump',\n",
       " 'antitrust',\n",
       " 'antiuk',\n",
       " 'antiwhite',\n",
       " 'antle',\n",
       " 'antonio',\n",
       " 'anumanu',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'anybody',\n",
       " 'anybodys',\n",
       " 'anyday',\n",
       " 'anymore',\n",
       " 'anymorejust',\n",
       " 'anymorewe',\n",
       " 'anyones',\n",
       " 'anytime',\n",
       " 'anywayits',\n",
       " 'anyways',\n",
       " 'ao',\n",
       " 'aok',\n",
       " 'ap',\n",
       " 'apart',\n",
       " 'apartaments',\n",
       " 'apartheid',\n",
       " 'apartment',\n",
       " 'apathetic',\n",
       " 'apiece',\n",
       " 'apirate',\n",
       " 'apne',\n",
       " 'apocalypse',\n",
       " 'apologetic',\n",
       " 'apologise',\n",
       " 'apologist',\n",
       " 'apologize',\n",
       " 'apologized',\n",
       " 'apologizing',\n",
       " 'apology',\n",
       " 'apon',\n",
       " 'app',\n",
       " 'appalled',\n",
       " 'appalling',\n",
       " 'apparantly',\n",
       " 'apparent',\n",
       " 'apparently',\n",
       " 'appeal',\n",
       " 'appealed',\n",
       " 'appear',\n",
       " 'appearance',\n",
       " 'appeared',\n",
       " 'appearing',\n",
       " 'appears',\n",
       " 'appease',\n",
       " 'appeasement',\n",
       " 'appeaser',\n",
       " 'appeasing',\n",
       " 'applaud',\n",
       " 'applauded',\n",
       " 'applauding',\n",
       " 'apple',\n",
       " 'applebee',\n",
       " 'applejack',\n",
       " 'application',\n",
       " 'applied',\n",
       " 'applies',\n",
       " 'apply',\n",
       " 'applying',\n",
       " 'appoint',\n",
       " 'appointed',\n",
       " 'appointee',\n",
       " 'appointment',\n",
       " 'appreciate',\n",
       " 'appreciated',\n",
       " 'appreciates',\n",
       " 'appreciation',\n",
       " 'approach',\n",
       " 'approaching',\n",
       " 'appropiated',\n",
       " 'appropo',\n",
       " 'appropriate',\n",
       " 'appropriating',\n",
       " 'approval',\n",
       " 'approve',\n",
       " 'approved',\n",
       " 'approves',\n",
       " 'appt',\n",
       " 'april',\n",
       " 'apt',\n",
       " 'ar',\n",
       " 'arachnophobia',\n",
       " 'arbiter',\n",
       " 'arbitrary',\n",
       " 'arbys',\n",
       " 'arc',\n",
       " 'arcane',\n",
       " 'archbishop',\n",
       " 'archetype',\n",
       " 'archie',\n",
       " 'architect',\n",
       " 'archived',\n",
       " 'area',\n",
       " 'arebut',\n",
       " 'areer',\n",
       " 'arenado',\n",
       " 'arent',\n",
       " 'areterrorists',\n",
       " 'areunless',\n",
       " 'argentborn',\n",
       " 'argento',\n",
       " 'arguably',\n",
       " 'argue',\n",
       " 'arguing',\n",
       " 'argument',\n",
       " 'ariana',\n",
       " 'arizona',\n",
       " 'arkansas',\n",
       " 'arlene',\n",
       " 'arm',\n",
       " 'armageddon',\n",
       " 'armamenttraining',\n",
       " 'armband',\n",
       " 'armchair',\n",
       " 'armed',\n",
       " 'arming',\n",
       " 'armor',\n",
       " 'armrest',\n",
       " 'army',\n",
       " 'arnie',\n",
       " 'arnold',\n",
       " 'arquette',\n",
       " 'arrange',\n",
       " 'arranged',\n",
       " 'arrest',\n",
       " 'arrested',\n",
       " 'arresting',\n",
       " 'arrive',\n",
       " 'arrived',\n",
       " 'arrogance',\n",
       " 'arrogant',\n",
       " 'arrogantly',\n",
       " 'arsenal',\n",
       " 'art',\n",
       " 'article',\n",
       " 'artificial',\n",
       " 'artist',\n",
       " 'artistforhire',\n",
       " 'artistsontwitter',\n",
       " 'artsy',\n",
       " 'asa',\n",
       " 'asap',\n",
       " 'asb',\n",
       " 'asbestos',\n",
       " 'ascend',\n",
       " 'ascended',\n",
       " 'asdfghjkl',\n",
       " 'asf',\n",
       " 'ash',\n",
       " 'ashall',\n",
       " 'ashame',\n",
       " 'ashamed',\n",
       " 'ashley',\n",
       " 'ashole',\n",
       " 'ashwariya',\n",
       " 'asia',\n",
       " 'asian',\n",
       " 'aside',\n",
       " 'asinine',\n",
       " 'ask',\n",
       " 'askalivelshi',\n",
       " 'asked',\n",
       " 'asking',\n",
       " 'asks',\n",
       " 'asleep',\n",
       " 'asma',\n",
       " 'asmr',\n",
       " 'aspect',\n",
       " 'asphalt',\n",
       " 'ass',\n",
       " 'assad',\n",
       " 'assange',\n",
       " 'assassin',\n",
       " 'assassinate',\n",
       " 'assassinating',\n",
       " 'assassination',\n",
       " 'assault',\n",
       " 'assaulted',\n",
       " 'assaultharassment',\n",
       " 'assaulting',\n",
       " 'assembly',\n",
       " 'assert',\n",
       " 'asserting',\n",
       " 'assertion',\n",
       " 'assessment',\n",
       " 'asset',\n",
       " 'asshats',\n",
       " 'asshole',\n",
       " 'assign',\n",
       " 'assignment',\n",
       " 'assist',\n",
       " 'assistant',\n",
       " 'assisting',\n",
       " 'associate',\n",
       " 'associated',\n",
       " 'association',\n",
       " 'assualted',\n",
       " 'assulting',\n",
       " 'assume',\n",
       " 'assumed',\n",
       " 'assumes',\n",
       " 'assuming',\n",
       " 'assumption',\n",
       " 'assure',\n",
       " 'astand',\n",
       " 'astonishing',\n",
       " 'astounded',\n",
       " 'astronaut',\n",
       " 'astronomically',\n",
       " 'asylum',\n",
       " 'ata',\n",
       " 'ate',\n",
       " 'atf',\n",
       " 'atheism',\n",
       " 'atheist',\n",
       " 'athlete',\n",
       " 'athought',\n",
       " 'atlanta',\n",
       " 'atlantic',\n",
       " 'atleast',\n",
       " 'atm',\n",
       " 'atmos',\n",
       " 'atmosphere',\n",
       " 'atone',\n",
       " 'atp',\n",
       " 'atrocious',\n",
       " 'atrocity',\n",
       " 'atsushikun',\n",
       " 'att',\n",
       " 'attached',\n",
       " 'attack',\n",
       " 'attacked',\n",
       " 'attacker',\n",
       " 'attacking',\n",
       " 'attempt',\n",
       " 'attempted',\n",
       " 'attempting',\n",
       " 'attend',\n",
       " 'attended',\n",
       " 'attendee',\n",
       " 'attending',\n",
       " 'attention',\n",
       " 'attentive',\n",
       " 'attest',\n",
       " 'attested',\n",
       " 'attire',\n",
       " 'attitude',\n",
       " 'attkisson',\n",
       " 'attlee',\n",
       " 'attn',\n",
       " 'attorney',\n",
       " 'attracted',\n",
       " 'attribute',\n",
       " 'atty',\n",
       " 'au',\n",
       " 'auburn',\n",
       " 'audible',\n",
       " 'audience',\n",
       " 'audio',\n",
       " 'audioslave',\n",
       " 'audrey',\n",
       " 'august',\n",
       " 'auhm',\n",
       " 'aum',\n",
       " 'aumf',\n",
       " 'aunt',\n",
       " 'auntie',\n",
       " 'aunty',\n",
       " 'aur',\n",
       " 'aura',\n",
       " 'aurora',\n",
       " 'ause',\n",
       " 'auspol',\n",
       " 'aust',\n",
       " 'austerity',\n",
       " 'austin',\n",
       " 'australia',\n",
       " 'australian',\n",
       " 'austria',\n",
       " 'authentic',\n",
       " 'author',\n",
       " 'authoritarian',\n",
       " 'authoritarianism',\n",
       " 'authoritarianismshock',\n",
       " 'authoritative',\n",
       " 'authority',\n",
       " 'authorization',\n",
       " 'authorize',\n",
       " 'authorized',\n",
       " 'autism',\n",
       " 'auto',\n",
       " 'autocratic',\n",
       " 'automatic',\n",
       " 'automatically',\n",
       " 'available',\n",
       " 'avatar',\n",
       " 'ave',\n",
       " 'avenatti',\n",
       " 'avenger',\n",
       " 'avenue',\n",
       " 'average',\n",
       " 'averagewould',\n",
       " 'avery',\n",
       " 'avi',\n",
       " 'avocado',\n",
       " 'avoid',\n",
       " 'avoided',\n",
       " 'avoiding',\n",
       " 'avoids',\n",
       " 'avowed',\n",
       " 'avram',\n",
       " 'aw',\n",
       " 'awaits',\n",
       " 'awake',\n",
       " 'awaken',\n",
       " 'awakening',\n",
       " 'award',\n",
       " 'awarded',\n",
       " 'aware',\n",
       " 'awareness',\n",
       " 'away',\n",
       " 'awb',\n",
       " 'awe',\n",
       " 'aweee',\n",
       " 'awesome',\n",
       " 'awewww',\n",
       " 'awful',\n",
       " 'awh',\n",
       " 'awhile',\n",
       " 'awkward',\n",
       " 'awone',\n",
       " 'aww',\n",
       " 'awwh',\n",
       " 'awww',\n",
       " 'ax',\n",
       " 'axe',\n",
       " 'axis',\n",
       " 'ay',\n",
       " 'aye',\n",
       " 'ayers',\n",
       " 'ayumi',\n",
       " 'az',\n",
       " 'azeez',\n",
       " 'ba',\n",
       " 'baaa',\n",
       " 'baaathats',\n",
       " 'babble',\n",
       " 'babe',\n",
       " 'babesfortrump',\n",
       " 'babie',\n",
       " 'babiesthey',\n",
       " 'babieswar',\n",
       " 'baby',\n",
       " 'babyadults',\n",
       " 'babygirl',\n",
       " 'babylonian',\n",
       " 'babynot',\n",
       " 'babysit',\n",
       " 'babysitting',\n",
       " 'bache',\n",
       " 'bachelor',\n",
       " 'backbencher',\n",
       " 'backbone',\n",
       " 'backdoor',\n",
       " 'backed',\n",
       " 'backer',\n",
       " 'backfield',\n",
       " 'backfire',\n",
       " 'background',\n",
       " 'backing',\n",
       " 'backlinks',\n",
       " 'backon',\n",
       " 'backpack',\n",
       " 'backshe',\n",
       " 'backside',\n",
       " 'backstabber',\n",
       " 'backstabbing',\n",
       " 'backto',\n",
       " 'backup',\n",
       " 'backward',\n",
       " 'backwards',\n",
       " 'backwood',\n",
       " 'bacon',\n",
       " 'bad',\n",
       " 'badass',\n",
       " 'badasses',\n",
       " 'badge',\n",
       " 'badger',\n",
       " 'badhai',\n",
       " 'badi',\n",
       " 'badly',\n",
       " 'bae',\n",
       " 'baekhyun',\n",
       " 'baer',\n",
       " 'baff',\n",
       " 'bafoonicus',\n",
       " 'bag',\n",
       " 'bagel',\n",
       " 'bagger',\n",
       " ...]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bright-throat",
   "metadata": {},
   "source": [
    "## Classifying Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "amber-composition",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "circular-holiday",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.05,\n",
       " 0.1,\n",
       " 0.15000000000000002,\n",
       " 0.2,\n",
       " 0.25,\n",
       " 0.30000000000000004,\n",
       " 0.35000000000000003,\n",
       " 0.4,\n",
       " 0.45,\n",
       " 0.5,\n",
       " 0.55,\n",
       " 0.6000000000000001,\n",
       " 0.65,\n",
       " 0.7000000000000001,\n",
       " 0.75,\n",
       " 0.8,\n",
       " 0.8500000000000001,\n",
       " 0.9,\n",
       " 0.9500000000000001]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = list(np.arange(0, 1, 0.05))\n",
    "\n",
    "C = [float(i) for i in C]\n",
    "\n",
    "C = C[1:]\n",
    "\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "supported-letters",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "personalized-plastic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.05: 0.6758308157099698,\n",
       " 0.1: 0.6948640483383686,\n",
       " 0.15000000000000002: 0.7078549848942598,\n",
       " 0.2: 0.7175226586102719,\n",
       " 0.25: 0.7259818731117825,\n",
       " 0.30000000000000004: 0.7317220543806646,\n",
       " 0.35000000000000003: 0.7383685800604229,\n",
       " 0.4: 0.7447129909365559,\n",
       " 0.45: 0.7474320241691843,\n",
       " 0.5: 0.7501510574018126,\n",
       " 0.55: 0.7549848942598187,\n",
       " 0.6000000000000001: 0.7577039274924471,\n",
       " 0.65: 0.7598187311178247,\n",
       " 0.7000000000000001: 0.7613293051359517,\n",
       " 0.75: 0.7619335347432025,\n",
       " 0.8: 0.7634441087613293,\n",
       " 0.8500000000000001: 0.7646525679758308,\n",
       " 0.9: 0.7652567975830815,\n",
       " 0.9500000000000001: 0.7658610271903323}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in C:\n",
    "    clf = LogisticRegression(C= i, max_iter=1000)\n",
    "    clf.fit(X_train_vect, y_train)\n",
    "    scores[i] = clf.score(vect.transform(X_test), y_test)\n",
    "    \n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "placed-sight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9500000000000001\n"
     ]
    }
   ],
   "source": [
    "best_C = max(scores, key=scores.get)\n",
    "\n",
    "print(best_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "right-wealth",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(C=best_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "secure-laptop",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.9500000000000001)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "sharing-modem",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7658610271903323"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(vect.transform(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "romance-corpus",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "desirable-tragedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = clf.coef_[0].argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "pending-detector",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coefs \n",
      "['antifa' 'thank' 'best' 'url' 'beautiful' 'conservative' 'new' 'thanks'\n",
      " 'funny' 'love']\n",
      "Largest Coefs \n",
      "['racist' 'sick' 'disgusting' 'liar' 'suck' 'idiot' 'bitch' 'fucking'\n",
      " 'stupid' 'fuck']\n"
     ]
    }
   ],
   "source": [
    "print(\"Smallest Coefs \\n{}\".format(features[coefs[:10]]))\n",
    "print(\"Largest Coefs \\n{}\".format(features[coefs[-11:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standing-airplane",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
