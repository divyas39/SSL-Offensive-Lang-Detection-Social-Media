{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "durable-outreach",
   "metadata": {},
   "source": [
    "# Bag Of Words Model\n",
    "\n",
    "Uses one-hot encoding to count number of occurences of a word in a given document. Disadvantage is that most words are not repeated in every document leading to a sparse matrix and also does not take into account the structure of a sentence, i.e., the order of words or semantics.\n",
    "\n",
    "\"Not bad, working good\" and \"Not good, working bad\" would be treated as the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "duplicate-design",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "coordinated-alfred",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"processed_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "surprising-moment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>subtask_b</th>\n",
       "      <th>subtask_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>86426</td>\n",
       "      <td>['ask', 'native', 'american', 'take']</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>90194</td>\n",
       "      <td>['go', 'home', '’', 'drunk', 'maga', 'trump', ...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>16820</td>\n",
       "      <td>['amazon', 'investigating', 'chinese', 'employ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>62688</td>\n",
       "      <td>['someone', 'shouldve', 'taken', 'piece', 'shi...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>43605</td>\n",
       "      <td>['obama', 'wanted', 'liberal', 'amp', 'illegal...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13235</th>\n",
       "      <td>13235</td>\n",
       "      <td>95338</td>\n",
       "      <td>['sometimes', 'get', 'strong', 'vibe', 'people...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13236</th>\n",
       "      <td>13236</td>\n",
       "      <td>67210</td>\n",
       "      <td>['benidorm', '✅', 'creamfields', '✅', 'maga', ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13237</th>\n",
       "      <td>13237</td>\n",
       "      <td>82921</td>\n",
       "      <td>['report', 'garbage', 'dont', 'give', 'crap']</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>OTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13238</th>\n",
       "      <td>13238</td>\n",
       "      <td>27429</td>\n",
       "      <td>['pussy']</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13239</th>\n",
       "      <td>13239</td>\n",
       "      <td>46552</td>\n",
       "      <td>['spanishrevenge', 'v', 'justice', 'human', 'r...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13240 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0     id                                              tweet  \\\n",
       "0               0  86426              ['ask', 'native', 'american', 'take']   \n",
       "1               1  90194  ['go', 'home', '’', 'drunk', 'maga', 'trump', ...   \n",
       "2               2  16820  ['amazon', 'investigating', 'chinese', 'employ...   \n",
       "3               3  62688  ['someone', 'shouldve', 'taken', 'piece', 'shi...   \n",
       "4               4  43605  ['obama', 'wanted', 'liberal', 'amp', 'illegal...   \n",
       "...           ...    ...                                                ...   \n",
       "13235       13235  95338  ['sometimes', 'get', 'strong', 'vibe', 'people...   \n",
       "13236       13236  67210  ['benidorm', '✅', 'creamfields', '✅', 'maga', ...   \n",
       "13237       13237  82921      ['report', 'garbage', 'dont', 'give', 'crap']   \n",
       "13238       13238  27429                                          ['pussy']   \n",
       "13239       13239  46552  ['spanishrevenge', 'v', 'justice', 'human', 'r...   \n",
       "\n",
       "      subtask_a subtask_b subtask_c  \n",
       "0           OFF       UNT       NaN  \n",
       "1           OFF       TIN       IND  \n",
       "2           NOT       NaN       NaN  \n",
       "3           OFF       UNT       NaN  \n",
       "4           NOT       NaN       NaN  \n",
       "...         ...       ...       ...  \n",
       "13235       OFF       TIN       IND  \n",
       "13236       NOT       NaN       NaN  \n",
       "13237       OFF       TIN       OTH  \n",
       "13238       OFF       UNT       NaN  \n",
       "13239       NOT       NaN       NaN  \n",
       "\n",
       "[13240 rows x 6 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sexual-cursor",
   "metadata": {},
   "source": [
    "### Removing redundant axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "driving-collectible",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "finnish-reality",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>subtask_b</th>\n",
       "      <th>subtask_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86426</td>\n",
       "      <td>['ask', 'native', 'american', 'take']</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90194</td>\n",
       "      <td>['go', 'home', '’', 'drunk', 'maga', 'trump', ...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16820</td>\n",
       "      <td>['amazon', 'investigating', 'chinese', 'employ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62688</td>\n",
       "      <td>['someone', 'shouldve', 'taken', 'piece', 'shi...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43605</td>\n",
       "      <td>['obama', 'wanted', 'liberal', 'amp', 'illegal...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13235</th>\n",
       "      <td>95338</td>\n",
       "      <td>['sometimes', 'get', 'strong', 'vibe', 'people...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13236</th>\n",
       "      <td>67210</td>\n",
       "      <td>['benidorm', '✅', 'creamfields', '✅', 'maga', ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13237</th>\n",
       "      <td>82921</td>\n",
       "      <td>['report', 'garbage', 'dont', 'give', 'crap']</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>OTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13238</th>\n",
       "      <td>27429</td>\n",
       "      <td>['pussy']</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13239</th>\n",
       "      <td>46552</td>\n",
       "      <td>['spanishrevenge', 'v', 'justice', 'human', 'r...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13240 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              tweet subtask_a  \\\n",
       "0      86426              ['ask', 'native', 'american', 'take']       OFF   \n",
       "1      90194  ['go', 'home', '’', 'drunk', 'maga', 'trump', ...       OFF   \n",
       "2      16820  ['amazon', 'investigating', 'chinese', 'employ...       NOT   \n",
       "3      62688  ['someone', 'shouldve', 'taken', 'piece', 'shi...       OFF   \n",
       "4      43605  ['obama', 'wanted', 'liberal', 'amp', 'illegal...       NOT   \n",
       "...      ...                                                ...       ...   \n",
       "13235  95338  ['sometimes', 'get', 'strong', 'vibe', 'people...       OFF   \n",
       "13236  67210  ['benidorm', '✅', 'creamfields', '✅', 'maga', ...       NOT   \n",
       "13237  82921      ['report', 'garbage', 'dont', 'give', 'crap']       OFF   \n",
       "13238  27429                                          ['pussy']       OFF   \n",
       "13239  46552  ['spanishrevenge', 'v', 'justice', 'human', 'r...       NOT   \n",
       "\n",
       "      subtask_b subtask_c  \n",
       "0           UNT       NaN  \n",
       "1           TIN       IND  \n",
       "2           NaN       NaN  \n",
       "3           UNT       NaN  \n",
       "4           NaN       NaN  \n",
       "...         ...       ...  \n",
       "13235       TIN       IND  \n",
       "13236       NaN       NaN  \n",
       "13237       TIN       OTH  \n",
       "13238       UNT       NaN  \n",
       "13239       NaN       NaN  \n",
       "\n",
       "[13240 rows x 5 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fundamental-board",
   "metadata": {},
   "source": [
    "### Removing Unnecessary Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "extra-somerset",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"subtask_b\", \"subtask_c\", \"id\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "younger-symphony",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['ask', 'native', 'american', 'take']</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['go', 'home', '’', 'drunk', 'maga', 'trump', ...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['amazon', 'investigating', 'chinese', 'employ...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['someone', 'shouldve', 'taken', 'piece', 'shi...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['obama', 'wanted', 'liberal', 'amp', 'illegal...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13235</th>\n",
       "      <td>['sometimes', 'get', 'strong', 'vibe', 'people...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13236</th>\n",
       "      <td>['benidorm', '✅', 'creamfields', '✅', 'maga', ...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13237</th>\n",
       "      <td>['report', 'garbage', 'dont', 'give', 'crap']</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13238</th>\n",
       "      <td>['pussy']</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13239</th>\n",
       "      <td>['spanishrevenge', 'v', 'justice', 'human', 'r...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13240 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet subtask_a\n",
       "0                  ['ask', 'native', 'american', 'take']       OFF\n",
       "1      ['go', 'home', '’', 'drunk', 'maga', 'trump', ...       OFF\n",
       "2      ['amazon', 'investigating', 'chinese', 'employ...       NOT\n",
       "3      ['someone', 'shouldve', 'taken', 'piece', 'shi...       OFF\n",
       "4      ['obama', 'wanted', 'liberal', 'amp', 'illegal...       NOT\n",
       "...                                                  ...       ...\n",
       "13235  ['sometimes', 'get', 'strong', 'vibe', 'people...       OFF\n",
       "13236  ['benidorm', '✅', 'creamfields', '✅', 'maga', ...       NOT\n",
       "13237      ['report', 'garbage', 'dont', 'give', 'crap']       OFF\n",
       "13238                                          ['pussy']       OFF\n",
       "13239  ['spanishrevenge', 'v', 'justice', 'human', 'r...       NOT\n",
       "\n",
       "[13240 rows x 2 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollywood-external",
   "metadata": {},
   "source": [
    "### Renaming Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "previous-coordinate",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"subtask_a\": \"Offensive\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "aboriginal-lawyer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>Offensive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['ask', 'native', 'american', 'take']</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['go', 'home', '’', 'drunk', 'maga', 'trump', ...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['amazon', 'investigating', 'chinese', 'employ...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['someone', 'shouldve', 'taken', 'piece', 'shi...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['obama', 'wanted', 'liberal', 'amp', 'illegal...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13235</th>\n",
       "      <td>['sometimes', 'get', 'strong', 'vibe', 'people...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13236</th>\n",
       "      <td>['benidorm', '✅', 'creamfields', '✅', 'maga', ...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13237</th>\n",
       "      <td>['report', 'garbage', 'dont', 'give', 'crap']</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13238</th>\n",
       "      <td>['pussy']</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13239</th>\n",
       "      <td>['spanishrevenge', 'v', 'justice', 'human', 'r...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13240 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet Offensive\n",
       "0                  ['ask', 'native', 'american', 'take']       OFF\n",
       "1      ['go', 'home', '’', 'drunk', 'maga', 'trump', ...       OFF\n",
       "2      ['amazon', 'investigating', 'chinese', 'employ...       NOT\n",
       "3      ['someone', 'shouldve', 'taken', 'piece', 'shi...       OFF\n",
       "4      ['obama', 'wanted', 'liberal', 'amp', 'illegal...       NOT\n",
       "...                                                  ...       ...\n",
       "13235  ['sometimes', 'get', 'strong', 'vibe', 'people...       OFF\n",
       "13236  ['benidorm', '✅', 'creamfields', '✅', 'maga', ...       NOT\n",
       "13237      ['report', 'garbage', 'dont', 'give', 'crap']       OFF\n",
       "13238                                          ['pussy']       OFF\n",
       "13239  ['spanishrevenge', 'v', 'justice', 'human', 'r...       NOT\n",
       "\n",
       "[13240 rows x 2 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honest-worry",
   "metadata": {},
   "source": [
    "### Replacing Class with Numeric Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "higher-hammer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def repl(off):\n",
    "    if off == 'OFF':\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "amber-stuff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Offensive'] = df['Offensive'].apply(repl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "academic-commitment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>Offensive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['ask', 'native', 'american', 'take']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['go', 'home', '’', 'drunk', 'maga', 'trump', ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['amazon', 'investigating', 'chinese', 'employ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['someone', 'shouldve', 'taken', 'piece', 'shi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['obama', 'wanted', 'liberal', 'amp', 'illegal...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13235</th>\n",
       "      <td>['sometimes', 'get', 'strong', 'vibe', 'people...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13236</th>\n",
       "      <td>['benidorm', '✅', 'creamfields', '✅', 'maga', ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13237</th>\n",
       "      <td>['report', 'garbage', 'dont', 'give', 'crap']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13238</th>\n",
       "      <td>['pussy']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13239</th>\n",
       "      <td>['spanishrevenge', 'v', 'justice', 'human', 'r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13240 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet  Offensive\n",
       "0                  ['ask', 'native', 'american', 'take']          1\n",
       "1      ['go', 'home', '’', 'drunk', 'maga', 'trump', ...          1\n",
       "2      ['amazon', 'investigating', 'chinese', 'employ...          0\n",
       "3      ['someone', 'shouldve', 'taken', 'piece', 'shi...          1\n",
       "4      ['obama', 'wanted', 'liberal', 'amp', 'illegal...          0\n",
       "...                                                  ...        ...\n",
       "13235  ['sometimes', 'get', 'strong', 'vibe', 'people...          1\n",
       "13236  ['benidorm', '✅', 'creamfields', '✅', 'maga', ...          0\n",
       "13237      ['report', 'garbage', 'dont', 'give', 'crap']          1\n",
       "13238                                          ['pussy']          1\n",
       "13239  ['spanishrevenge', 'v', 'justice', 'human', 'r...          0\n",
       "\n",
       "[13240 rows x 2 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "acknowledged-sending",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    ['ask', 'native', 'american', 'take']\n",
       "1        ['go', 'home', '’', 'drunk', 'maga', 'trump', ...\n",
       "2        ['amazon', 'investigating', 'chinese', 'employ...\n",
       "3        ['someone', 'shouldve', 'taken', 'piece', 'shi...\n",
       "4        ['obama', 'wanted', 'liberal', 'amp', 'illegal...\n",
       "                               ...                        \n",
       "13235    ['sometimes', 'get', 'strong', 'vibe', 'people...\n",
       "13236    ['benidorm', '✅', 'creamfields', '✅', 'maga', ...\n",
       "13237        ['report', 'garbage', 'dont', 'give', 'crap']\n",
       "13238                                            ['pussy']\n",
       "13239    ['spanishrevenge', 'v', 'justice', 'human', 'r...\n",
       "Name: tweet, Length: 13240, dtype: object"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabulous-making",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "uniform-jacksonville",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['tweet'], df['Offensive'], stratify=df['Offensive'], shuffle=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "controlled-findings",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10485    ['chicago', 'record', 'number', 'homicide', 'g...\n",
       "227      ['aha', 'yes', 'see', 'individual', 'sense', '...\n",
       "446      ['yeah', 'think', 'saying', 'addiction', 'life...\n",
       "4830     ['antikavanaugh', 'group', 'already', 'spinnin...\n",
       "6141     ['hope', 'theyre', 'brushed', 'large', 'negati...\n",
       "                               ...                        \n",
       "8265               ['like', 'boob', 'mass', 'belly', 'xd']\n",
       "4815     ['civilian', 'also', 'ill', 'admit', 'hard', '...\n",
       "12445    ['good', 'thats', 'fine', 'gun', 'control', 'd...\n",
       "11772                       ['oh', 'shit', 'stay', 'safe']\n",
       "5486     ['twitter', 'social', 'medium', 'seems', 'make...\n",
       "Name: tweet, Length: 9930, dtype: object"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "through-corner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10485    1\n",
       "227      0\n",
       "446      0\n",
       "4830     0\n",
       "6141     1\n",
       "        ..\n",
       "8265     1\n",
       "4815     0\n",
       "12445    1\n",
       "11772    0\n",
       "5486     0\n",
       "Name: Offensive, Length: 9930, dtype: int64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "traditional-weekly",
   "metadata": {},
   "source": [
    "## BoW Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "following-guyana",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(lowercase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "romantic-browse",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = vect.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "worst-minister",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14572"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "broadband-sierra",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<9930x14572 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 99161 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vect = vect.transform(X_train)\n",
    "\n",
    "X_train_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "measured-local",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "sweet-beginning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.05,\n",
       " 0.1,\n",
       " 0.15000000000000002,\n",
       " 0.2,\n",
       " 0.25,\n",
       " 0.30000000000000004,\n",
       " 0.35000000000000003,\n",
       " 0.4,\n",
       " 0.45,\n",
       " 0.5,\n",
       " 0.55,\n",
       " 0.6000000000000001,\n",
       " 0.65,\n",
       " 0.7000000000000001,\n",
       " 0.75,\n",
       " 0.8,\n",
       " 0.8500000000000001,\n",
       " 0.9,\n",
       " 0.9500000000000001]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = list(np.arange(0, 1, 0.05))\n",
    "\n",
    "C = [float(i) for i in C]\n",
    "\n",
    "C = C[1:]\n",
    "\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "assumed-logan",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "designed-thanks",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.05: 0.7477341389728097,\n",
       " 0.1: 0.7595166163141994,\n",
       " 0.15000000000000002: 0.7601208459214501,\n",
       " 0.2: 0.7640483383685801,\n",
       " 0.25: 0.766465256797583,\n",
       " 0.30000000000000004: 0.7673716012084593,\n",
       " 0.35000000000000003: 0.7655589123867069,\n",
       " 0.4: 0.7661631419939577,\n",
       " 0.45: 0.7637462235649547,\n",
       " 0.5: 0.7631419939577039,\n",
       " 0.55: 0.7637462235649547,\n",
       " 0.6000000000000001: 0.7646525679758308,\n",
       " 0.65: 0.7652567975830815,\n",
       " 0.7000000000000001: 0.7655589123867069,\n",
       " 0.75: 0.7673716012084593,\n",
       " 0.8: 0.7661631419939577,\n",
       " 0.8500000000000001: 0.766465256797583,\n",
       " 0.9: 0.766465256797583,\n",
       " 0.9500000000000001: 0.7658610271903323}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in C:\n",
    "    clf = LogisticRegression(C= i, max_iter=1000)\n",
    "    clf.fit(X_train_vect, y_train)\n",
    "    scores[i] = clf.score(vect.transform(X_test), y_test)\n",
    "    \n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "animal-science",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30000000000000004\n"
     ]
    }
   ],
   "source": [
    "best_C = max(scores, key=scores.get)\n",
    "\n",
    "print(best_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "automated-catch",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(C= 0.3, max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "tribal-ordering",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.3, max_iter=1000)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ongoing-aluminum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7673716012084593"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(vect.transform(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "endless-dispute",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "improved-stereo",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = clf.coef_[0].argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "gentle-idaho",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coefs \n",
      "['thank' 'justice' 'lead' 'best' 'brexit' 'welcome' 'nike' 'action'\n",
      " 'accuser' 'company']\n",
      "Largest Coefs \n",
      "['nigga' 'suck' 'disgusting' 'liar' 'as' 'idiot' 'fucking' 'stupid'\n",
      " 'bitch' 'shit']\n"
     ]
    }
   ],
   "source": [
    "print(\"Smallest Coefs \\n{}\".format(features[coefs[:10]]))\n",
    "print(\"Largest Coefs \\n{}\".format(features[coefs[-11:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fuzzy-saudi",
   "metadata": {},
   "source": [
    "## BoW with Bigrams and Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "global-closing",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_gram = CountVectorizer(lowercase=False, ngram_range=(1, 3), min_df=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "documentary-compression",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_gram = vect_gram.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "integral-watts",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14922"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vect_gram.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "narrow-survey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aa',\n",
       " 'aaa',\n",
       " 'aaron',\n",
       " 'ab',\n",
       " 'abandon',\n",
       " 'abbott',\n",
       " 'abhorrent',\n",
       " 'abiding',\n",
       " 'abiding citizen',\n",
       " 'abiding nra',\n",
       " 'abiding nra member',\n",
       " 'ability',\n",
       " 'abject',\n",
       " 'able',\n",
       " 'able eat',\n",
       " 'able get',\n",
       " 'able get time',\n",
       " 'able keep',\n",
       " 'aboard',\n",
       " 'abolish',\n",
       " 'aborting',\n",
       " 'abortion',\n",
       " 'abortion gun',\n",
       " 'abortion gun control',\n",
       " 'absentee',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absolutely insane',\n",
       " 'absolutely nothing',\n",
       " 'absolutely one',\n",
       " 'absolutely right',\n",
       " 'absurd',\n",
       " 'abt',\n",
       " 'abuse',\n",
       " 'abuse power',\n",
       " 'abuse right',\n",
       " 'abuse woman',\n",
       " 'abused',\n",
       " 'abuser',\n",
       " 'abuser woman',\n",
       " 'abusing',\n",
       " 'abusive',\n",
       " 'abysmal',\n",
       " 'ac',\n",
       " 'ac npr',\n",
       " 'ac npr pbsnews',\n",
       " 'aca',\n",
       " 'academic',\n",
       " 'acc',\n",
       " 'accept',\n",
       " 'accept allegation',\n",
       " 'acceptable',\n",
       " 'accepted',\n",
       " 'accepting',\n",
       " 'access',\n",
       " 'accessory',\n",
       " 'accident',\n",
       " 'accidentally',\n",
       " 'accomplish',\n",
       " 'accomplished',\n",
       " 'accomplishment',\n",
       " 'according',\n",
       " 'according liberal',\n",
       " 'accordingly',\n",
       " 'account',\n",
       " 'account antifa',\n",
       " 'account check',\n",
       " 'account check list',\n",
       " 'account list',\n",
       " 'accountability',\n",
       " 'accountable',\n",
       " 'accountable action',\n",
       " 'accuracy',\n",
       " 'accurate',\n",
       " 'accusation',\n",
       " 'accusation credible',\n",
       " 'accusation without',\n",
       " 'accuse',\n",
       " 'accuse conservative',\n",
       " 'accuse people',\n",
       " 'accused',\n",
       " 'accuser',\n",
       " 'accuser maga',\n",
       " 'accuser maga prolife',\n",
       " 'accuses',\n",
       " 'accusing',\n",
       " 'ace',\n",
       " 'achieve',\n",
       " 'achievement',\n",
       " 'achieving',\n",
       " 'acknowledge',\n",
       " 'aclu',\n",
       " 'acquiring',\n",
       " 'across',\n",
       " 'across border',\n",
       " 'across country',\n",
       " 'act',\n",
       " 'act like',\n",
       " 'acted',\n",
       " 'acted like',\n",
       " 'acted like spoiled',\n",
       " 'acting',\n",
       " 'acting like',\n",
       " 'acting like jihadist',\n",
       " 'action',\n",
       " 'action never',\n",
       " 'action url',\n",
       " 'action woman',\n",
       " 'action would',\n",
       " 'active',\n",
       " 'active shooter',\n",
       " 'active shooter middleton',\n",
       " 'actively',\n",
       " 'activist',\n",
       " 'activist jail',\n",
       " 'activist jail year',\n",
       " 'activist liar',\n",
       " 'activity',\n",
       " 'actor',\n",
       " 'actress',\n",
       " 'actual',\n",
       " 'actual fascist',\n",
       " 'actually',\n",
       " 'actually antifa',\n",
       " 'actually bad',\n",
       " 'actually care',\n",
       " 'actually dead',\n",
       " 'actually got',\n",
       " 'actually liberal',\n",
       " 'actually make',\n",
       " 'actually say',\n",
       " 'actually want',\n",
       " 'actually want improved',\n",
       " 'ad',\n",
       " 'ad gun',\n",
       " 'ad gun control',\n",
       " 'adam',\n",
       " 'add',\n",
       " 'added',\n",
       " 'addict',\n",
       " 'addicted',\n",
       " 'addiction',\n",
       " 'adding',\n",
       " 'addition',\n",
       " 'address',\n",
       " 'address issue',\n",
       " 'address question',\n",
       " 'addressing',\n",
       " 'adefenders',\n",
       " 'adelaide',\n",
       " 'adhere',\n",
       " 'admin',\n",
       " 'administration',\n",
       " 'administration history',\n",
       " 'admire',\n",
       " 'admissible',\n",
       " 'admit',\n",
       " 'admits',\n",
       " 'admitted',\n",
       " 'admitting',\n",
       " 'adopt',\n",
       " 'adopted',\n",
       " 'adopting',\n",
       " 'adorable',\n",
       " 'adore',\n",
       " 'adult',\n",
       " 'adult room',\n",
       " 'advance',\n",
       " 'advance follow',\n",
       " 'advance follow back',\n",
       " 'advantage',\n",
       " 'advice',\n",
       " 'advocate',\n",
       " 'advocate gun',\n",
       " 'advocate gun control',\n",
       " 'advocating',\n",
       " 'af',\n",
       " 'affair',\n",
       " 'affect',\n",
       " 'affected',\n",
       " 'affluent',\n",
       " 'afford',\n",
       " 'affordable',\n",
       " 'affordable health',\n",
       " 'affordable health care',\n",
       " 'affordable home',\n",
       " 'affordable social',\n",
       " 'afforded',\n",
       " 'afraid',\n",
       " 'afraid trump',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'african friend',\n",
       " 'african friend dont',\n",
       " 'afterward',\n",
       " 'afterwards',\n",
       " 'ag',\n",
       " 'age',\n",
       " 'age liberal',\n",
       " 'aged',\n",
       " 'agency',\n",
       " 'agenda',\n",
       " 'agent',\n",
       " 'aggression',\n",
       " 'aggressive',\n",
       " 'ago',\n",
       " 'ago big',\n",
       " 'ago liberal',\n",
       " 'ago today',\n",
       " 'ago yr',\n",
       " 'ago yr old',\n",
       " 'agree',\n",
       " 'agree conservative',\n",
       " 'agree though',\n",
       " 'agree trump',\n",
       " 'agree url',\n",
       " 'agreed',\n",
       " 'agreeing',\n",
       " 'agreement',\n",
       " 'agrees',\n",
       " 'ah',\n",
       " 'ah yes',\n",
       " 'ahead',\n",
       " 'ahh',\n",
       " 'ahhh',\n",
       " 'ahhh left',\n",
       " 'ahole',\n",
       " 'aid',\n",
       " 'aide',\n",
       " 'aiding',\n",
       " 'aight',\n",
       " 'aim',\n",
       " 'aim send',\n",
       " 'aim send masked',\n",
       " 'aimed',\n",
       " 'aimed nearuniversal',\n",
       " 'aimed nearuniversal armamenttraining',\n",
       " 'aiming',\n",
       " 'aint',\n",
       " 'aint gonna',\n",
       " 'air',\n",
       " 'air time',\n",
       " 'airplane',\n",
       " 'airport',\n",
       " 'airtime',\n",
       " 'aisle',\n",
       " 'aj',\n",
       " 'aka',\n",
       " 'akin',\n",
       " 'al',\n",
       " 'alamo',\n",
       " 'alan',\n",
       " 'alarm',\n",
       " 'album',\n",
       " 'alcohol',\n",
       " 'alert',\n",
       " 'alert gun',\n",
       " 'alert gun control',\n",
       " 'alex',\n",
       " 'alex jones',\n",
       " 'alien',\n",
       " 'alienate',\n",
       " 'align',\n",
       " 'aligned',\n",
       " 'alinsky',\n",
       " 'alive',\n",
       " 'alive well',\n",
       " 'allegation',\n",
       " 'allegation conservative',\n",
       " 'allegation lying',\n",
       " 'alleged',\n",
       " 'allegedly',\n",
       " 'alleslev',\n",
       " 'allow',\n",
       " 'allow people',\n",
       " 'allow rapist',\n",
       " 'allowed',\n",
       " 'allowed url',\n",
       " 'allowing',\n",
       " 'allows',\n",
       " 'ally',\n",
       " 'almost',\n",
       " 'almost bad',\n",
       " 'almost every',\n",
       " 'almost everyone',\n",
       " 'almost like',\n",
       " 'almost year',\n",
       " 'almost yr',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'alongside',\n",
       " 'alongside blast',\n",
       " 'alot',\n",
       " 'alpolitics',\n",
       " 'already',\n",
       " 'already following',\n",
       " 'already found',\n",
       " 'already gun',\n",
       " 'already gun control',\n",
       " 'already know',\n",
       " 'already rejected',\n",
       " 'already strict',\n",
       " 'already strict gun',\n",
       " 'already url',\n",
       " 'alright',\n",
       " 'also',\n",
       " 'also antifa',\n",
       " 'also believe',\n",
       " 'also go',\n",
       " 'also great',\n",
       " 'also im',\n",
       " 'also love',\n",
       " 'also need',\n",
       " 'also one',\n",
       " 'also said',\n",
       " 'also say',\n",
       " 'also support',\n",
       " 'also support antifa',\n",
       " 'also trump',\n",
       " 'also want',\n",
       " 'also would',\n",
       " 'also wrong',\n",
       " 'alt',\n",
       " 'alt left',\n",
       " 'alt right',\n",
       " 'alternative',\n",
       " 'alternative fact',\n",
       " 'although',\n",
       " 'altleft',\n",
       " 'altnews',\n",
       " 'altnews brexit',\n",
       " 'altnews brexit remain',\n",
       " 'altright',\n",
       " 'altright fascist',\n",
       " 'always',\n",
       " 'always find',\n",
       " 'always get',\n",
       " 'always happy',\n",
       " 'always look',\n",
       " 'always look like',\n",
       " 'always looking',\n",
       " 'always play',\n",
       " 'always play victim',\n",
       " 'always playing',\n",
       " 'always right',\n",
       " 'always say',\n",
       " 'always tell',\n",
       " 'always thought',\n",
       " 'always victim',\n",
       " 'always want',\n",
       " 'always wanted',\n",
       " 'alyssa',\n",
       " 'amazed',\n",
       " 'amazing',\n",
       " 'amazing beautiful',\n",
       " 'amazing little',\n",
       " 'amazing little girl',\n",
       " 'amazing people',\n",
       " 'amazing person',\n",
       " 'amazingly',\n",
       " 'amazon',\n",
       " 'ambitious',\n",
       " 'ambitious housing',\n",
       " 'ambitious housing association',\n",
       " 'ambulance',\n",
       " 'ambush',\n",
       " 'amen',\n",
       " 'amendment',\n",
       " 'amendment right',\n",
       " 'amendment url',\n",
       " 'amendment url alpolitics',\n",
       " 'amendment youth',\n",
       " 'amendment youth invasion',\n",
       " 'amental',\n",
       " 'amental disease',\n",
       " 'amental disorder',\n",
       " 'amental disorder url',\n",
       " 'america',\n",
       " 'america america',\n",
       " 'america better',\n",
       " 'america first',\n",
       " 'america first maga',\n",
       " 'america first trump',\n",
       " 'america first url',\n",
       " 'america go',\n",
       " 'america go back',\n",
       " 'america god',\n",
       " 'america god bless',\n",
       " 'america great',\n",
       " 'america great america',\n",
       " 'america great keep',\n",
       " 'america great resistance',\n",
       " 'america know',\n",
       " 'america know truth',\n",
       " 'america liberal',\n",
       " 'america like',\n",
       " 'america maga',\n",
       " 'america maybe',\n",
       " 'america url',\n",
       " 'america vote',\n",
       " 'american',\n",
       " 'american care',\n",
       " 'american citizen',\n",
       " 'american conservative',\n",
       " 'american died',\n",
       " 'american dream',\n",
       " 'american flag',\n",
       " 'american liberal',\n",
       " 'american maga',\n",
       " 'american need',\n",
       " 'american people',\n",
       " 'american people know',\n",
       " 'american politics',\n",
       " 'american republic',\n",
       " 'american republic gained',\n",
       " 'american say',\n",
       " 'american sport',\n",
       " 'american stand',\n",
       " 'american thinker',\n",
       " 'american thinker url',\n",
       " 'american ur',\n",
       " 'american ur fake',\n",
       " 'american value',\n",
       " 'american voter',\n",
       " 'american want',\n",
       " 'american worker',\n",
       " 'ammo',\n",
       " 'ammunition',\n",
       " 'amnesia',\n",
       " 'amnesty',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'amount',\n",
       " 'amount money',\n",
       " 'amp',\n",
       " 'amp antifa',\n",
       " 'amp anything',\n",
       " 'amp bill',\n",
       " 'amp blm',\n",
       " 'amp child',\n",
       " 'amp conservative',\n",
       " 'amp democrat',\n",
       " 'amp done',\n",
       " 'amp foresight',\n",
       " 'amp furious',\n",
       " 'amp get',\n",
       " 'amp good',\n",
       " 'amp gun',\n",
       " 'amp gun control',\n",
       " 'amp gun violence',\n",
       " 'amp hatred',\n",
       " 'amp help',\n",
       " 'amp horrible',\n",
       " 'amp illegals',\n",
       " 'amp kag',\n",
       " 'amp kept',\n",
       " 'amp kept home',\n",
       " 'amp know',\n",
       " 'amp leftist',\n",
       " 'amp let',\n",
       " 'amp liberal',\n",
       " 'amp lie',\n",
       " 'amp like',\n",
       " 'amp maga',\n",
       " 'amp make',\n",
       " 'amp many',\n",
       " 'amp msm',\n",
       " 'amp need',\n",
       " 'amp others',\n",
       " 'amp police',\n",
       " 'amp quit',\n",
       " 'amp rd',\n",
       " 'amp see',\n",
       " 'amp still',\n",
       " 'amp support',\n",
       " 'amp supporter',\n",
       " 'amp violence',\n",
       " 'amp vote',\n",
       " 'amp voter',\n",
       " 'amp voter suppression',\n",
       " 'amp want',\n",
       " 'amy',\n",
       " 'amy barrett',\n",
       " 'analysis',\n",
       " 'anarchist',\n",
       " 'anarchist left',\n",
       " 'anarchy',\n",
       " 'ancestor',\n",
       " 'ancient',\n",
       " 'anderson',\n",
       " 'andor',\n",
       " 'andrew',\n",
       " 'android',\n",
       " 'andy',\n",
       " 'angel',\n",
       " 'angel love',\n",
       " 'angela',\n",
       " 'angelina',\n",
       " 'anger',\n",
       " 'angry',\n",
       " 'animal',\n",
       " 'anime',\n",
       " 'anita',\n",
       " 'anita hill',\n",
       " 'anna',\n",
       " 'announce',\n",
       " 'announce new',\n",
       " 'announce new longerterm',\n",
       " 'announced',\n",
       " 'announced extra',\n",
       " 'announced extra bn',\n",
       " 'announcement',\n",
       " 'announces',\n",
       " 'annoying',\n",
       " 'annual',\n",
       " 'annual funding',\n",
       " 'annual funding build',\n",
       " 'anons',\n",
       " 'anonymous',\n",
       " 'anonymous letter',\n",
       " 'another',\n",
       " 'another attempt',\n",
       " 'another country',\n",
       " 'another dem',\n",
       " 'another election',\n",
       " 'another elitist',\n",
       " 'another form',\n",
       " 'another good',\n",
       " 'another illegal',\n",
       " 'another liberal',\n",
       " 'another lie',\n",
       " 'another nail',\n",
       " 'another one',\n",
       " 'another person',\n",
       " 'another reason',\n",
       " 'another referendum',\n",
       " 'another time',\n",
       " 'another way',\n",
       " 'answer',\n",
       " 'answer liberal',\n",
       " 'answer question',\n",
       " 'answer right',\n",
       " 'answer url',\n",
       " 'answered',\n",
       " 'answered question',\n",
       " 'answering',\n",
       " 'answering question',\n",
       " 'ant',\n",
       " 'anthem',\n",
       " 'anthony',\n",
       " 'anthony weiner',\n",
       " 'anti',\n",
       " 'anti abortion',\n",
       " 'anti american',\n",
       " 'anti fa',\n",
       " 'anti fa fascist',\n",
       " 'anti fa thug',\n",
       " 'anti fascist',\n",
       " 'anti semite',\n",
       " 'antiamerican',\n",
       " 'antiantifa',\n",
       " 'antic',\n",
       " 'antideutsch',\n",
       " 'antifa',\n",
       " 'antifa activist',\n",
       " 'antifa activist jail',\n",
       " 'antifa actually',\n",
       " 'antifa already',\n",
       " 'antifa also',\n",
       " 'antifa amp',\n",
       " 'antifa amp blm',\n",
       " 'antifa anarchist',\n",
       " 'antifa anti',\n",
       " 'antifa anti fascist',\n",
       " 'antifa antifascist',\n",
       " 'antifa attack',\n",
       " 'antifa attacking',\n",
       " 'antifa bad',\n",
       " 'antifa banned',\n",
       " 'antifa beat',\n",
       " 'antifa berkeley',\n",
       " 'antifa black',\n",
       " 'antifa black life',\n",
       " 'antifa blm',\n",
       " 'antifa branch',\n",
       " 'antifa brown',\n",
       " 'antifa brown shirt',\n",
       " 'antifa buddy',\n",
       " 'antifa bully',\n",
       " 'antifa called',\n",
       " 'antifa calling',\n",
       " 'antifa caught',\n",
       " 'antifa caught guard',\n",
       " 'antifa college',\n",
       " 'antifa college kid',\n",
       " 'antifa come',\n",
       " 'antifa communist',\n",
       " 'antifa complete',\n",
       " 'antifa comrade',\n",
       " 'antifa crowd',\n",
       " 'antifa democrat',\n",
       " 'antifa democrat dixiecrats',\n",
       " 'antifa domestic',\n",
       " 'antifa domestic terrorist',\n",
       " 'antifa dont',\n",
       " 'antifa dress',\n",
       " 'antifa dress like',\n",
       " 'antifa even',\n",
       " 'antifa far',\n",
       " 'antifa fascist',\n",
       " 'antifa fighting',\n",
       " 'antifa fighting neonazis',\n",
       " 'antifa fit',\n",
       " 'antifa flag',\n",
       " 'antifa get',\n",
       " 'antifa getting',\n",
       " 'antifa girl',\n",
       " 'antifa go',\n",
       " 'antifa going',\n",
       " 'antifa good',\n",
       " 'antifa group',\n",
       " 'antifa guess',\n",
       " 'antifa idiot',\n",
       " 'antifa isnt',\n",
       " 'antifa kid',\n",
       " 'antifa kkk',\n",
       " 'antifa kkk hood',\n",
       " 'antifa know',\n",
       " 'antifa lie',\n",
       " 'antifa like',\n",
       " 'antifa listed',\n",
       " 'antifa lol',\n",
       " 'antifa lover',\n",
       " 'antifa make',\n",
       " 'antifa march',\n",
       " 'antifa mask',\n",
       " 'antifa mean',\n",
       " 'antifa meeting',\n",
       " 'antifa member',\n",
       " 'antifa member pd',\n",
       " 'antifa mob',\n",
       " 'antifa much',\n",
       " 'antifa muslim',\n",
       " 'antifa nazi',\n",
       " 'antifa need',\n",
       " 'antifa never',\n",
       " 'antifa new',\n",
       " 'antifa ninja',\n",
       " 'antifa ninja turtle',\n",
       " 'antifa nothing',\n",
       " 'antifa one',\n",
       " 'antifa organization',\n",
       " 'antifa party',\n",
       " 'antifa peaceful',\n",
       " 'antifa people',\n",
       " 'antifa place',\n",
       " 'antifa professor',\n",
       " 'antifa promise',\n",
       " 'antifa promote',\n",
       " 'antifa protest',\n",
       " 'antifa protestors',\n",
       " 'antifa protestors law',\n",
       " 'antifa punk',\n",
       " 'antifa rally',\n",
       " 'antifa real',\n",
       " 'antifa really',\n",
       " 'antifa riot',\n",
       " 'antifa say',\n",
       " 'antifa scum',\n",
       " 'antifa seems',\n",
       " 'antifa shit',\n",
       " 'antifa something',\n",
       " 'antifa son',\n",
       " 'antifa soy',\n",
       " 'antifa spread',\n",
       " 'antifa stand',\n",
       " 'antifa style',\n",
       " 'antifa style attack',\n",
       " 'antifa super',\n",
       " 'antifa super soldier',\n",
       " 'antifa tactic',\n",
       " 'antifa take',\n",
       " 'antifa target',\n",
       " 'antifa target list',\n",
       " 'antifa tell',\n",
       " 'antifa tell truth',\n",
       " 'antifa terrorist',\n",
       " 'antifa terrorist organization',\n",
       " 'antifa thats',\n",
       " 'antifa though',\n",
       " 'antifa thug',\n",
       " 'antifa time',\n",
       " 'antifa took',\n",
       " 'antifa trump',\n",
       " 'antifa turned',\n",
       " 'antifa twin',\n",
       " 'antifa type',\n",
       " 'antifa u200d',\n",
       " 'antifa url',\n",
       " 'antifa violence',\n",
       " 'antifa violent',\n",
       " 'antifa wannabe',\n",
       " 'antifa want',\n",
       " 'antifa warrior',\n",
       " 'antifa work',\n",
       " 'antifa would',\n",
       " 'antifa yet',\n",
       " 'antifas',\n",
       " 'antifascism',\n",
       " 'antifascist',\n",
       " 'antikavanaugh',\n",
       " 'antisemitic',\n",
       " 'antisemitism',\n",
       " 'antitrump',\n",
       " 'antiwhite',\n",
       " 'antonio',\n",
       " 'anxiety',\n",
       " 'anybody',\n",
       " 'anymore',\n",
       " 'anyone',\n",
       " 'anyone believe',\n",
       " 'anyone brain',\n",
       " 'anyone disagrees',\n",
       " 'anyone else',\n",
       " 'anyone else think',\n",
       " 'anyone expect',\n",
       " 'anyone feel',\n",
       " 'anyone get',\n",
       " 'anyone gun',\n",
       " 'anyone gun control',\n",
       " 'anyone half',\n",
       " 'anyone half brain',\n",
       " 'anyone including',\n",
       " 'anyone isnt',\n",
       " 'anyone surprised',\n",
       " 'anyone want',\n",
       " 'anyones',\n",
       " 'anything',\n",
       " 'anything antifa',\n",
       " 'anything anyone',\n",
       " 'anything except',\n",
       " 'anything get',\n",
       " 'anything gun',\n",
       " 'anything gun control',\n",
       " 'anything know',\n",
       " 'anything le',\n",
       " 'anything say',\n",
       " 'anything trump',\n",
       " 'anytime',\n",
       " 'anyway',\n",
       " 'anyways',\n",
       " 'anywhere',\n",
       " 'ap',\n",
       " 'apart',\n",
       " 'apartment',\n",
       " 'apirate',\n",
       " 'apirate day',\n",
       " 'apologize',\n",
       " 'apologized',\n",
       " 'apologizing',\n",
       " 'apology',\n",
       " 'app',\n",
       " 'appalling',\n",
       " 'apparent',\n",
       " 'apparently',\n",
       " 'appeal',\n",
       " 'appear',\n",
       " 'appearance',\n",
       " 'appeared',\n",
       " 'appearing',\n",
       " 'appears',\n",
       " 'appease',\n",
       " 'appease muslim',\n",
       " 'appease muslim conservative',\n",
       " 'appeasing',\n",
       " 'applauded',\n",
       " 'apple',\n",
       " 'applies',\n",
       " 'apply',\n",
       " 'appoint',\n",
       " 'appointed',\n",
       " 'appointee',\n",
       " 'appointment',\n",
       " 'appreciate',\n",
       " 'appreciated',\n",
       " 'appreciation',\n",
       " 'approach',\n",
       " 'appropriate',\n",
       " 'approve',\n",
       " 'approved',\n",
       " 'approved antifa',\n",
       " 'ar',\n",
       " 'ar fully',\n",
       " 'ar fully semiautomatic',\n",
       " 'ar url',\n",
       " 'arc',\n",
       " 'archetype',\n",
       " 'architect',\n",
       " 'area',\n",
       " 'arent',\n",
       " 'argue',\n",
       " 'arguing',\n",
       " 'arguing gun',\n",
       " 'arguing gun control',\n",
       " 'argument',\n",
       " 'argument considering',\n",
       " 'argument gun',\n",
       " 'argument gun control',\n",
       " 'ariana',\n",
       " 'arizona',\n",
       " 'arm',\n",
       " 'arm democratic',\n",
       " 'arm democratic party',\n",
       " 'arm personally',\n",
       " 'arm personally ownedpossessed',\n",
       " 'arm rifle',\n",
       " 'arm rifle nra',\n",
       " 'arm teacher',\n",
       " 'arm wereare',\n",
       " 'arm wereare regulated',\n",
       " 'armageddon',\n",
       " 'armamenttraining',\n",
       " 'armamenttraining contemporary',\n",
       " 'armamenttraining contemporary military',\n",
       " 'armed',\n",
       " 'armed citizen',\n",
       " 'armed protection',\n",
       " 'armed protection gun',\n",
       " 'arming',\n",
       " 'armor',\n",
       " 'army',\n",
       " 'army great',\n",
       " 'army great awakening',\n",
       " 'army url',\n",
       " 'arnold',\n",
       " 'around',\n",
       " 'around acting',\n",
       " 'around acting like',\n",
       " 'around conservative',\n",
       " 'around gun',\n",
       " 'around liberal',\n",
       " 'around world',\n",
       " 'arrest',\n",
       " 'arrested',\n",
       " 'arrived',\n",
       " 'arrogance',\n",
       " 'arrogant',\n",
       " 'art',\n",
       " 'article',\n",
       " 'article sec',\n",
       " 'article sec constitution',\n",
       " 'artist',\n",
       " 'as',\n",
       " 'as bitch',\n",
       " 'as boy',\n",
       " 'as good',\n",
       " 'as look',\n",
       " 'as maga',\n",
       " 'as nigga',\n",
       " 'as one',\n",
       " 'as people',\n",
       " 'as serious',\n",
       " 'as shit',\n",
       " 'as sister',\n",
       " 'as url',\n",
       " 'as would',\n",
       " 'asap',\n",
       " 'ash',\n",
       " 'ashamed',\n",
       " 'asia',\n",
       " 'asian',\n",
       " 'asian country',\n",
       " 'aside',\n",
       " 'asinine',\n",
       " 'ask',\n",
       " 'ask ally',\n",
       " 'ask antifa',\n",
       " 'ask could',\n",
       " 'ask gun',\n",
       " 'ask gun control',\n",
       " 'ask help',\n",
       " 'ask know',\n",
       " 'ask liberal',\n",
       " 'ask question',\n",
       " 'ask supporting',\n",
       " 'asked',\n",
       " 'asked question',\n",
       " 'asking',\n",
       " 'asking friend',\n",
       " 'asking liberal',\n",
       " 'asking probing',\n",
       " 'asking probing question',\n",
       " 'asking question',\n",
       " 'asks',\n",
       " 'asleep',\n",
       " 'aspect',\n",
       " 'aspect life',\n",
       " 'ass',\n",
       " 'assassinate',\n",
       " 'assassination',\n",
       " 'assault',\n",
       " 'assault claim',\n",
       " 'assault rape',\n",
       " 'assault rifle',\n",
       " 'assault weapon',\n",
       " 'assaulted',\n",
       " 'assaulted antifa',\n",
       " 'assaulting',\n",
       " 'assembly',\n",
       " 'asset',\n",
       " 'asshole',\n",
       " 'assignment',\n",
       " 'assist',\n",
       " 'associate',\n",
       " 'associate antifa',\n",
       " 'associated',\n",
       " 'association',\n",
       " 'association groundbreaking',\n",
       " 'association groundbreaking billion',\n",
       " 'assume',\n",
       " 'assume master',\n",
       " 'assume telling',\n",
       " 'assumed',\n",
       " 'assumes',\n",
       " 'assuming',\n",
       " 'assumption',\n",
       " 'assure',\n",
       " 'astand',\n",
       " 'astonishing',\n",
       " 'ate',\n",
       " 'atheist',\n",
       " 'athlete',\n",
       " 'atlanta',\n",
       " 'atlantic',\n",
       " 'atleast',\n",
       " 'atmosphere',\n",
       " 'attack',\n",
       " 'attack conservative',\n",
       " 'attack liberal',\n",
       " 'attack people',\n",
       " 'attacked',\n",
       " 'attacked antifa',\n",
       " 'attacker',\n",
       " 'attacking',\n",
       " 'attacking trump',\n",
       " 'attempt',\n",
       " 'attempt get',\n",
       " 'attempted',\n",
       " 'attempted rape',\n",
       " 'attempting',\n",
       " 'attend',\n",
       " 'attending',\n",
       " 'attention',\n",
       " 'attention gun',\n",
       " 'attention gun control',\n",
       " 'attention publicizing',\n",
       " 'attention publicizing antifa',\n",
       " 'attention publishing',\n",
       " 'attitude',\n",
       " 'attorney',\n",
       " 'attorney general',\n",
       " 'attracted',\n",
       " 'audience',\n",
       " 'august',\n",
       " 'aunt',\n",
       " 'aur',\n",
       " 'auspol',\n",
       " 'austerity',\n",
       " 'austin',\n",
       " 'australia',\n",
       " 'australia gun',\n",
       " 'australian',\n",
       " 'author',\n",
       " 'authoritarian',\n",
       " 'authoritarianism',\n",
       " 'authority',\n",
       " 'auto',\n",
       " 'automatic',\n",
       " 'automatically',\n",
       " 'autumn',\n",
       " 'available',\n",
       " 'available blocktogether',\n",
       " 'available blocktogether list',\n",
       " 'avenatti',\n",
       " 'average',\n",
       " 'average american',\n",
       " 'avi',\n",
       " 'avoid',\n",
       " 'aw',\n",
       " 'awake',\n",
       " 'awakening',\n",
       " 'awakening drain',\n",
       " 'awakening drain swamp',\n",
       " 'awakening jesuslives',\n",
       " 'awakening jesuslives catch',\n",
       " 'awakening maga',\n",
       " 'awakening qanon',\n",
       " 'awakening storm',\n",
       " 'award',\n",
       " 'award show',\n",
       " ...]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_gram.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "aging-wesley",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<9930x14922 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 117844 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vect = vect_gram.transform(X_train)\n",
    "\n",
    "X_train_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "boring-manitoba",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_gram = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "brazilian-eight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.05: 0.7462235649546828,\n",
       " 0.1: 0.7570996978851964,\n",
       " 0.15000000000000002: 0.7616314199395771,\n",
       " 0.2: 0.7646525679758308,\n",
       " 0.25: 0.7649546827794562,\n",
       " 0.30000000000000004: 0.7649546827794562,\n",
       " 0.35000000000000003: 0.7661631419939577,\n",
       " 0.4: 0.7658610271903323,\n",
       " 0.45: 0.7658610271903323,\n",
       " 0.5: 0.7652567975830815,\n",
       " 0.55: 0.7643504531722054,\n",
       " 0.6000000000000001: 0.7628398791540786,\n",
       " 0.65: 0.7625377643504532,\n",
       " 0.7000000000000001: 0.7616314199395771,\n",
       " 0.75: 0.7622356495468278,\n",
       " 0.8: 0.7613293051359517,\n",
       " 0.8500000000000001: 0.7619335347432025,\n",
       " 0.9: 0.760725075528701,\n",
       " 0.9500000000000001: 0.759214501510574}"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in C:\n",
    "    clf = LogisticRegression(C= i, max_iter=1000)\n",
    "    clf.fit(X_train_vect, y_train)\n",
    "    scores_gram[i] = clf.score(vect_gram.transform(X_test), y_test)\n",
    "    \n",
    "scores_gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "certified-conversation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30000000000000004\n"
     ]
    }
   ],
   "source": [
    "best_C_gram = max(scores_gram, key=scores.get)\n",
    "\n",
    "print(best_C_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "wanted-jordan",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(C= 0.3, max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "armed-entertainment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.3, max_iter=1000)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "sustainable-grammar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7649546827794562"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(vect_gram.transform(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "indian-police",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array(vect_gram.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "accomplished-proof",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = clf.coef_[0].argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "powerful-renaissance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coefs \n",
      "['thank' 'justice' 'best' 'lead' 'action' 'brexit' 'welcome' 'nike'\n",
      " 'accuser' 'company']\n",
      "Largest Coefs \n",
      "['nigga' 'suck' 'liar' 'disgusting' 'as' 'idiot' 'fucking' 'stupid'\n",
      " 'bitch' 'shit']\n"
     ]
    }
   ],
   "source": [
    "print(\"Smallest Coefs \\n{}\".format(features[coefs[:10]]))\n",
    "print(\"Largest Coefs \\n{}\".format(features[coefs[-11:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approved-affiliate",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
