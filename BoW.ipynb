{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adolescent-charter",
   "metadata": {},
   "source": [
    "# Bag Of Words Model\n",
    "\n",
    "Uses one-hot encoding to count number of occurences of a word in a given document. Disadvantage is that most words are not repeated in every document leading to a sparse matrix and also does not take into account the structure of a sentence, i.e., the order of words or semantics.\n",
    "\n",
    "\"Not bad, working good\" and \"Not good, working bad\" would be treated as the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "superb-tournament",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "given-composition",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"processed_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cloudy-allergy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>subtask_b</th>\n",
       "      <th>subtask_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>86426</td>\n",
       "      <td>['ask', 'native', 'american', 'take']</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>90194</td>\n",
       "      <td>['go', 'home', '’', 'drunk', 'maga', 'trump', ...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>16820</td>\n",
       "      <td>['amazon', 'investigating', 'chinese', 'employ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>62688</td>\n",
       "      <td>['someone', 'shouldve', 'taken', 'piece', 'shi...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>43605</td>\n",
       "      <td>['obama', 'wanted', 'liberal', 'amp', 'illegal...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13235</th>\n",
       "      <td>13235</td>\n",
       "      <td>95338</td>\n",
       "      <td>['sometimes', 'get', 'strong', 'vibe', 'people...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13236</th>\n",
       "      <td>13236</td>\n",
       "      <td>67210</td>\n",
       "      <td>['benidorm', '✅', 'creamfields', '✅', 'maga', ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13237</th>\n",
       "      <td>13237</td>\n",
       "      <td>82921</td>\n",
       "      <td>['report', 'garbage', 'dont', 'give', 'crap']</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>OTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13238</th>\n",
       "      <td>13238</td>\n",
       "      <td>27429</td>\n",
       "      <td>['pussy']</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13239</th>\n",
       "      <td>13239</td>\n",
       "      <td>46552</td>\n",
       "      <td>['spanishrevenge', 'v', 'justice', 'human', 'r...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13240 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0     id                                              tweet  \\\n",
       "0               0  86426              ['ask', 'native', 'american', 'take']   \n",
       "1               1  90194  ['go', 'home', '’', 'drunk', 'maga', 'trump', ...   \n",
       "2               2  16820  ['amazon', 'investigating', 'chinese', 'employ...   \n",
       "3               3  62688  ['someone', 'shouldve', 'taken', 'piece', 'shi...   \n",
       "4               4  43605  ['obama', 'wanted', 'liberal', 'amp', 'illegal...   \n",
       "...           ...    ...                                                ...   \n",
       "13235       13235  95338  ['sometimes', 'get', 'strong', 'vibe', 'people...   \n",
       "13236       13236  67210  ['benidorm', '✅', 'creamfields', '✅', 'maga', ...   \n",
       "13237       13237  82921      ['report', 'garbage', 'dont', 'give', 'crap']   \n",
       "13238       13238  27429                                          ['pussy']   \n",
       "13239       13239  46552  ['spanishrevenge', 'v', 'justice', 'human', 'r...   \n",
       "\n",
       "      subtask_a subtask_b subtask_c  \n",
       "0           OFF       UNT       NaN  \n",
       "1           OFF       TIN       IND  \n",
       "2           NOT       NaN       NaN  \n",
       "3           OFF       UNT       NaN  \n",
       "4           NOT       NaN       NaN  \n",
       "...         ...       ...       ...  \n",
       "13235       OFF       TIN       IND  \n",
       "13236       NOT       NaN       NaN  \n",
       "13237       OFF       TIN       OTH  \n",
       "13238       OFF       UNT       NaN  \n",
       "13239       NOT       NaN       NaN  \n",
       "\n",
       "[13240 rows x 6 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "canadian-bones",
   "metadata": {},
   "source": [
    "### Removing redundant axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "reverse-stopping",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "final-lounge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>subtask_b</th>\n",
       "      <th>subtask_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86426</td>\n",
       "      <td>['ask', 'native', 'american', 'take']</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90194</td>\n",
       "      <td>['go', 'home', '’', 'drunk', 'maga', 'trump', ...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16820</td>\n",
       "      <td>['amazon', 'investigating', 'chinese', 'employ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62688</td>\n",
       "      <td>['someone', 'shouldve', 'taken', 'piece', 'shi...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43605</td>\n",
       "      <td>['obama', 'wanted', 'liberal', 'amp', 'illegal...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13235</th>\n",
       "      <td>95338</td>\n",
       "      <td>['sometimes', 'get', 'strong', 'vibe', 'people...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13236</th>\n",
       "      <td>67210</td>\n",
       "      <td>['benidorm', '✅', 'creamfields', '✅', 'maga', ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13237</th>\n",
       "      <td>82921</td>\n",
       "      <td>['report', 'garbage', 'dont', 'give', 'crap']</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>OTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13238</th>\n",
       "      <td>27429</td>\n",
       "      <td>['pussy']</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13239</th>\n",
       "      <td>46552</td>\n",
       "      <td>['spanishrevenge', 'v', 'justice', 'human', 'r...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13240 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              tweet subtask_a  \\\n",
       "0      86426              ['ask', 'native', 'american', 'take']       OFF   \n",
       "1      90194  ['go', 'home', '’', 'drunk', 'maga', 'trump', ...       OFF   \n",
       "2      16820  ['amazon', 'investigating', 'chinese', 'employ...       NOT   \n",
       "3      62688  ['someone', 'shouldve', 'taken', 'piece', 'shi...       OFF   \n",
       "4      43605  ['obama', 'wanted', 'liberal', 'amp', 'illegal...       NOT   \n",
       "...      ...                                                ...       ...   \n",
       "13235  95338  ['sometimes', 'get', 'strong', 'vibe', 'people...       OFF   \n",
       "13236  67210  ['benidorm', '✅', 'creamfields', '✅', 'maga', ...       NOT   \n",
       "13237  82921      ['report', 'garbage', 'dont', 'give', 'crap']       OFF   \n",
       "13238  27429                                          ['pussy']       OFF   \n",
       "13239  46552  ['spanishrevenge', 'v', 'justice', 'human', 'r...       NOT   \n",
       "\n",
       "      subtask_b subtask_c  \n",
       "0           UNT       NaN  \n",
       "1           TIN       IND  \n",
       "2           NaN       NaN  \n",
       "3           UNT       NaN  \n",
       "4           NaN       NaN  \n",
       "...         ...       ...  \n",
       "13235       TIN       IND  \n",
       "13236       NaN       NaN  \n",
       "13237       TIN       OTH  \n",
       "13238       UNT       NaN  \n",
       "13239       NaN       NaN  \n",
       "\n",
       "[13240 rows x 5 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powered-isaac",
   "metadata": {},
   "source": [
    "### Removing Unnecessary Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "designed-repair",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"subtask_b\", \"subtask_c\", \"id\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "exterior-snake",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['ask', 'native', 'american', 'take']</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['go', 'home', '’', 'drunk', 'maga', 'trump', ...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['amazon', 'investigating', 'chinese', 'employ...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['someone', 'shouldve', 'taken', 'piece', 'shi...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['obama', 'wanted', 'liberal', 'amp', 'illegal...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13235</th>\n",
       "      <td>['sometimes', 'get', 'strong', 'vibe', 'people...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13236</th>\n",
       "      <td>['benidorm', '✅', 'creamfields', '✅', 'maga', ...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13237</th>\n",
       "      <td>['report', 'garbage', 'dont', 'give', 'crap']</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13238</th>\n",
       "      <td>['pussy']</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13239</th>\n",
       "      <td>['spanishrevenge', 'v', 'justice', 'human', 'r...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13240 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet subtask_a\n",
       "0                  ['ask', 'native', 'american', 'take']       OFF\n",
       "1      ['go', 'home', '’', 'drunk', 'maga', 'trump', ...       OFF\n",
       "2      ['amazon', 'investigating', 'chinese', 'employ...       NOT\n",
       "3      ['someone', 'shouldve', 'taken', 'piece', 'shi...       OFF\n",
       "4      ['obama', 'wanted', 'liberal', 'amp', 'illegal...       NOT\n",
       "...                                                  ...       ...\n",
       "13235  ['sometimes', 'get', 'strong', 'vibe', 'people...       OFF\n",
       "13236  ['benidorm', '✅', 'creamfields', '✅', 'maga', ...       NOT\n",
       "13237      ['report', 'garbage', 'dont', 'give', 'crap']       OFF\n",
       "13238                                          ['pussy']       OFF\n",
       "13239  ['spanishrevenge', 'v', 'justice', 'human', 'r...       NOT\n",
       "\n",
       "[13240 rows x 2 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adverse-offset",
   "metadata": {},
   "source": [
    "### Renaming Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "acute-frost",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"subtask_a\": \"Offensive\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "unknown-biology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>Offensive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['ask', 'native', 'american', 'take']</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['go', 'home', '’', 'drunk', 'maga', 'trump', ...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['amazon', 'investigating', 'chinese', 'employ...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['someone', 'shouldve', 'taken', 'piece', 'shi...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['obama', 'wanted', 'liberal', 'amp', 'illegal...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13235</th>\n",
       "      <td>['sometimes', 'get', 'strong', 'vibe', 'people...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13236</th>\n",
       "      <td>['benidorm', '✅', 'creamfields', '✅', 'maga', ...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13237</th>\n",
       "      <td>['report', 'garbage', 'dont', 'give', 'crap']</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13238</th>\n",
       "      <td>['pussy']</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13239</th>\n",
       "      <td>['spanishrevenge', 'v', 'justice', 'human', 'r...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13240 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet Offensive\n",
       "0                  ['ask', 'native', 'american', 'take']       OFF\n",
       "1      ['go', 'home', '’', 'drunk', 'maga', 'trump', ...       OFF\n",
       "2      ['amazon', 'investigating', 'chinese', 'employ...       NOT\n",
       "3      ['someone', 'shouldve', 'taken', 'piece', 'shi...       OFF\n",
       "4      ['obama', 'wanted', 'liberal', 'amp', 'illegal...       NOT\n",
       "...                                                  ...       ...\n",
       "13235  ['sometimes', 'get', 'strong', 'vibe', 'people...       OFF\n",
       "13236  ['benidorm', '✅', 'creamfields', '✅', 'maga', ...       NOT\n",
       "13237      ['report', 'garbage', 'dont', 'give', 'crap']       OFF\n",
       "13238                                          ['pussy']       OFF\n",
       "13239  ['spanishrevenge', 'v', 'justice', 'human', 'r...       NOT\n",
       "\n",
       "[13240 rows x 2 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "golden-swing",
   "metadata": {},
   "source": [
    "### Replacing Class with Numeric Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "female-religion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def repl(off):\n",
    "    if off == 'OFF':\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "pregnant-girlfriend",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Offensive'] = df['Offensive'].apply(repl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "assured-surveillance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>Offensive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['ask', 'native', 'american', 'take']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['go', 'home', '’', 'drunk', 'maga', 'trump', ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['amazon', 'investigating', 'chinese', 'employ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['someone', 'shouldve', 'taken', 'piece', 'shi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['obama', 'wanted', 'liberal', 'amp', 'illegal...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13235</th>\n",
       "      <td>['sometimes', 'get', 'strong', 'vibe', 'people...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13236</th>\n",
       "      <td>['benidorm', '✅', 'creamfields', '✅', 'maga', ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13237</th>\n",
       "      <td>['report', 'garbage', 'dont', 'give', 'crap']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13238</th>\n",
       "      <td>['pussy']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13239</th>\n",
       "      <td>['spanishrevenge', 'v', 'justice', 'human', 'r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13240 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet  Offensive\n",
       "0                  ['ask', 'native', 'american', 'take']          1\n",
       "1      ['go', 'home', '’', 'drunk', 'maga', 'trump', ...          1\n",
       "2      ['amazon', 'investigating', 'chinese', 'employ...          0\n",
       "3      ['someone', 'shouldve', 'taken', 'piece', 'shi...          1\n",
       "4      ['obama', 'wanted', 'liberal', 'amp', 'illegal...          0\n",
       "...                                                  ...        ...\n",
       "13235  ['sometimes', 'get', 'strong', 'vibe', 'people...          1\n",
       "13236  ['benidorm', '✅', 'creamfields', '✅', 'maga', ...          0\n",
       "13237      ['report', 'garbage', 'dont', 'give', 'crap']          1\n",
       "13238                                          ['pussy']          1\n",
       "13239  ['spanishrevenge', 'v', 'justice', 'human', 'r...          0\n",
       "\n",
       "[13240 rows x 2 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "automotive-december",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    ['ask', 'native', 'american', 'take']\n",
       "1        ['go', 'home', '’', 'drunk', 'maga', 'trump', ...\n",
       "2        ['amazon', 'investigating', 'chinese', 'employ...\n",
       "3        ['someone', 'shouldve', 'taken', 'piece', 'shi...\n",
       "4        ['obama', 'wanted', 'liberal', 'amp', 'illegal...\n",
       "                               ...                        \n",
       "13235    ['sometimes', 'get', 'strong', 'vibe', 'people...\n",
       "13236    ['benidorm', '✅', 'creamfields', '✅', 'maga', ...\n",
       "13237        ['report', 'garbage', 'dont', 'give', 'crap']\n",
       "13238                                            ['pussy']\n",
       "13239    ['spanishrevenge', 'v', 'justice', 'human', 'r...\n",
       "Name: tweet, Length: 13240, dtype: object"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acceptable-learning",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "sweet-drink",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['tweet'], df['Offensive'], stratify=df['Offensive'], shuffle=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "surprised-profession",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10485    ['chicago', 'record', 'number', 'homicide', 'g...\n",
       "227      ['aha', 'yes', 'see', 'individual', 'sense', '...\n",
       "446      ['yeah', 'think', 'saying', 'addiction', 'life...\n",
       "4830     ['antikavanaugh', 'group', 'already', 'spinnin...\n",
       "6141     ['hope', 'theyre', 'brushed', 'large', 'negati...\n",
       "                               ...                        \n",
       "8265               ['like', 'boob', 'mass', 'belly', 'xd']\n",
       "4815     ['civilian', 'also', 'ill', 'admit', 'hard', '...\n",
       "12445    ['good', 'thats', 'fine', 'gun', 'control', 'd...\n",
       "11772                       ['oh', 'shit', 'stay', 'safe']\n",
       "5486     ['twitter', 'social', 'medium', 'seems', 'make...\n",
       "Name: tweet, Length: 9930, dtype: object"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "common-jaguar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10485    1\n",
       "227      0\n",
       "446      0\n",
       "4830     0\n",
       "6141     1\n",
       "        ..\n",
       "8265     1\n",
       "4815     0\n",
       "12445    1\n",
       "11772    0\n",
       "5486     0\n",
       "Name: Offensive, Length: 9930, dtype: int64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proved-machine",
   "metadata": {},
   "source": [
    "## BoW Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "instant-tennessee",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(lowercase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "persistent-position",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = vect.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "arranged-frequency",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14572"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "accomplished-enemy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<9930x14572 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 99161 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vect = vect.transform(X_train)\n",
    "\n",
    "X_train_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "crucial-apparatus",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "published-brand",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.05,\n",
       " 0.1,\n",
       " 0.15000000000000002,\n",
       " 0.2,\n",
       " 0.25,\n",
       " 0.30000000000000004,\n",
       " 0.35000000000000003,\n",
       " 0.4,\n",
       " 0.45,\n",
       " 0.5,\n",
       " 0.55,\n",
       " 0.6000000000000001,\n",
       " 0.65,\n",
       " 0.7000000000000001,\n",
       " 0.75,\n",
       " 0.8,\n",
       " 0.8500000000000001,\n",
       " 0.9,\n",
       " 0.9500000000000001]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = list(np.arange(0, 1, 0.05))\n",
    "\n",
    "C = [float(i) for i in C]\n",
    "\n",
    "C = C[1:]\n",
    "\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "mineral-lodge",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "liable-exclusive",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.05: 0.7477341389728097,\n",
       " 0.1: 0.7595166163141994,\n",
       " 0.15000000000000002: 0.7601208459214501,\n",
       " 0.2: 0.7640483383685801,\n",
       " 0.25: 0.766465256797583,\n",
       " 0.30000000000000004: 0.7673716012084593,\n",
       " 0.35000000000000003: 0.7655589123867069,\n",
       " 0.4: 0.7661631419939577,\n",
       " 0.45: 0.7637462235649547,\n",
       " 0.5: 0.7631419939577039,\n",
       " 0.55: 0.7637462235649547,\n",
       " 0.6000000000000001: 0.7646525679758308,\n",
       " 0.65: 0.7652567975830815,\n",
       " 0.7000000000000001: 0.7655589123867069,\n",
       " 0.75: 0.7673716012084593,\n",
       " 0.8: 0.7661631419939577,\n",
       " 0.8500000000000001: 0.766465256797583,\n",
       " 0.9: 0.766465256797583,\n",
       " 0.9500000000000001: 0.7658610271903323}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in C:\n",
    "    clf = LogisticRegression(C= i, max_iter=1000)\n",
    "    clf.fit(X_train_vect, y_train)\n",
    "    scores[i] = clf.score(vect.transform(X_test), y_test)\n",
    "    \n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "indoor-germany",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30000000000000004\n"
     ]
    }
   ],
   "source": [
    "best_C = max(scores, key=scores.get)\n",
    "\n",
    "print(best_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "dental-beast",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(C= 0.3, max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "super-shoot",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.3, max_iter=1000)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "expanded-design",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7673716012084593"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(vect.transform(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "collected-premium",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "missing-cornwall",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = clf.coef_[0].argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "early-delicious",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coefs \n",
      "['thank' 'justice' 'lead' 'best' 'brexit' 'welcome' 'nike' 'action'\n",
      " 'accuser' 'company']\n",
      "Largest Coefs \n",
      "['nigga' 'suck' 'disgusting' 'liar' 'as' 'idiot' 'fucking' 'stupid'\n",
      " 'bitch' 'shit']\n"
     ]
    }
   ],
   "source": [
    "print(\"Smallest Coefs \\n{}\".format(features[coefs[:10]]))\n",
    "print(\"Largest Coefs \\n{}\".format(features[coefs[-11:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "light-scholarship",
   "metadata": {},
   "source": [
    "## BoW with Bigrams and Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "residential-hartford",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_gram = CountVectorizer(lowercase=False, ngram_range=(1, 3), min_df=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "superb-silly",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_gram = vect_gram.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "literary-tennessee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3918"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vect_gram.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "comprehensive-klein",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ab',\n",
       " 'abiding',\n",
       " 'abiding citizen',\n",
       " 'ability',\n",
       " 'able',\n",
       " 'abortion',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absolutely right',\n",
       " 'absurd',\n",
       " 'abuse',\n",
       " 'abused',\n",
       " 'abuser',\n",
       " 'abusive',\n",
       " 'accept',\n",
       " 'accepting',\n",
       " 'access',\n",
       " 'accident',\n",
       " 'accomplished',\n",
       " 'accomplishment',\n",
       " 'according',\n",
       " 'account',\n",
       " 'accountable',\n",
       " 'accusation',\n",
       " 'accuse',\n",
       " 'accused',\n",
       " 'accuser',\n",
       " 'accusing',\n",
       " 'acknowledge',\n",
       " 'across',\n",
       " 'act',\n",
       " 'act like',\n",
       " 'acting',\n",
       " 'acting like',\n",
       " 'action',\n",
       " 'active',\n",
       " 'actively',\n",
       " 'activist',\n",
       " 'activity',\n",
       " 'actor',\n",
       " 'actress',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'ad',\n",
       " 'add',\n",
       " 'address',\n",
       " 'administration',\n",
       " 'admire',\n",
       " 'admit',\n",
       " 'admitted',\n",
       " 'adorable',\n",
       " 'adult',\n",
       " 'advance',\n",
       " 'advantage',\n",
       " 'advice',\n",
       " 'advocate',\n",
       " 'advocating',\n",
       " 'af',\n",
       " 'affair',\n",
       " 'affect',\n",
       " 'afford',\n",
       " 'affordable',\n",
       " 'afraid',\n",
       " 'african',\n",
       " 'ag',\n",
       " 'age',\n",
       " 'agency',\n",
       " 'agenda',\n",
       " 'agent',\n",
       " 'aggressive',\n",
       " 'ago',\n",
       " 'agree',\n",
       " 'agreed',\n",
       " 'ah',\n",
       " 'ahead',\n",
       " 'ahhh',\n",
       " 'aim',\n",
       " 'aint',\n",
       " 'air',\n",
       " 'aka',\n",
       " 'al',\n",
       " 'alert',\n",
       " 'alex',\n",
       " 'alex jones',\n",
       " 'alien',\n",
       " 'alive',\n",
       " 'allegation',\n",
       " 'alleged',\n",
       " 'alleslev',\n",
       " 'allow',\n",
       " 'allowed',\n",
       " 'allowing',\n",
       " 'allows',\n",
       " 'ally',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'already',\n",
       " 'already know',\n",
       " 'alright',\n",
       " 'also',\n",
       " 'alt',\n",
       " 'alt right',\n",
       " 'alternative',\n",
       " 'altright',\n",
       " 'always',\n",
       " 'always get',\n",
       " 'amazing',\n",
       " 'ambitious',\n",
       " 'amendment',\n",
       " 'amental',\n",
       " 'america',\n",
       " 'america first',\n",
       " 'america first maga',\n",
       " 'america great',\n",
       " 'america maga',\n",
       " 'america url',\n",
       " 'american',\n",
       " 'american citizen',\n",
       " 'american people',\n",
       " 'among',\n",
       " 'amount',\n",
       " 'amp',\n",
       " 'amp antifa',\n",
       " 'amp conservative',\n",
       " 'amp gun',\n",
       " 'amp liberal',\n",
       " 'amy',\n",
       " 'anarchist',\n",
       " 'andrew',\n",
       " 'angel',\n",
       " 'anger',\n",
       " 'angry',\n",
       " 'animal',\n",
       " 'anime',\n",
       " 'announced',\n",
       " 'announcement',\n",
       " 'anonymous',\n",
       " 'another',\n",
       " 'another one',\n",
       " 'answer',\n",
       " 'answer question',\n",
       " 'answer url',\n",
       " 'answered',\n",
       " 'anthony',\n",
       " 'anti',\n",
       " 'anti american',\n",
       " 'anti fa',\n",
       " 'anti fascist',\n",
       " 'antiamerican',\n",
       " 'antifa',\n",
       " 'antifa amp',\n",
       " 'antifa black',\n",
       " 'antifa blm',\n",
       " 'antifa democrat',\n",
       " 'antifa get',\n",
       " 'antifa go',\n",
       " 'antifa group',\n",
       " 'antifa kkk',\n",
       " 'antifa kkk hood',\n",
       " 'antifa member',\n",
       " 'antifa one',\n",
       " 'antifa protestors',\n",
       " 'antifa target',\n",
       " 'antifa target list',\n",
       " 'antifa terrorist',\n",
       " 'antifa terrorist organization',\n",
       " 'antifa thug',\n",
       " 'antifa type',\n",
       " 'antifa url',\n",
       " 'antifa violence',\n",
       " 'antifa would',\n",
       " 'antifascist',\n",
       " 'antisemitism',\n",
       " 'antitrump',\n",
       " 'anxiety',\n",
       " 'anybody',\n",
       " 'anymore',\n",
       " 'anyone',\n",
       " 'anyone else',\n",
       " 'anything',\n",
       " 'anyway',\n",
       " 'anyways',\n",
       " 'anywhere',\n",
       " 'apart',\n",
       " 'apologize',\n",
       " 'apology',\n",
       " 'apparently',\n",
       " 'appear',\n",
       " 'appears',\n",
       " 'apple',\n",
       " 'apply',\n",
       " 'appointment',\n",
       " 'appreciate',\n",
       " 'approach',\n",
       " 'approve',\n",
       " 'approved',\n",
       " 'ar',\n",
       " 'area',\n",
       " 'arent',\n",
       " 'argue',\n",
       " 'arguing',\n",
       " 'argument',\n",
       " 'argument gun',\n",
       " 'argument gun control',\n",
       " 'arm',\n",
       " 'armed',\n",
       " 'army',\n",
       " 'around',\n",
       " 'around world',\n",
       " 'arrest',\n",
       " 'arrested',\n",
       " 'art',\n",
       " 'article',\n",
       " 'article sec',\n",
       " 'artist',\n",
       " 'as',\n",
       " 'asap',\n",
       " 'ashamed',\n",
       " 'asian',\n",
       " 'aside',\n",
       " 'ask',\n",
       " 'asked',\n",
       " 'asking',\n",
       " 'aspect',\n",
       " 'ass',\n",
       " 'assassination',\n",
       " 'assault',\n",
       " 'assault rifle',\n",
       " 'assault weapon',\n",
       " 'assaulted',\n",
       " 'asset',\n",
       " 'asshole',\n",
       " 'associated',\n",
       " 'association',\n",
       " 'assume',\n",
       " 'assuming',\n",
       " 'ate',\n",
       " 'athlete',\n",
       " 'attack',\n",
       " 'attacked',\n",
       " 'attacking',\n",
       " 'attempt',\n",
       " 'attempted',\n",
       " 'attempting',\n",
       " 'attention',\n",
       " 'attention publicizing',\n",
       " 'attitude',\n",
       " 'attorney',\n",
       " 'audience',\n",
       " 'aunt',\n",
       " 'austerity',\n",
       " 'australia',\n",
       " 'australian',\n",
       " 'authoritarian',\n",
       " 'authority',\n",
       " 'available',\n",
       " 'average',\n",
       " 'awake',\n",
       " 'awakening',\n",
       " 'award',\n",
       " 'aware',\n",
       " 'away',\n",
       " 'away democrat',\n",
       " 'away right',\n",
       " 'away url',\n",
       " 'awe',\n",
       " 'awesome',\n",
       " 'awful',\n",
       " 'awww',\n",
       " 'babe',\n",
       " 'baby',\n",
       " 'back',\n",
       " 'back maga',\n",
       " 'backed',\n",
       " 'background',\n",
       " 'background check',\n",
       " 'backing',\n",
       " 'bad',\n",
       " 'bad bitch',\n",
       " 'bad guy',\n",
       " 'badly',\n",
       " 'bag',\n",
       " 'balance',\n",
       " 'bald',\n",
       " 'ball',\n",
       " 'ballot',\n",
       " 'ban',\n",
       " 'ban gun',\n",
       " 'band',\n",
       " 'bank',\n",
       " 'banned',\n",
       " 'banning',\n",
       " 'bar',\n",
       " 'barry',\n",
       " 'base',\n",
       " 'baseball',\n",
       " 'based',\n",
       " 'basement',\n",
       " 'bash',\n",
       " 'bashing',\n",
       " 'basic',\n",
       " 'basically',\n",
       " 'basically saying',\n",
       " 'basis',\n",
       " 'bastard',\n",
       " 'bat',\n",
       " 'bathroom',\n",
       " 'battle',\n",
       " 'bb',\n",
       " 'bbc',\n",
       " 'bc',\n",
       " 'bear',\n",
       " 'beast',\n",
       " 'beat',\n",
       " 'beating',\n",
       " 'beating stranger',\n",
       " 'beating stranger know',\n",
       " 'beautiful',\n",
       " 'beauty',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'becoming',\n",
       " 'bed',\n",
       " 'begging',\n",
       " 'begin',\n",
       " 'beginning',\n",
       " 'behalf',\n",
       " 'behavior',\n",
       " 'behaviour',\n",
       " 'behind',\n",
       " 'being',\n",
       " 'belief',\n",
       " 'believe',\n",
       " 'believe gun',\n",
       " 'believe gun control',\n",
       " 'believe woman',\n",
       " 'believed',\n",
       " 'believing',\n",
       " 'bell',\n",
       " 'belong',\n",
       " 'belongs',\n",
       " 'ben',\n",
       " 'benefit',\n",
       " 'berkeley',\n",
       " 'bernie',\n",
       " 'bernier',\n",
       " 'besides',\n",
       " 'best',\n",
       " 'bet',\n",
       " 'beta',\n",
       " 'beto',\n",
       " 'better',\n",
       " 'better gun',\n",
       " 'better gun control',\n",
       " 'beyond',\n",
       " 'bias',\n",
       " 'biased',\n",
       " 'bible',\n",
       " 'biden',\n",
       " 'big',\n",
       " 'bigger',\n",
       " 'biggest',\n",
       " 'bigot',\n",
       " 'bigotry',\n",
       " 'bill',\n",
       " 'bill clinton',\n",
       " 'billion',\n",
       " 'billionaire',\n",
       " 'billy',\n",
       " 'bird',\n",
       " 'birth',\n",
       " 'birthday',\n",
       " 'bit',\n",
       " 'bitch',\n",
       " 'bitch lol',\n",
       " 'bite',\n",
       " 'bitter',\n",
       " 'black',\n",
       " 'black conservative',\n",
       " 'black life',\n",
       " 'black life matter',\n",
       " 'black men',\n",
       " 'black panther',\n",
       " 'black people',\n",
       " 'blame',\n",
       " 'blame gun',\n",
       " 'blame gun control',\n",
       " 'blaming',\n",
       " 'blanket',\n",
       " 'blasey',\n",
       " 'blasey ford',\n",
       " 'blatant',\n",
       " 'bless',\n",
       " 'blessed',\n",
       " 'blessing',\n",
       " 'blind',\n",
       " 'blm',\n",
       " 'block',\n",
       " 'blocked',\n",
       " 'blocking',\n",
       " 'blog',\n",
       " 'blonde',\n",
       " 'blood',\n",
       " 'bloody',\n",
       " 'blow',\n",
       " 'blue',\n",
       " 'blue wave',\n",
       " 'bn',\n",
       " 'bo',\n",
       " 'board',\n",
       " 'boarder',\n",
       " 'bob',\n",
       " 'body',\n",
       " 'bomb',\n",
       " 'bone',\n",
       " 'bono',\n",
       " 'boo',\n",
       " 'boob',\n",
       " 'book',\n",
       " 'booker',\n",
       " 'booming',\n",
       " 'booming economy',\n",
       " 'booming economy url',\n",
       " 'boost',\n",
       " 'booty',\n",
       " 'border',\n",
       " 'boring',\n",
       " 'boris',\n",
       " 'born',\n",
       " 'bos',\n",
       " 'boston',\n",
       " 'bot',\n",
       " 'bother',\n",
       " 'bottom',\n",
       " 'bought',\n",
       " 'bout',\n",
       " 'box',\n",
       " 'boy',\n",
       " 'boycott',\n",
       " 'boycott nfl',\n",
       " 'boycott nike',\n",
       " 'boycotting',\n",
       " 'boyfriend',\n",
       " 'brain',\n",
       " 'brainwashed',\n",
       " 'brandon',\n",
       " 'brat',\n",
       " 'brave',\n",
       " 'break',\n",
       " 'breaking',\n",
       " 'breath',\n",
       " 'breitbart',\n",
       " 'brennan',\n",
       " 'brett',\n",
       " 'brett kavanaugh',\n",
       " 'brexit',\n",
       " 'brexit url',\n",
       " 'brian',\n",
       " 'bright',\n",
       " 'brilliant',\n",
       " 'bring',\n",
       " 'bringing',\n",
       " 'britain',\n",
       " 'british',\n",
       " 'bro',\n",
       " 'broke',\n",
       " 'broken',\n",
       " 'brother',\n",
       " 'brought',\n",
       " 'brown',\n",
       " 'brown shirt',\n",
       " 'bruh',\n",
       " 'brutality',\n",
       " 'btw',\n",
       " 'bubble',\n",
       " 'buddy',\n",
       " 'budget',\n",
       " 'build',\n",
       " 'build wall',\n",
       " 'building',\n",
       " 'built',\n",
       " 'bull',\n",
       " 'bullet',\n",
       " 'bullshit',\n",
       " 'bully',\n",
       " 'bullying',\n",
       " 'bunch',\n",
       " 'burn',\n",
       " 'burning',\n",
       " 'bus',\n",
       " 'business',\n",
       " 'busy',\n",
       " 'butt',\n",
       " 'buy',\n",
       " 'buying',\n",
       " 'bye',\n",
       " 'ca',\n",
       " 'cain',\n",
       " 'cake',\n",
       " 'cali',\n",
       " 'california',\n",
       " 'call',\n",
       " 'call gun',\n",
       " 'call gun control',\n",
       " 'called',\n",
       " 'calling',\n",
       " 'calm',\n",
       " 'came',\n",
       " 'camera',\n",
       " 'camp',\n",
       " 'campaign',\n",
       " 'campus',\n",
       " 'canada',\n",
       " 'canadian',\n",
       " 'cancel',\n",
       " 'cancer',\n",
       " 'candidate',\n",
       " 'candy',\n",
       " 'cannot',\n",
       " 'cannot stand',\n",
       " 'cant',\n",
       " 'cant believe',\n",
       " 'cant blame',\n",
       " 'cant even',\n",
       " 'cant find',\n",
       " 'cant help',\n",
       " 'cant wait',\n",
       " 'cap',\n",
       " 'capable',\n",
       " 'capital',\n",
       " 'capitalism',\n",
       " 'capitalist',\n",
       " 'car',\n",
       " 'card',\n",
       " 'cardi',\n",
       " 'care',\n",
       " 'care gun',\n",
       " 'care gun control',\n",
       " 'care human',\n",
       " 'care le',\n",
       " 'cared',\n",
       " 'career',\n",
       " 'careful',\n",
       " 'carrey',\n",
       " 'carry',\n",
       " 'cartel',\n",
       " 'carter',\n",
       " 'case',\n",
       " 'cash',\n",
       " 'cast',\n",
       " 'cat',\n",
       " 'catch',\n",
       " 'catholic',\n",
       " 'catholic church',\n",
       " 'caught',\n",
       " 'cause',\n",
       " 'caused',\n",
       " 'causing',\n",
       " 'cbc',\n",
       " 'cbs',\n",
       " 'ccot',\n",
       " 'cdnpoli',\n",
       " 'celebrity',\n",
       " 'cell',\n",
       " 'censored',\n",
       " 'censoring',\n",
       " 'censoring conservative',\n",
       " 'censorship',\n",
       " 'center',\n",
       " 'centrist',\n",
       " 'century',\n",
       " 'ceo',\n",
       " 'certain',\n",
       " 'certainly',\n",
       " 'chair',\n",
       " 'challenge',\n",
       " 'champion',\n",
       " 'chance',\n",
       " 'change',\n",
       " 'change mind',\n",
       " 'changed',\n",
       " 'changing',\n",
       " 'channel',\n",
       " 'chaos',\n",
       " 'character',\n",
       " 'charge',\n",
       " 'charged',\n",
       " 'charlottesville',\n",
       " 'cheap',\n",
       " 'cheat',\n",
       " 'cheating',\n",
       " 'check',\n",
       " 'check list',\n",
       " 'checked',\n",
       " 'cheer',\n",
       " 'cheese',\n",
       " 'chelsea',\n",
       " 'chequer',\n",
       " 'cherry',\n",
       " 'chest',\n",
       " 'chicago',\n",
       " 'chick',\n",
       " 'chicken',\n",
       " 'chief',\n",
       " 'child',\n",
       " 'chill',\n",
       " 'china',\n",
       " 'chinese',\n",
       " 'chip',\n",
       " 'choice',\n",
       " 'choose',\n",
       " 'chose',\n",
       " 'chris',\n",
       " 'christ',\n",
       " 'christian',\n",
       " 'christian conservative',\n",
       " 'christine',\n",
       " 'christine blasey',\n",
       " 'christine blasey ford',\n",
       " 'christine ford',\n",
       " 'chuck',\n",
       " 'church',\n",
       " 'cia',\n",
       " 'circus',\n",
       " 'citizen',\n",
       " 'city',\n",
       " 'civil',\n",
       " 'civil right',\n",
       " 'civil war',\n",
       " 'claim',\n",
       " 'claiming',\n",
       " 'clarence',\n",
       " 'clarence thomas',\n",
       " 'clarify',\n",
       " 'class',\n",
       " 'clean',\n",
       " 'clear',\n",
       " 'clearly',\n",
       " 'climate',\n",
       " 'climate change',\n",
       " 'clinton',\n",
       " 'close',\n",
       " 'closer',\n",
       " 'closet',\n",
       " 'clown',\n",
       " 'club',\n",
       " 'clue',\n",
       " 'clueless',\n",
       " 'cnn',\n",
       " 'co',\n",
       " 'coach',\n",
       " 'coalition',\n",
       " 'code',\n",
       " 'coffin',\n",
       " 'cold',\n",
       " 'college',\n",
       " 'collins',\n",
       " 'colluding',\n",
       " 'collusion',\n",
       " 'color',\n",
       " 'come',\n",
       " 'come back',\n",
       " 'come forward',\n",
       " 'come gun',\n",
       " 'come gun control',\n",
       " 'comedian',\n",
       " 'comedy',\n",
       " 'comfortable',\n",
       " 'coming',\n",
       " 'coming back',\n",
       " 'comment',\n",
       " 'commercial',\n",
       " 'commie',\n",
       " 'commit',\n",
       " 'committed',\n",
       " 'committee',\n",
       " 'common',\n",
       " 'common sense',\n",
       " 'common sense gun',\n",
       " 'communism',\n",
       " 'communist',\n",
       " 'community',\n",
       " 'company',\n",
       " 'compare',\n",
       " 'compared',\n",
       " 'comparing',\n",
       " 'comparison',\n",
       " 'competition',\n",
       " 'competitive',\n",
       " 'complain',\n",
       " 'complaining',\n",
       " 'complete',\n",
       " 'completely',\n",
       " 'completely agree',\n",
       " 'computer',\n",
       " 'comrade',\n",
       " 'con',\n",
       " 'concept',\n",
       " 'concern',\n",
       " 'concerned',\n",
       " 'concert',\n",
       " 'conclusion',\n",
       " 'condemn',\n",
       " 'condition',\n",
       " 'conference',\n",
       " 'confidence',\n",
       " 'confirm',\n",
       " 'confirm judge',\n",
       " 'confirm judge kavanaugh',\n",
       " 'confirm kavanaugh',\n",
       " 'confirm kavanaugh maga',\n",
       " 'confirmation',\n",
       " 'confirmation hearing',\n",
       " 'confirmed',\n",
       " 'confuse',\n",
       " 'confused',\n",
       " 'congrats',\n",
       " 'congratulation',\n",
       " 'congress',\n",
       " 'congressional',\n",
       " 'congressman',\n",
       " 'connected',\n",
       " 'connection',\n",
       " 'conscience',\n",
       " 'consequence',\n",
       " 'conservative',\n",
       " 'conservative christian',\n",
       " 'conservative conservative',\n",
       " 'conservative conservative url',\n",
       " 'conservative dont',\n",
       " 'conservative hate',\n",
       " 'conservative keep',\n",
       " 'conservative left',\n",
       " 'conservative liberal',\n",
       " 'conservative like',\n",
       " 'conservative love',\n",
       " 'conservative must',\n",
       " 'conservative need',\n",
       " 'conservative never',\n",
       " 'conservative patriot',\n",
       " 'conservative patriot url',\n",
       " 'conservative republican',\n",
       " 'conservative think',\n",
       " 'conservative url',\n",
       " 'conservative vote',\n",
       " 'conservative want',\n",
       " 'conservative would',\n",
       " 'consider',\n",
       " 'considered',\n",
       " 'considering',\n",
       " 'conspiracy',\n",
       " 'constant',\n",
       " 'constantly',\n",
       " 'constituent',\n",
       " 'constitution',\n",
       " 'constitution day',\n",
       " 'constitutional',\n",
       " 'contempt',\n",
       " 'content',\n",
       " 'continue',\n",
       " 'continues',\n",
       " 'contract',\n",
       " 'contributed',\n",
       " 'control',\n",
       " 'control amp',\n",
       " 'control crowd',\n",
       " 'control debate',\n",
       " 'control doesnt',\n",
       " 'control gun',\n",
       " 'control issue',\n",
       " 'control law',\n",
       " 'control legislation',\n",
       " 'control liberal',\n",
       " 'control many',\n",
       " 'control mean',\n",
       " 'control measure',\n",
       " 'control need',\n",
       " 'control nut',\n",
       " 'control people',\n",
       " 'control policy',\n",
       " 'control research',\n",
       " 'control research unethical',\n",
       " 'control url',\n",
       " 'control work',\n",
       " 'control working',\n",
       " 'control would',\n",
       " 'controlled',\n",
       " 'convenient',\n",
       " 'conversation',\n",
       " 'convince',\n",
       " 'convinced',\n",
       " 'cool',\n",
       " 'cop',\n",
       " 'copy',\n",
       " 'corbyn',\n",
       " 'core',\n",
       " 'corporation',\n",
       " 'correct',\n",
       " 'corrupt',\n",
       " 'corruption',\n",
       " 'cory',\n",
       " 'cost',\n",
       " 'could',\n",
       " 'could get',\n",
       " 'couldnt',\n",
       " 'council',\n",
       " 'count',\n",
       " 'counter',\n",
       " 'country',\n",
       " 'country gun',\n",
       " 'country gun control',\n",
       " 'county',\n",
       " 'coup',\n",
       " 'couple',\n",
       " 'courage',\n",
       " 'course',\n",
       " 'court',\n",
       " 'court justice',\n",
       " 'cover',\n",
       " 'coverage',\n",
       " 'covered',\n",
       " 'covering',\n",
       " 'coward',\n",
       " 'cpc',\n",
       " 'crap',\n",
       " 'crash',\n",
       " 'crazy',\n",
       " 'crazy liberal',\n",
       " 'create',\n",
       " 'created',\n",
       " 'creating',\n",
       " 'credibility',\n",
       " 'credible',\n",
       " 'credit',\n",
       " 'creep',\n",
       " 'creepy',\n",
       " 'crime',\n",
       " 'crime rate',\n",
       " 'criminal',\n",
       " 'crisis',\n",
       " 'critical',\n",
       " 'criticism',\n",
       " 'crony',\n",
       " 'crook',\n",
       " 'crooked',\n",
       " 'cross',\n",
       " 'crossed',\n",
       " 'crossing',\n",
       " 'crowd',\n",
       " 'crush',\n",
       " 'cruz',\n",
       " 'cry',\n",
       " 'crybaby',\n",
       " 'cult',\n",
       " 'culture',\n",
       " 'cunt',\n",
       " 'curious',\n",
       " 'current',\n",
       " 'currently',\n",
       " 'customer',\n",
       " 'cut',\n",
       " 'cute',\n",
       " 'cutie',\n",
       " 'cuz',\n",
       " 'da',\n",
       " 'dad',\n",
       " 'daddy',\n",
       " 'daily',\n",
       " 'dairy',\n",
       " 'dallas',\n",
       " 'dam',\n",
       " 'damage',\n",
       " 'damn',\n",
       " 'dana',\n",
       " 'dance',\n",
       " 'danger',\n",
       " 'dangerous',\n",
       " 'dare',\n",
       " 'dark',\n",
       " 'data',\n",
       " 'date',\n",
       " 'dating',\n",
       " 'daughter',\n",
       " 'david',\n",
       " 'day',\n",
       " 'day maga',\n",
       " 'day url',\n",
       " 'dc',\n",
       " 'de',\n",
       " 'dead',\n",
       " 'deal',\n",
       " 'dealing',\n",
       " 'dear',\n",
       " 'death',\n",
       " 'death threat',\n",
       " 'debate',\n",
       " 'debt',\n",
       " 'decade',\n",
       " 'decency',\n",
       " 'decent',\n",
       " 'decide',\n",
       " 'decided',\n",
       " 'decision',\n",
       " 'declassified',\n",
       " 'declassify',\n",
       " 'deep',\n",
       " 'deep state',\n",
       " 'defeat',\n",
       " 'defeated',\n",
       " 'defend',\n",
       " 'defending',\n",
       " 'defense',\n",
       " 'defensive',\n",
       " 'deficit',\n",
       " 'defined',\n",
       " 'definitely',\n",
       " 'definition',\n",
       " 'degree',\n",
       " 'delay',\n",
       " 'delete',\n",
       " 'delusional',\n",
       " 'dem',\n",
       " 'demand',\n",
       " 'demanding',\n",
       " 'demented',\n",
       " 'democ',\n",
       " 'democ rat',\n",
       " 'democracy',\n",
       " 'democrat',\n",
       " 'democrat amp',\n",
       " 'democrat hate',\n",
       " 'democrat liberal',\n",
       " 'democrat party',\n",
       " 'democrat republican',\n",
       " 'democrat url',\n",
       " 'democrat want',\n",
       " 'democratic',\n",
       " 'democratic party',\n",
       " 'demon',\n",
       " 'dems',\n",
       " 'dems want',\n",
       " 'denial',\n",
       " 'denounce',\n",
       " 'deny',\n",
       " 'denying',\n",
       " 'department',\n",
       " 'depends',\n",
       " 'deplorable',\n",
       " 'deplorables',\n",
       " 'derail',\n",
       " 'deranged',\n",
       " 'derangement',\n",
       " 'derangement syndrome',\n",
       " 'describe',\n",
       " 'describing',\n",
       " 'description',\n",
       " 'deserve',\n",
       " 'deserved',\n",
       " 'deserves',\n",
       " 'designed',\n",
       " 'desk',\n",
       " 'desperate',\n",
       " 'despicable',\n",
       " 'despite',\n",
       " 'destroy',\n",
       " 'destroyed',\n",
       " 'destroying',\n",
       " 'destruction',\n",
       " 'detail',\n",
       " 'determined',\n",
       " 'devil',\n",
       " 'diane',\n",
       " 'diane feinstein',\n",
       " 'dianne',\n",
       " 'dick',\n",
       " 'dictator',\n",
       " 'dictionary',\n",
       " 'didnt',\n",
       " 'didnt get',\n",
       " 'didnt know',\n",
       " 'didnt want',\n",
       " 'die',\n",
       " 'died',\n",
       " 'difference',\n",
       " 'different',\n",
       " 'dig',\n",
       " 'dinner',\n",
       " 'direct',\n",
       " 'directly',\n",
       " 'dirt',\n",
       " 'dirty',\n",
       " 'dirty trick',\n",
       " 'disabled',\n",
       " 'disagree',\n",
       " 'disagrees',\n",
       " 'disarm',\n",
       " 'disaster',\n",
       " 'discredit',\n",
       " 'discus',\n",
       " ...]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_gram.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "conditional-collective",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<9930x3918 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 91192 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vect = vect_gram.transform(X_train)\n",
    "\n",
    "X_train_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "freelance-antigua",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_gram = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "cutting-touch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.05: 0.7471299093655589,\n",
       " 0.1: 0.7580060422960725,\n",
       " 0.15000000000000002: 0.7634441087613293,\n",
       " 0.2: 0.7643504531722054,\n",
       " 0.25: 0.7652567975830815,\n",
       " 0.30000000000000004: 0.7661631419939577,\n",
       " 0.35000000000000003: 0.7646525679758308,\n",
       " 0.4: 0.7628398791540786,\n",
       " 0.45: 0.7640483383685801,\n",
       " 0.5: 0.7646525679758308,\n",
       " 0.55: 0.7640483383685801,\n",
       " 0.6000000000000001: 0.7628398791540786,\n",
       " 0.65: 0.7610271903323262,\n",
       " 0.7000000000000001: 0.7598187311178247,\n",
       " 0.75: 0.7604229607250755,\n",
       " 0.8: 0.7601208459214501,\n",
       " 0.8500000000000001: 0.7610271903323262,\n",
       " 0.9: 0.760725075528701,\n",
       " 0.9500000000000001: 0.7595166163141994}"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in C:\n",
    "    clf = LogisticRegression(C= i, max_iter=1000)\n",
    "    clf.fit(X_train_vect, y_train)\n",
    "    scores_gram[i] = clf.score(vect_gram.transform(X_test), y_test)\n",
    "    \n",
    "scores_gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "attended-auditor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30000000000000004\n"
     ]
    }
   ],
   "source": [
    "best_C_gram = max(scores_gram, key=scores.get)\n",
    "\n",
    "print(best_C_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "desirable-cyprus",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(C= 0.3, max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "noticed-munich",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.3, max_iter=1000)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "limited-method",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7661631419939577"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(vect_gram.transform(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "automatic-captain",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array(vect_gram.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "charged-measurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = clf.coef_[0].argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "canadian-steal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coefs \n",
      "['thank' 'justice' 'best' 'lead' 'brexit' 'company' 'woman make' 'action'\n",
      " 'nike' 'accuser']\n",
      "Largest Coefs \n",
      "['nigga' 'suck' 'disgusting' 'liar' 'as' 'idiot' 'fucking' 'stupid'\n",
      " 'bitch' 'shit']\n"
     ]
    }
   ],
   "source": [
    "print(\"Smallest Coefs \\n{}\".format(features[coefs[:10]]))\n",
    "print(\"Largest Coefs \\n{}\".format(features[coefs[-11:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "global-final",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
