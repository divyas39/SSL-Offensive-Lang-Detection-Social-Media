{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adolescent-charter",
   "metadata": {},
   "source": [
    "# Bag Of Words Model\n",
    "\n",
    "Uses one-hot encoding to count number of occurences of a word in a given document. Disadvantage is that most words are not repeated in every document leading to a sparse matrix and also does not take into account the structure of a sentence, i.e., the order of words or semantics.\n",
    "\n",
    "\"Not bad, working good\" and \"Not good, working bad\" would be treated as the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "superb-tournament",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, learning_curve\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "given-composition",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"processed_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cloudy-allergy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>subtask_b</th>\n",
       "      <th>subtask_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>86426</td>\n",
       "      <td>['ask', 'native', 'american', 'take']</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>90194</td>\n",
       "      <td>['go', 'home', '‚Äô', 'drunk', 'maga', 'trump', ...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>16820</td>\n",
       "      <td>['amazon', 'investigating', 'chinese', 'employ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>62688</td>\n",
       "      <td>['someone', 'shouldve', 'taken', 'piece', 'shi...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>43605</td>\n",
       "      <td>['obama', 'wanted', 'liberal', 'amp', 'illegal...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13235</th>\n",
       "      <td>13235</td>\n",
       "      <td>95338</td>\n",
       "      <td>['sometimes', 'get', 'strong', 'vibe', 'people...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13236</th>\n",
       "      <td>13236</td>\n",
       "      <td>67210</td>\n",
       "      <td>['benidorm', '‚úÖ', 'creamfields', '‚úÖ', 'maga', ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13237</th>\n",
       "      <td>13237</td>\n",
       "      <td>82921</td>\n",
       "      <td>['report', 'garbage', 'dont', 'give', 'crap']</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>OTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13238</th>\n",
       "      <td>13238</td>\n",
       "      <td>27429</td>\n",
       "      <td>['pussy']</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13239</th>\n",
       "      <td>13239</td>\n",
       "      <td>46552</td>\n",
       "      <td>['spanishrevenge', 'v', 'justice', 'human', 'r...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13240 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0     id                                              tweet  \\\n",
       "0               0  86426              ['ask', 'native', 'american', 'take']   \n",
       "1               1  90194  ['go', 'home', '‚Äô', 'drunk', 'maga', 'trump', ...   \n",
       "2               2  16820  ['amazon', 'investigating', 'chinese', 'employ...   \n",
       "3               3  62688  ['someone', 'shouldve', 'taken', 'piece', 'shi...   \n",
       "4               4  43605  ['obama', 'wanted', 'liberal', 'amp', 'illegal...   \n",
       "...           ...    ...                                                ...   \n",
       "13235       13235  95338  ['sometimes', 'get', 'strong', 'vibe', 'people...   \n",
       "13236       13236  67210  ['benidorm', '‚úÖ', 'creamfields', '‚úÖ', 'maga', ...   \n",
       "13237       13237  82921      ['report', 'garbage', 'dont', 'give', 'crap']   \n",
       "13238       13238  27429                                          ['pussy']   \n",
       "13239       13239  46552  ['spanishrevenge', 'v', 'justice', 'human', 'r...   \n",
       "\n",
       "      subtask_a subtask_b subtask_c  \n",
       "0           OFF       UNT       NaN  \n",
       "1           OFF       TIN       IND  \n",
       "2           NOT       NaN       NaN  \n",
       "3           OFF       UNT       NaN  \n",
       "4           NOT       NaN       NaN  \n",
       "...         ...       ...       ...  \n",
       "13235       OFF       TIN       IND  \n",
       "13236       NOT       NaN       NaN  \n",
       "13237       OFF       TIN       OTH  \n",
       "13238       OFF       UNT       NaN  \n",
       "13239       NOT       NaN       NaN  \n",
       "\n",
       "[13240 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "canadian-bones",
   "metadata": {},
   "source": [
    "### Removing redundant axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "reverse-stopping",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "final-lounge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>subtask_b</th>\n",
       "      <th>subtask_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86426</td>\n",
       "      <td>['ask', 'native', 'american', 'take']</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90194</td>\n",
       "      <td>['go', 'home', '‚Äô', 'drunk', 'maga', 'trump', ...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16820</td>\n",
       "      <td>['amazon', 'investigating', 'chinese', 'employ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62688</td>\n",
       "      <td>['someone', 'shouldve', 'taken', 'piece', 'shi...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43605</td>\n",
       "      <td>['obama', 'wanted', 'liberal', 'amp', 'illegal...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13235</th>\n",
       "      <td>95338</td>\n",
       "      <td>['sometimes', 'get', 'strong', 'vibe', 'people...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13236</th>\n",
       "      <td>67210</td>\n",
       "      <td>['benidorm', '‚úÖ', 'creamfields', '‚úÖ', 'maga', ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13237</th>\n",
       "      <td>82921</td>\n",
       "      <td>['report', 'garbage', 'dont', 'give', 'crap']</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>OTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13238</th>\n",
       "      <td>27429</td>\n",
       "      <td>['pussy']</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13239</th>\n",
       "      <td>46552</td>\n",
       "      <td>['spanishrevenge', 'v', 'justice', 'human', 'r...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13240 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              tweet subtask_a  \\\n",
       "0      86426              ['ask', 'native', 'american', 'take']       OFF   \n",
       "1      90194  ['go', 'home', '‚Äô', 'drunk', 'maga', 'trump', ...       OFF   \n",
       "2      16820  ['amazon', 'investigating', 'chinese', 'employ...       NOT   \n",
       "3      62688  ['someone', 'shouldve', 'taken', 'piece', 'shi...       OFF   \n",
       "4      43605  ['obama', 'wanted', 'liberal', 'amp', 'illegal...       NOT   \n",
       "...      ...                                                ...       ...   \n",
       "13235  95338  ['sometimes', 'get', 'strong', 'vibe', 'people...       OFF   \n",
       "13236  67210  ['benidorm', '‚úÖ', 'creamfields', '‚úÖ', 'maga', ...       NOT   \n",
       "13237  82921      ['report', 'garbage', 'dont', 'give', 'crap']       OFF   \n",
       "13238  27429                                          ['pussy']       OFF   \n",
       "13239  46552  ['spanishrevenge', 'v', 'justice', 'human', 'r...       NOT   \n",
       "\n",
       "      subtask_b subtask_c  \n",
       "0           UNT       NaN  \n",
       "1           TIN       IND  \n",
       "2           NaN       NaN  \n",
       "3           UNT       NaN  \n",
       "4           NaN       NaN  \n",
       "...         ...       ...  \n",
       "13235       TIN       IND  \n",
       "13236       NaN       NaN  \n",
       "13237       TIN       OTH  \n",
       "13238       UNT       NaN  \n",
       "13239       NaN       NaN  \n",
       "\n",
       "[13240 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powered-isaac",
   "metadata": {},
   "source": [
    "### Removing Unnecessary Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "designed-repair",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"subtask_b\", \"subtask_c\", \"id\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "exterior-snake",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['ask', 'native', 'american', 'take']</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['go', 'home', '‚Äô', 'drunk', 'maga', 'trump', ...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['amazon', 'investigating', 'chinese', 'employ...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['someone', 'shouldve', 'taken', 'piece', 'shi...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['obama', 'wanted', 'liberal', 'amp', 'illegal...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13235</th>\n",
       "      <td>['sometimes', 'get', 'strong', 'vibe', 'people...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13236</th>\n",
       "      <td>['benidorm', '‚úÖ', 'creamfields', '‚úÖ', 'maga', ...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13237</th>\n",
       "      <td>['report', 'garbage', 'dont', 'give', 'crap']</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13238</th>\n",
       "      <td>['pussy']</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13239</th>\n",
       "      <td>['spanishrevenge', 'v', 'justice', 'human', 'r...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13240 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet subtask_a\n",
       "0                  ['ask', 'native', 'american', 'take']       OFF\n",
       "1      ['go', 'home', '‚Äô', 'drunk', 'maga', 'trump', ...       OFF\n",
       "2      ['amazon', 'investigating', 'chinese', 'employ...       NOT\n",
       "3      ['someone', 'shouldve', 'taken', 'piece', 'shi...       OFF\n",
       "4      ['obama', 'wanted', 'liberal', 'amp', 'illegal...       NOT\n",
       "...                                                  ...       ...\n",
       "13235  ['sometimes', 'get', 'strong', 'vibe', 'people...       OFF\n",
       "13236  ['benidorm', '‚úÖ', 'creamfields', '‚úÖ', 'maga', ...       NOT\n",
       "13237      ['report', 'garbage', 'dont', 'give', 'crap']       OFF\n",
       "13238                                          ['pussy']       OFF\n",
       "13239  ['spanishrevenge', 'v', 'justice', 'human', 'r...       NOT\n",
       "\n",
       "[13240 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adverse-offset",
   "metadata": {},
   "source": [
    "### Renaming Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acute-frost",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"subtask_a\": \"Offensive\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "unknown-biology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>Offensive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['ask', 'native', 'american', 'take']</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['go', 'home', '‚Äô', 'drunk', 'maga', 'trump', ...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['amazon', 'investigating', 'chinese', 'employ...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['someone', 'shouldve', 'taken', 'piece', 'shi...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['obama', 'wanted', 'liberal', 'amp', 'illegal...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13235</th>\n",
       "      <td>['sometimes', 'get', 'strong', 'vibe', 'people...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13236</th>\n",
       "      <td>['benidorm', '‚úÖ', 'creamfields', '‚úÖ', 'maga', ...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13237</th>\n",
       "      <td>['report', 'garbage', 'dont', 'give', 'crap']</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13238</th>\n",
       "      <td>['pussy']</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13239</th>\n",
       "      <td>['spanishrevenge', 'v', 'justice', 'human', 'r...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13240 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet Offensive\n",
       "0                  ['ask', 'native', 'american', 'take']       OFF\n",
       "1      ['go', 'home', '‚Äô', 'drunk', 'maga', 'trump', ...       OFF\n",
       "2      ['amazon', 'investigating', 'chinese', 'employ...       NOT\n",
       "3      ['someone', 'shouldve', 'taken', 'piece', 'shi...       OFF\n",
       "4      ['obama', 'wanted', 'liberal', 'amp', 'illegal...       NOT\n",
       "...                                                  ...       ...\n",
       "13235  ['sometimes', 'get', 'strong', 'vibe', 'people...       OFF\n",
       "13236  ['benidorm', '‚úÖ', 'creamfields', '‚úÖ', 'maga', ...       NOT\n",
       "13237      ['report', 'garbage', 'dont', 'give', 'crap']       OFF\n",
       "13238                                          ['pussy']       OFF\n",
       "13239  ['spanishrevenge', 'v', 'justice', 'human', 'r...       NOT\n",
       "\n",
       "[13240 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "golden-swing",
   "metadata": {},
   "source": [
    "### Replacing Class with Numeric Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "female-religion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def repl(off):\n",
    "    if off == 'OFF':\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "pregnant-girlfriend",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Offensive'] = df['Offensive'].apply(repl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "assured-surveillance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>Offensive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['ask', 'native', 'american', 'take']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['go', 'home', '‚Äô', 'drunk', 'maga', 'trump', ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['amazon', 'investigating', 'chinese', 'employ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['someone', 'shouldve', 'taken', 'piece', 'shi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['obama', 'wanted', 'liberal', 'amp', 'illegal...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13235</th>\n",
       "      <td>['sometimes', 'get', 'strong', 'vibe', 'people...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13236</th>\n",
       "      <td>['benidorm', '‚úÖ', 'creamfields', '‚úÖ', 'maga', ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13237</th>\n",
       "      <td>['report', 'garbage', 'dont', 'give', 'crap']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13238</th>\n",
       "      <td>['pussy']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13239</th>\n",
       "      <td>['spanishrevenge', 'v', 'justice', 'human', 'r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13240 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet  Offensive\n",
       "0                  ['ask', 'native', 'american', 'take']          1\n",
       "1      ['go', 'home', '‚Äô', 'drunk', 'maga', 'trump', ...          1\n",
       "2      ['amazon', 'investigating', 'chinese', 'employ...          0\n",
       "3      ['someone', 'shouldve', 'taken', 'piece', 'shi...          1\n",
       "4      ['obama', 'wanted', 'liberal', 'amp', 'illegal...          0\n",
       "...                                                  ...        ...\n",
       "13235  ['sometimes', 'get', 'strong', 'vibe', 'people...          1\n",
       "13236  ['benidorm', '‚úÖ', 'creamfields', '‚úÖ', 'maga', ...          0\n",
       "13237      ['report', 'garbage', 'dont', 'give', 'crap']          1\n",
       "13238                                          ['pussy']          1\n",
       "13239  ['spanishrevenge', 'v', 'justice', 'human', 'r...          0\n",
       "\n",
       "[13240 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "automotive-december",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    ['ask', 'native', 'american', 'take']\n",
       "1        ['go', 'home', '‚Äô', 'drunk', 'maga', 'trump', ...\n",
       "2        ['amazon', 'investigating', 'chinese', 'employ...\n",
       "3        ['someone', 'shouldve', 'taken', 'piece', 'shi...\n",
       "4        ['obama', 'wanted', 'liberal', 'amp', 'illegal...\n",
       "                               ...                        \n",
       "13235    ['sometimes', 'get', 'strong', 'vibe', 'people...\n",
       "13236    ['benidorm', '‚úÖ', 'creamfields', '‚úÖ', 'maga', ...\n",
       "13237        ['report', 'garbage', 'dont', 'give', 'crap']\n",
       "13238                                            ['pussy']\n",
       "13239    ['spanishrevenge', 'v', 'justice', 'human', 'r...\n",
       "Name: tweet, Length: 13240, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acceptable-learning",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "sweet-drink",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['tweet'], df['Offensive'], stratify=df['Offensive'], shuffle=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "surprised-profession",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "754                        ['awesome', 'thankful', 'know']\n",
       "6255                                  ['god', 'help', 'u']\n",
       "3203                                     ['ball', 'court']\n",
       "8671     ['suppose', 'antitrumps', 'accepted', 'loss', ...\n",
       "5988            ['another', 'billionaire', 'buffoon', 'üòé']\n",
       "                               ...                        \n",
       "10127             ['prayer', '‚ù§', 'Ô∏è', 'üôè', 'üèª', 'missed']\n",
       "1272            ['suggest', 'using', 'handcuff', 'remove']\n",
       "4167     ['awww', 'kaise', 'bache', 'ki', 'tarah', 'hol...\n",
       "242      ['dont', 'forget', 'telling', 'primarily', 'bl...\n",
       "1144                             ['look', 'cranky', 'url']\n",
       "Name: tweet, Length: 9930, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "common-jaguar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "754      0\n",
       "6255     0\n",
       "3203     1\n",
       "8671     0\n",
       "5988     0\n",
       "        ..\n",
       "10127    0\n",
       "1272     1\n",
       "4167     0\n",
       "242      0\n",
       "1144     0\n",
       "Name: Offensive, Length: 9930, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proved-machine",
   "metadata": {},
   "source": [
    "## BoW Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "instant-tennessee",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(lowercase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "persistent-position",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = vect.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "arranged-frequency",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14699"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "accomplished-enemy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<9930x14699 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 99138 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vect = vect.transform(X_train)\n",
    "\n",
    "X_train_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "crucial-apparatus",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "published-brand",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.05,\n",
       " 0.1,\n",
       " 0.15000000000000002,\n",
       " 0.2,\n",
       " 0.25,\n",
       " 0.30000000000000004,\n",
       " 0.35000000000000003,\n",
       " 0.4,\n",
       " 0.45,\n",
       " 0.5,\n",
       " 0.55,\n",
       " 0.6000000000000001,\n",
       " 0.65,\n",
       " 0.7000000000000001,\n",
       " 0.75,\n",
       " 0.8,\n",
       " 0.8500000000000001,\n",
       " 0.9,\n",
       " 0.9500000000000001]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = list(np.arange(0, 1, 0.05))\n",
    "\n",
    "C = [float(i) for i in C]\n",
    "\n",
    "C = C[1:]\n",
    "\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "mineral-lodge",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "liable-exclusive",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.05: 0.7447129909365559,\n",
       " 0.1: 0.7570996978851964,\n",
       " 0.15000000000000002: 0.7586102719033233,\n",
       " 0.2: 0.7601208459214501,\n",
       " 0.25: 0.7622356495468278,\n",
       " 0.30000000000000004: 0.7628398791540786,\n",
       " 0.35000000000000003: 0.7628398791540786,\n",
       " 0.4: 0.7625377643504532,\n",
       " 0.45: 0.7616314199395771,\n",
       " 0.5: 0.7610271903323262,\n",
       " 0.55: 0.759214501510574,\n",
       " 0.6000000000000001: 0.7604229607250755,\n",
       " 0.65: 0.7586102719033233,\n",
       " 0.7000000000000001: 0.7586102719033233,\n",
       " 0.75: 0.7580060422960725,\n",
       " 0.8: 0.7574018126888218,\n",
       " 0.8500000000000001: 0.7580060422960725,\n",
       " 0.9: 0.7589123867069486,\n",
       " 0.9500000000000001: 0.7586102719033233}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in C:\n",
    "    clf = LogisticRegression(C= i, max_iter=1000)\n",
    "    clf.fit(X_train_vect, y_train)\n",
    "    scores[i] = clf.score(vect.transform(X_test), y_test)\n",
    "    \n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "indoor-germany",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30000000000000004\n"
     ]
    }
   ],
   "source": [
    "best_C = max(scores, key=scores.get)\n",
    "\n",
    "print(best_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dental-beast",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(C= 0.3, max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "super-shoot",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.3, max_iter=1000)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "expanded-design",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7628398791540786"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(vect.transform(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "collected-premium",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "missing-cornwall",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = clf.coef_[0].argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "early-delicious",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coefs \n",
      "['best' 'brexit' 'thank' 'nike' 'lead' 'awesome' 'accuser' 'thanks'\n",
      " 'excuse' 'action']\n",
      "Largest Coefs \n",
      "['nigga' 'liar' 'fucked' 'suck' 'as' 'fucking' 'idiot' 'stupid' 'shit'\n",
      " 'bitch']\n"
     ]
    }
   ],
   "source": [
    "print(\"Smallest Coefs \\n{}\".format(features[coefs[:10]]))\n",
    "print(\"Largest Coefs \\n{}\".format(features[coefs[-11:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "light-scholarship",
   "metadata": {},
   "source": [
    "## BoW with Bigrams and Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "residential-hartford",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_gram = CountVectorizer(lowercase=False, ngram_range=(1, 3), min_df=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "superb-silly",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_gram = vect_gram.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "literary-tennessee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3862"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vect_gram.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "comprehensive-klein",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aaron',\n",
       " 'ab',\n",
       " 'abiding',\n",
       " 'abiding citizen',\n",
       " 'ability',\n",
       " 'able',\n",
       " 'abortion',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'abt',\n",
       " 'abuse',\n",
       " 'abuse power',\n",
       " 'abused',\n",
       " 'abuser',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'accepting',\n",
       " 'access',\n",
       " 'accident',\n",
       " 'accomplished',\n",
       " 'according',\n",
       " 'account',\n",
       " 'accountable',\n",
       " 'accusation',\n",
       " 'accuse',\n",
       " 'accused',\n",
       " 'accuser',\n",
       " 'accuses',\n",
       " 'accusing',\n",
       " 'achieve',\n",
       " 'achievement',\n",
       " 'acknowledge',\n",
       " 'across',\n",
       " 'act',\n",
       " 'act like',\n",
       " 'acting',\n",
       " 'acting like',\n",
       " 'action',\n",
       " 'active',\n",
       " 'actively',\n",
       " 'activist',\n",
       " 'activity',\n",
       " 'actor',\n",
       " 'actress',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'ad',\n",
       " 'adam',\n",
       " 'add',\n",
       " 'added',\n",
       " 'address',\n",
       " 'administration',\n",
       " 'admire',\n",
       " 'admit',\n",
       " 'admitted',\n",
       " 'adopt',\n",
       " 'adorable',\n",
       " 'adult',\n",
       " 'advantage',\n",
       " 'advice',\n",
       " 'advocate',\n",
       " 'advocating',\n",
       " 'af',\n",
       " 'affair',\n",
       " 'affect',\n",
       " 'afford',\n",
       " 'affordable',\n",
       " 'afraid',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'ag',\n",
       " 'age',\n",
       " 'agency',\n",
       " 'agenda',\n",
       " 'agent',\n",
       " 'aggressive',\n",
       " 'ago',\n",
       " 'agree',\n",
       " 'agreed',\n",
       " 'ah',\n",
       " 'ahead',\n",
       " 'ahhh',\n",
       " 'aim',\n",
       " 'aint',\n",
       " 'air',\n",
       " 'aka',\n",
       " 'al',\n",
       " 'album',\n",
       " 'alert',\n",
       " 'alex',\n",
       " 'alex jones',\n",
       " 'alien',\n",
       " 'alinsky',\n",
       " 'alive',\n",
       " 'allegation',\n",
       " 'alleged',\n",
       " 'allegedly',\n",
       " 'allow',\n",
       " 'allowed',\n",
       " 'allowing',\n",
       " 'allows',\n",
       " 'ally',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'alot',\n",
       " 'already',\n",
       " 'already know',\n",
       " 'also',\n",
       " 'alt',\n",
       " 'alt right',\n",
       " 'alternative',\n",
       " 'although',\n",
       " 'altright',\n",
       " 'always',\n",
       " 'always get',\n",
       " 'amazing',\n",
       " 'ambitious',\n",
       " 'amendment',\n",
       " 'amental',\n",
       " 'america',\n",
       " 'america first',\n",
       " 'america great',\n",
       " 'america url',\n",
       " 'american',\n",
       " 'american people',\n",
       " 'among',\n",
       " 'amount',\n",
       " 'amp',\n",
       " 'amp conservative',\n",
       " 'amp get',\n",
       " 'anarchist',\n",
       " 'andrew',\n",
       " 'andy',\n",
       " 'angel',\n",
       " 'anger',\n",
       " 'angry',\n",
       " 'animal',\n",
       " 'anita',\n",
       " 'announced',\n",
       " 'announcement',\n",
       " 'anonymous',\n",
       " 'another',\n",
       " 'answer',\n",
       " 'answer question',\n",
       " 'answer url',\n",
       " 'answered',\n",
       " 'anthony',\n",
       " 'anti',\n",
       " 'anti american',\n",
       " 'anti fa',\n",
       " 'antiamerican',\n",
       " 'antifa',\n",
       " 'antifa amp',\n",
       " 'antifa black',\n",
       " 'antifa blm',\n",
       " 'antifa democrat',\n",
       " 'antifa get',\n",
       " 'antifa go',\n",
       " 'antifa kkk',\n",
       " 'antifa kkk hood',\n",
       " 'antifa member',\n",
       " 'antifa people',\n",
       " 'antifa protest',\n",
       " 'antifa protestors',\n",
       " 'antifa target',\n",
       " 'antifa terrorist',\n",
       " 'antifa thug',\n",
       " 'antifa type',\n",
       " 'antifa url',\n",
       " 'antifa violence',\n",
       " 'antifa would',\n",
       " 'antifascist',\n",
       " 'antisemitism',\n",
       " 'anybody',\n",
       " 'anymore',\n",
       " 'anyone',\n",
       " 'anyone else',\n",
       " 'anything',\n",
       " 'anyway',\n",
       " 'anyways',\n",
       " 'anywhere',\n",
       " 'apart',\n",
       " 'apologize',\n",
       " 'apology',\n",
       " 'app',\n",
       " 'apparently',\n",
       " 'appear',\n",
       " 'appears',\n",
       " 'apple',\n",
       " 'apply',\n",
       " 'appointed',\n",
       " 'appointment',\n",
       " 'appreciate',\n",
       " 'approach',\n",
       " 'approve',\n",
       " 'approved',\n",
       " 'ar',\n",
       " 'area',\n",
       " 'arent',\n",
       " 'argue',\n",
       " 'arguing',\n",
       " 'argument',\n",
       " 'arm',\n",
       " 'armed',\n",
       " 'army',\n",
       " 'around',\n",
       " 'around world',\n",
       " 'arrest',\n",
       " 'arrested',\n",
       " 'art',\n",
       " 'article',\n",
       " 'artist',\n",
       " 'as',\n",
       " 'asap',\n",
       " 'asian',\n",
       " 'ask',\n",
       " 'asked',\n",
       " 'asking',\n",
       " 'asks',\n",
       " 'aspect',\n",
       " 'aspect life',\n",
       " 'ass',\n",
       " 'assault',\n",
       " 'assault rifle',\n",
       " 'assault weapon',\n",
       " 'assaulted',\n",
       " 'asset',\n",
       " 'asshole',\n",
       " 'associated',\n",
       " 'association',\n",
       " 'assume',\n",
       " 'ate',\n",
       " 'attack',\n",
       " 'attacked',\n",
       " 'attacking',\n",
       " 'attempt',\n",
       " 'attempted',\n",
       " 'attempting',\n",
       " 'attend',\n",
       " 'attention',\n",
       " 'attitude',\n",
       " 'attorney',\n",
       " 'audience',\n",
       " 'aunt',\n",
       " 'austerity',\n",
       " 'australia',\n",
       " 'australian',\n",
       " 'author',\n",
       " 'authoritarian',\n",
       " 'authority',\n",
       " 'available',\n",
       " 'average',\n",
       " 'average american',\n",
       " 'avoid',\n",
       " 'aw',\n",
       " 'awakening',\n",
       " 'award',\n",
       " 'aware',\n",
       " 'away',\n",
       " 'away democrat',\n",
       " 'away liberal',\n",
       " 'away maga',\n",
       " 'away url',\n",
       " 'awesome',\n",
       " 'awful',\n",
       " 'babe',\n",
       " 'baby',\n",
       " 'back',\n",
       " 'back maga',\n",
       " 'backed',\n",
       " 'background',\n",
       " 'background check',\n",
       " 'backing',\n",
       " 'bad',\n",
       " 'badly',\n",
       " 'bag',\n",
       " 'balance',\n",
       " 'ball',\n",
       " 'baltimore',\n",
       " 'ban',\n",
       " 'bank',\n",
       " 'banned',\n",
       " 'banning',\n",
       " 'bar',\n",
       " 'base',\n",
       " 'baseball',\n",
       " 'based',\n",
       " 'bash',\n",
       " 'basic',\n",
       " 'basically',\n",
       " 'basically saying',\n",
       " 'basis',\n",
       " 'bastard',\n",
       " 'battle',\n",
       " 'bb',\n",
       " 'bbc',\n",
       " 'bc',\n",
       " 'bear',\n",
       " 'beast',\n",
       " 'beat',\n",
       " 'beating',\n",
       " 'beating stranger',\n",
       " 'beating stranger know',\n",
       " 'beautiful',\n",
       " 'beauty',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'becoming',\n",
       " 'beef',\n",
       " 'beer',\n",
       " 'begin',\n",
       " 'beginning',\n",
       " 'behalf',\n",
       " 'behavior',\n",
       " 'behaviour',\n",
       " 'behind',\n",
       " 'being',\n",
       " 'belief',\n",
       " 'believe',\n",
       " 'believe gun',\n",
       " 'believe gun control',\n",
       " 'believe woman',\n",
       " 'believed',\n",
       " 'believing',\n",
       " 'bell',\n",
       " 'belong',\n",
       " 'belongs',\n",
       " 'ben',\n",
       " 'benefit',\n",
       " 'berkeley',\n",
       " 'bernie',\n",
       " 'bernier',\n",
       " 'bert',\n",
       " 'bert ernie',\n",
       " 'besides',\n",
       " 'best',\n",
       " 'bet',\n",
       " 'beta',\n",
       " 'beto',\n",
       " 'betrayal',\n",
       " 'better',\n",
       " 'better gun',\n",
       " 'better gun control',\n",
       " 'better soon',\n",
       " 'beyond',\n",
       " 'bias',\n",
       " 'biased',\n",
       " 'bible',\n",
       " 'biden',\n",
       " 'big',\n",
       " 'bigger',\n",
       " 'biggest',\n",
       " 'bigot',\n",
       " 'bigotry',\n",
       " 'bill',\n",
       " 'bill clinton',\n",
       " 'billion',\n",
       " 'billionaire',\n",
       " 'billy',\n",
       " 'bird',\n",
       " 'birth',\n",
       " 'birthday',\n",
       " 'bit',\n",
       " 'bitch',\n",
       " 'bitch url',\n",
       " 'bite',\n",
       " 'bitter',\n",
       " 'black',\n",
       " 'black american',\n",
       " 'black conservative',\n",
       " 'black life',\n",
       " 'black life matter',\n",
       " 'black men',\n",
       " 'black panther',\n",
       " 'black people',\n",
       " 'blame',\n",
       " 'blame gun',\n",
       " 'blame gun control',\n",
       " 'blame trump',\n",
       " 'blaming',\n",
       " 'blasey',\n",
       " 'blasey ford',\n",
       " 'blatant',\n",
       " 'blatantly',\n",
       " 'bless',\n",
       " 'blind',\n",
       " 'blm',\n",
       " 'block',\n",
       " 'blocked',\n",
       " 'blocking',\n",
       " 'blood',\n",
       " 'bloody',\n",
       " 'blow',\n",
       " 'blue',\n",
       " 'blue wave',\n",
       " 'bo',\n",
       " 'board',\n",
       " 'bob',\n",
       " 'body',\n",
       " 'boi',\n",
       " 'bomb',\n",
       " 'bone',\n",
       " 'bono',\n",
       " 'boo',\n",
       " 'boob',\n",
       " 'book',\n",
       " 'booker',\n",
       " 'booming',\n",
       " 'boot',\n",
       " 'booty',\n",
       " 'border',\n",
       " 'boring',\n",
       " 'boris',\n",
       " 'born',\n",
       " 'bos',\n",
       " 'boston',\n",
       " 'bot',\n",
       " 'bother',\n",
       " 'bottom',\n",
       " 'bought',\n",
       " 'bout',\n",
       " 'box',\n",
       " 'boy',\n",
       " 'boycott',\n",
       " 'boycott nfl',\n",
       " 'boycotting',\n",
       " 'boyfriend',\n",
       " 'brain',\n",
       " 'brainwashed',\n",
       " 'brand',\n",
       " 'brandon',\n",
       " 'brat',\n",
       " 'brave',\n",
       " 'break',\n",
       " 'breaking',\n",
       " 'breath',\n",
       " 'breitbart',\n",
       " 'brennan',\n",
       " 'brett',\n",
       " 'brett kavanaugh',\n",
       " 'brexit',\n",
       " 'brian',\n",
       " 'bridge',\n",
       " 'bright',\n",
       " 'brilliant',\n",
       " 'bring',\n",
       " 'bringing',\n",
       " 'brings',\n",
       " 'britain',\n",
       " 'british',\n",
       " 'bro',\n",
       " 'broke',\n",
       " 'broken',\n",
       " 'brother',\n",
       " 'brought',\n",
       " 'brown',\n",
       " 'brown shirt',\n",
       " 'bruh',\n",
       " 'brutality',\n",
       " 'btw',\n",
       " 'buck',\n",
       " 'buddy',\n",
       " 'budget',\n",
       " 'build',\n",
       " 'build wall',\n",
       " 'building',\n",
       " 'bull',\n",
       " 'bullet',\n",
       " 'bullshit',\n",
       " 'bully',\n",
       " 'bullying',\n",
       " 'bunch',\n",
       " 'burn',\n",
       " 'burning',\n",
       " 'bus',\n",
       " 'business',\n",
       " 'busy',\n",
       " 'butt',\n",
       " 'buy',\n",
       " 'buying',\n",
       " 'bye',\n",
       " 'ca',\n",
       " 'cabinet',\n",
       " 'cain',\n",
       " 'cali',\n",
       " 'california',\n",
       " 'call',\n",
       " 'call gun',\n",
       " 'call gun control',\n",
       " 'called',\n",
       " 'calling',\n",
       " 'calm',\n",
       " 'came',\n",
       " 'camera',\n",
       " 'camp',\n",
       " 'campaign',\n",
       " 'campus',\n",
       " 'canada',\n",
       " 'canadian',\n",
       " 'cancer',\n",
       " 'candidate',\n",
       " 'candy',\n",
       " 'cannot',\n",
       " 'cannot stand',\n",
       " 'cant',\n",
       " 'cant believe',\n",
       " 'cant even',\n",
       " 'cant help',\n",
       " 'cap',\n",
       " 'capital',\n",
       " 'capitalist',\n",
       " 'car',\n",
       " 'card',\n",
       " 'cardi',\n",
       " 'care',\n",
       " 'care gun',\n",
       " 'care gun control',\n",
       " 'care human',\n",
       " 'care le',\n",
       " 'career',\n",
       " 'careful',\n",
       " 'caring',\n",
       " 'carrey',\n",
       " 'carry',\n",
       " 'carrying',\n",
       " 'carter',\n",
       " 'case',\n",
       " 'cash',\n",
       " 'cast',\n",
       " 'cat',\n",
       " 'catch',\n",
       " 'catholic',\n",
       " 'catholic church',\n",
       " 'caught',\n",
       " 'cause',\n",
       " 'caused',\n",
       " 'causing',\n",
       " 'cbc',\n",
       " 'cbs',\n",
       " 'ccot',\n",
       " 'cdnpoli',\n",
       " 'celebrity',\n",
       " 'cell',\n",
       " 'censored',\n",
       " 'censoring',\n",
       " 'censorship',\n",
       " 'center',\n",
       " 'centrist',\n",
       " 'century',\n",
       " 'ceo',\n",
       " 'certain',\n",
       " 'certainly',\n",
       " 'chain',\n",
       " 'challenge',\n",
       " 'champion',\n",
       " 'championship',\n",
       " 'chance',\n",
       " 'change',\n",
       " 'change mind',\n",
       " 'changed',\n",
       " 'changing',\n",
       " 'channel',\n",
       " 'chaos',\n",
       " 'character',\n",
       " 'charge',\n",
       " 'charged',\n",
       " 'cheap',\n",
       " 'cheat',\n",
       " 'cheating',\n",
       " 'check',\n",
       " 'check list',\n",
       " 'checked',\n",
       " 'cheer',\n",
       " 'chelsea',\n",
       " 'chequer',\n",
       " 'chest',\n",
       " 'chicago',\n",
       " 'chicken',\n",
       " 'chief',\n",
       " 'child',\n",
       " 'chill',\n",
       " 'china',\n",
       " 'chinese',\n",
       " 'choice',\n",
       " 'choose',\n",
       " 'chose',\n",
       " 'chosen',\n",
       " 'chris',\n",
       " 'christ',\n",
       " 'christian',\n",
       " 'christian conservative',\n",
       " 'christine',\n",
       " 'christine blasey',\n",
       " 'christine blasey ford',\n",
       " 'christine ford',\n",
       " 'chuck',\n",
       " 'church',\n",
       " 'cia',\n",
       " 'citizen',\n",
       " 'city',\n",
       " 'civil',\n",
       " 'civil war',\n",
       " 'claim',\n",
       " 'claiming',\n",
       " 'clarence',\n",
       " 'clarence thomas',\n",
       " 'class',\n",
       " 'clean',\n",
       " 'clear',\n",
       " 'clearly',\n",
       " 'client',\n",
       " 'climate',\n",
       " 'climate change',\n",
       " 'clinton',\n",
       " 'close',\n",
       " 'closer',\n",
       " 'closet',\n",
       " 'clown',\n",
       " 'club',\n",
       " 'clue',\n",
       " 'clueless',\n",
       " 'cnn',\n",
       " 'co',\n",
       " 'coach',\n",
       " 'coalition',\n",
       " 'cock',\n",
       " 'code',\n",
       " 'cold',\n",
       " 'colin',\n",
       " 'college',\n",
       " 'collins',\n",
       " 'collusion',\n",
       " 'color',\n",
       " 'come',\n",
       " 'come forward',\n",
       " 'comedian',\n",
       " 'comedy',\n",
       " 'comfortable',\n",
       " 'coming',\n",
       " 'coming back',\n",
       " 'comment',\n",
       " 'commie',\n",
       " 'commit',\n",
       " 'committed',\n",
       " 'committee',\n",
       " 'common',\n",
       " 'common sense',\n",
       " 'common sense gun',\n",
       " 'communism',\n",
       " 'communist',\n",
       " 'community',\n",
       " 'company',\n",
       " 'compare',\n",
       " 'compared',\n",
       " 'comparing',\n",
       " 'comparison',\n",
       " 'competition',\n",
       " 'complain',\n",
       " 'complaining',\n",
       " 'complaint',\n",
       " 'complete',\n",
       " 'completely',\n",
       " 'complicit',\n",
       " 'computer',\n",
       " 'comrade',\n",
       " 'con',\n",
       " 'concept',\n",
       " 'concern',\n",
       " 'concerned',\n",
       " 'concert',\n",
       " 'conclusion',\n",
       " 'condemn',\n",
       " 'condition',\n",
       " 'conference',\n",
       " 'confirm',\n",
       " 'confirm judge',\n",
       " 'confirm judge kavanaugh',\n",
       " 'confirm kavanaugh',\n",
       " 'confirm kavanaugh maga',\n",
       " 'confirmation',\n",
       " 'confirmation hearing',\n",
       " 'confirmed',\n",
       " 'confused',\n",
       " 'congrats',\n",
       " 'congratulation',\n",
       " 'congress',\n",
       " 'congressional',\n",
       " 'congressman',\n",
       " 'connected',\n",
       " 'connection',\n",
       " 'conscience',\n",
       " 'consequence',\n",
       " 'conservative',\n",
       " 'conservative always',\n",
       " 'conservative conservative',\n",
       " 'conservative conservative url',\n",
       " 'conservative dont',\n",
       " 'conservative hate',\n",
       " 'conservative left',\n",
       " 'conservative liberal',\n",
       " 'conservative like',\n",
       " 'conservative love',\n",
       " 'conservative maga',\n",
       " 'conservative must',\n",
       " 'conservative need',\n",
       " 'conservative never',\n",
       " 'conservative one',\n",
       " 'conservative party',\n",
       " 'conservative patriot',\n",
       " 'conservative patriot url',\n",
       " 'conservative republican',\n",
       " 'conservative right',\n",
       " 'conservative say',\n",
       " 'conservative think',\n",
       " 'conservative url',\n",
       " 'conservative want',\n",
       " 'conservative would',\n",
       " 'consider',\n",
       " 'considered',\n",
       " 'considering',\n",
       " 'conspiracy',\n",
       " 'conspiracy theory',\n",
       " 'constant',\n",
       " 'constantly',\n",
       " 'constituent',\n",
       " 'constitution',\n",
       " 'constitution day',\n",
       " 'constitutional',\n",
       " 'constitutional right',\n",
       " 'contact',\n",
       " 'content',\n",
       " 'continue',\n",
       " 'continues',\n",
       " 'contract',\n",
       " 'contributed',\n",
       " 'control',\n",
       " 'control advocate',\n",
       " 'control amp',\n",
       " 'control chicago',\n",
       " 'control debate',\n",
       " 'control doesnt',\n",
       " 'control doesnt work',\n",
       " 'control gun',\n",
       " 'control gun control',\n",
       " 'control isnt',\n",
       " 'control issue',\n",
       " 'control law',\n",
       " 'control legislation',\n",
       " 'control many',\n",
       " 'control mean',\n",
       " 'control measure',\n",
       " 'control never',\n",
       " 'control nut',\n",
       " 'control people',\n",
       " 'control research',\n",
       " 'control research unethical',\n",
       " 'control right',\n",
       " 'control url',\n",
       " 'control want',\n",
       " 'control work',\n",
       " 'control working',\n",
       " 'control would',\n",
       " 'controlled',\n",
       " 'controlling',\n",
       " 'convenient',\n",
       " 'conversation',\n",
       " 'convinced',\n",
       " 'cool',\n",
       " 'cop',\n",
       " 'corbyn',\n",
       " 'core',\n",
       " 'corner',\n",
       " 'corporate',\n",
       " 'correct',\n",
       " 'correlation',\n",
       " 'corrupt',\n",
       " 'corruption',\n",
       " 'cory',\n",
       " 'cost',\n",
       " 'could',\n",
       " 'couldnt',\n",
       " 'council',\n",
       " 'count',\n",
       " 'counter',\n",
       " 'counting',\n",
       " 'country',\n",
       " 'country back',\n",
       " 'country gun',\n",
       " 'country gun control',\n",
       " 'county',\n",
       " 'coup',\n",
       " 'couple',\n",
       " 'courage',\n",
       " 'course',\n",
       " 'court',\n",
       " 'court justice',\n",
       " 'cover',\n",
       " 'coverage',\n",
       " 'covered',\n",
       " 'covering',\n",
       " 'coward',\n",
       " 'cpc',\n",
       " 'crap',\n",
       " 'crash',\n",
       " 'crazy',\n",
       " 'crazy liberal',\n",
       " 'crazy thing',\n",
       " 'create',\n",
       " 'created',\n",
       " 'creature',\n",
       " 'credibility',\n",
       " 'credible',\n",
       " 'credit',\n",
       " 'creep',\n",
       " 'creepy',\n",
       " 'crime',\n",
       " 'crime rate',\n",
       " 'criminal',\n",
       " 'crisis',\n",
       " 'criticism',\n",
       " 'crony',\n",
       " 'crook',\n",
       " 'crooked',\n",
       " 'cross',\n",
       " 'crossed',\n",
       " 'crowd',\n",
       " 'crush',\n",
       " 'cruz',\n",
       " 'cry',\n",
       " 'crybaby',\n",
       " 'cue',\n",
       " 'cult',\n",
       " 'cultural',\n",
       " 'culture',\n",
       " 'cum',\n",
       " 'cunt',\n",
       " 'curb',\n",
       " 'curious',\n",
       " 'current',\n",
       " 'currently',\n",
       " 'cut',\n",
       " 'cute',\n",
       " 'cutie',\n",
       " 'cuz',\n",
       " 'da',\n",
       " 'dad',\n",
       " 'daddy',\n",
       " 'daily',\n",
       " 'dallas',\n",
       " 'dam',\n",
       " 'damage',\n",
       " 'damn',\n",
       " 'dana',\n",
       " 'dance',\n",
       " 'danger',\n",
       " 'dangerous',\n",
       " 'daniel',\n",
       " 'dare',\n",
       " 'dark',\n",
       " 'data',\n",
       " 'date',\n",
       " 'dating',\n",
       " 'daughter',\n",
       " 'dave',\n",
       " 'david',\n",
       " 'day',\n",
       " 'day maga',\n",
       " 'day url',\n",
       " 'dc',\n",
       " 'de',\n",
       " 'dead',\n",
       " 'deal',\n",
       " 'dealing',\n",
       " 'dear',\n",
       " 'death',\n",
       " 'death threat',\n",
       " 'debate',\n",
       " 'debt',\n",
       " 'decade',\n",
       " 'decency',\n",
       " 'decent',\n",
       " 'decide',\n",
       " 'decided',\n",
       " 'decision',\n",
       " 'declassify',\n",
       " 'deep',\n",
       " 'deep state',\n",
       " 'deeply',\n",
       " 'def',\n",
       " 'defeat',\n",
       " 'defend',\n",
       " 'defending',\n",
       " 'defense',\n",
       " 'defenseless',\n",
       " 'defensive',\n",
       " 'deficit',\n",
       " 'definitely',\n",
       " 'definition',\n",
       " 'degree',\n",
       " 'delay',\n",
       " 'delete',\n",
       " 'deliberately',\n",
       " 'deliver',\n",
       " 'delusional',\n",
       " 'dem',\n",
       " 'demand',\n",
       " 'demented',\n",
       " 'democ',\n",
       " 'democ rat',\n",
       " 'democracy',\n",
       " 'democrat',\n",
       " 'democrat liberal',\n",
       " 'democrat party',\n",
       " 'democrat republican',\n",
       " 'democrat url',\n",
       " 'democrat want',\n",
       " 'democratic',\n",
       " 'democratic party',\n",
       " 'demon',\n",
       " 'dems',\n",
       " 'denounce',\n",
       " 'deny',\n",
       " 'department',\n",
       " 'depends',\n",
       " 'deplorable',\n",
       " 'deplorables',\n",
       " 'deranged',\n",
       " 'describe',\n",
       " 'description',\n",
       " 'deserve',\n",
       " 'deserved',\n",
       " 'deserves',\n",
       " 'designed',\n",
       " 'desperate',\n",
       " 'desperately',\n",
       " 'despicable',\n",
       " 'despite',\n",
       " 'destroy',\n",
       " 'destroyed',\n",
       " 'destroying',\n",
       " 'destruction',\n",
       " 'detail',\n",
       " 'detector',\n",
       " 'determined',\n",
       " 'devil',\n",
       " 'dianne',\n",
       " 'dick',\n",
       " 'dictator',\n",
       " 'didnt',\n",
       " 'didnt know',\n",
       " 'didnt see',\n",
       " 'didnt want',\n",
       " 'die',\n",
       " 'died',\n",
       " 'difference',\n",
       " 'different',\n",
       " 'different opinion',\n",
       " 'dig',\n",
       " 'direct',\n",
       " 'directed',\n",
       " 'directly',\n",
       " 'dirt',\n",
       " 'dirty',\n",
       " 'dirty trick',\n",
       " 'disagree',\n",
       " 'disappointed',\n",
       " 'disarm',\n",
       " 'disaster',\n",
       " 'discovered',\n",
       " 'discredit',\n",
       " 'discus',\n",
       " 'discussing',\n",
       " 'discussion',\n",
       " 'disease',\n",
       " 'disgrace',\n",
       " 'disgraceful',\n",
       " 'disgusting',\n",
       " 'dislike',\n",
       " 'disorder',\n",
       " 'display',\n",
       " 'disrespect',\n",
       " 'district',\n",
       " 'diversity',\n",
       " 'divide',\n",
       " 'divided',\n",
       " 'division',\n",
       " 'dm',\n",
       " 'dnc',\n",
       " 'doctor',\n",
       " 'document',\n",
       " 'doesnt',\n",
       " 'doesnt look',\n",
       " 'doesnt matter',\n",
       " 'doesnt mean',\n",
       " 'doesnt stop',\n",
       " 'doesnt work',\n",
       " 'dog',\n",
       " 'dog whistle',\n",
       " 'doj',\n",
       " ...]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_gram.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "conditional-collective",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<9930x3862 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 90736 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vect = vect_gram.transform(X_train)\n",
    "\n",
    "X_train_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "freelance-antigua",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_gram = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cutting-touch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.05: 0.7447129909365559,\n",
       " 0.1: 0.7564954682779457,\n",
       " 0.15000000000000002: 0.7574018126888218,\n",
       " 0.2: 0.7628398791540786,\n",
       " 0.25: 0.7625377643504532,\n",
       " 0.30000000000000004: 0.7634441087613293,\n",
       " 0.35000000000000003: 0.7616314199395771,\n",
       " 0.4: 0.760725075528701,\n",
       " 0.45: 0.7604229607250755,\n",
       " 0.5: 0.7583081570996979,\n",
       " 0.55: 0.7580060422960725,\n",
       " 0.6000000000000001: 0.7574018126888218,\n",
       " 0.65: 0.7564954682779457,\n",
       " 0.7000000000000001: 0.7558912386706949,\n",
       " 0.75: 0.7546827794561933,\n",
       " 0.8: 0.7525679758308157,\n",
       " 0.8500000000000001: 0.7501510574018126,\n",
       " 0.9: 0.7507552870090635,\n",
       " 0.9500000000000001: 0.7501510574018126}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in C:\n",
    "    clf = LogisticRegression(C= i, max_iter=1000)\n",
    "    clf.fit(X_train_vect, y_train)\n",
    "    scores_gram[i] = clf.score(vect_gram.transform(X_test), y_test)\n",
    "    \n",
    "scores_gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "attended-auditor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30000000000000004\n"
     ]
    }
   ],
   "source": [
    "best_C_gram = max(scores_gram, key=scores.get)\n",
    "\n",
    "print(best_C_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "desirable-cyprus",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(C= 0.3, max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "noticed-munich",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.3, max_iter=1000)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "limited-method",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7634441087613293"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(vect_gram.transform(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "automatic-captain",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array(vect_gram.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "charged-measurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = clf.coef_[0].argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "canadian-steal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coefs \n",
      "['brexit' 'best' 'thank' 'nike' 'excuse' 'action' 'lead' 'awesome'\n",
      " 'accuser' 'thanks']\n",
      "Largest Coefs \n",
      "['liar' 'nigga' 'fucked' 'suck' 'as' 'fucking' 'idiot' 'stupid' 'bitch'\n",
      " 'shit']\n"
     ]
    }
   ],
   "source": [
    "print(\"Smallest Coefs \\n{}\".format(features[coefs[:10]]))\n",
    "print(\"Largest Coefs \\n{}\".format(features[coefs[-11:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desperate-invalid",
   "metadata": {},
   "source": [
    "## SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "reflected-karaoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "referenced-ethernet",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'kernel': ['rbf', 'poly', 'sigmoid'], 'C': [0.05, 0.01, 0.1, 1, 5], 'gamma': [0.01, 0.1, 1, 5, 10,], 'degree': [1, 2, 3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "military-czech",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "distributed-colonial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "daily-colorado",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7522658610271903"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(vect_gram.transform(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "israeli-logging",
   "metadata": {},
   "outputs": [],
   "source": [
    "gsc = GridSearchCV(clf, param_grid=params, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "unlike-patrol",
   "metadata": {},
   "outputs": [
    {
     "ename": "TerminatedWorkerError",
     "evalue": "A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTerminatedWorkerError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-b46bdb4a345e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgrid_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgsc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_vect\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    734\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1188\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    713\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    714\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 715\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    716\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    717\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1054\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1055\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    931\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    433\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTerminatedWorkerError\u001b[0m: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n"
     ]
    }
   ],
   "source": [
    "grid_result = gsc.fit(X_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "active-beast",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_result.best_params_\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ignored-validation",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-precipitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(C=best_params['C'], gamma=best_params['gamma'], kernel=best_params['kernel'], probability = True, degree=best_params['degree'])\n",
    "clf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
