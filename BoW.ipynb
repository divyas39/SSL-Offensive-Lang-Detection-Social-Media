{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adolescent-charter",
   "metadata": {},
   "source": [
    "# Bag Of Words Model\n",
    "\n",
    "Uses one-hot encoding to count number of occurences of a word in a given document. Disadvantage is that most words are not repeated in every document leading to a sparse matrix and also does not take into account the structure of a sentence, i.e., the order of words or semantics.\n",
    "\n",
    "\"Not bad, working good\" and \"Not good, working bad\" would be treated as the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "superb-tournament",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, learning_curve\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "given-composition",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"processed_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cloudy-allergy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>subtask_b</th>\n",
       "      <th>subtask_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>86426</td>\n",
       "      <td>['ask', 'native', 'american', 'take']</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>90194</td>\n",
       "      <td>['go', 'home', '’', 'drunk', 'maga', 'trump', ...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>16820</td>\n",
       "      <td>['amazon', 'investigating', 'chinese', 'employ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>62688</td>\n",
       "      <td>['someone', 'shouldve', 'taken', 'piece', 'shi...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>43605</td>\n",
       "      <td>['obama', 'wanted', 'liberal', 'amp', 'illegal...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13235</th>\n",
       "      <td>13235</td>\n",
       "      <td>95338</td>\n",
       "      <td>['sometimes', 'get', 'strong', 'vibe', 'people...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13236</th>\n",
       "      <td>13236</td>\n",
       "      <td>67210</td>\n",
       "      <td>['benidorm', '✅', 'creamfields', '✅', 'maga', ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13237</th>\n",
       "      <td>13237</td>\n",
       "      <td>82921</td>\n",
       "      <td>['report', 'garbage', 'dont', 'give', 'crap']</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>OTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13238</th>\n",
       "      <td>13238</td>\n",
       "      <td>27429</td>\n",
       "      <td>['pussy']</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13239</th>\n",
       "      <td>13239</td>\n",
       "      <td>46552</td>\n",
       "      <td>['spanishrevenge', 'v', 'justice', 'human', 'r...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13240 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0     id                                              tweet  \\\n",
       "0               0  86426              ['ask', 'native', 'american', 'take']   \n",
       "1               1  90194  ['go', 'home', '’', 'drunk', 'maga', 'trump', ...   \n",
       "2               2  16820  ['amazon', 'investigating', 'chinese', 'employ...   \n",
       "3               3  62688  ['someone', 'shouldve', 'taken', 'piece', 'shi...   \n",
       "4               4  43605  ['obama', 'wanted', 'liberal', 'amp', 'illegal...   \n",
       "...           ...    ...                                                ...   \n",
       "13235       13235  95338  ['sometimes', 'get', 'strong', 'vibe', 'people...   \n",
       "13236       13236  67210  ['benidorm', '✅', 'creamfields', '✅', 'maga', ...   \n",
       "13237       13237  82921      ['report', 'garbage', 'dont', 'give', 'crap']   \n",
       "13238       13238  27429                                          ['pussy']   \n",
       "13239       13239  46552  ['spanishrevenge', 'v', 'justice', 'human', 'r...   \n",
       "\n",
       "      subtask_a subtask_b subtask_c  \n",
       "0           OFF       UNT       NaN  \n",
       "1           OFF       TIN       IND  \n",
       "2           NOT       NaN       NaN  \n",
       "3           OFF       UNT       NaN  \n",
       "4           NOT       NaN       NaN  \n",
       "...         ...       ...       ...  \n",
       "13235       OFF       TIN       IND  \n",
       "13236       NOT       NaN       NaN  \n",
       "13237       OFF       TIN       OTH  \n",
       "13238       OFF       UNT       NaN  \n",
       "13239       NOT       NaN       NaN  \n",
       "\n",
       "[13240 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "canadian-bones",
   "metadata": {},
   "source": [
    "### Removing redundant axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "reverse-stopping",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "final-lounge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>subtask_b</th>\n",
       "      <th>subtask_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86426</td>\n",
       "      <td>['ask', 'native', 'american', 'take']</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90194</td>\n",
       "      <td>['go', 'home', '’', 'drunk', 'maga', 'trump', ...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16820</td>\n",
       "      <td>['amazon', 'investigating', 'chinese', 'employ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62688</td>\n",
       "      <td>['someone', 'shouldve', 'taken', 'piece', 'shi...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43605</td>\n",
       "      <td>['obama', 'wanted', 'liberal', 'amp', 'illegal...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13235</th>\n",
       "      <td>95338</td>\n",
       "      <td>['sometimes', 'get', 'strong', 'vibe', 'people...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13236</th>\n",
       "      <td>67210</td>\n",
       "      <td>['benidorm', '✅', 'creamfields', '✅', 'maga', ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13237</th>\n",
       "      <td>82921</td>\n",
       "      <td>['report', 'garbage', 'dont', 'give', 'crap']</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>OTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13238</th>\n",
       "      <td>27429</td>\n",
       "      <td>['pussy']</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13239</th>\n",
       "      <td>46552</td>\n",
       "      <td>['spanishrevenge', 'v', 'justice', 'human', 'r...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13240 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              tweet subtask_a  \\\n",
       "0      86426              ['ask', 'native', 'american', 'take']       OFF   \n",
       "1      90194  ['go', 'home', '’', 'drunk', 'maga', 'trump', ...       OFF   \n",
       "2      16820  ['amazon', 'investigating', 'chinese', 'employ...       NOT   \n",
       "3      62688  ['someone', 'shouldve', 'taken', 'piece', 'shi...       OFF   \n",
       "4      43605  ['obama', 'wanted', 'liberal', 'amp', 'illegal...       NOT   \n",
       "...      ...                                                ...       ...   \n",
       "13235  95338  ['sometimes', 'get', 'strong', 'vibe', 'people...       OFF   \n",
       "13236  67210  ['benidorm', '✅', 'creamfields', '✅', 'maga', ...       NOT   \n",
       "13237  82921      ['report', 'garbage', 'dont', 'give', 'crap']       OFF   \n",
       "13238  27429                                          ['pussy']       OFF   \n",
       "13239  46552  ['spanishrevenge', 'v', 'justice', 'human', 'r...       NOT   \n",
       "\n",
       "      subtask_b subtask_c  \n",
       "0           UNT       NaN  \n",
       "1           TIN       IND  \n",
       "2           NaN       NaN  \n",
       "3           UNT       NaN  \n",
       "4           NaN       NaN  \n",
       "...         ...       ...  \n",
       "13235       TIN       IND  \n",
       "13236       NaN       NaN  \n",
       "13237       TIN       OTH  \n",
       "13238       UNT       NaN  \n",
       "13239       NaN       NaN  \n",
       "\n",
       "[13240 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powered-isaac",
   "metadata": {},
   "source": [
    "### Removing Unnecessary Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "designed-repair",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"subtask_b\", \"subtask_c\", \"id\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "exterior-snake",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['ask', 'native', 'american', 'take']</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['go', 'home', '’', 'drunk', 'maga', 'trump', ...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['amazon', 'investigating', 'chinese', 'employ...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['someone', 'shouldve', 'taken', 'piece', 'shi...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['obama', 'wanted', 'liberal', 'amp', 'illegal...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13235</th>\n",
       "      <td>['sometimes', 'get', 'strong', 'vibe', 'people...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13236</th>\n",
       "      <td>['benidorm', '✅', 'creamfields', '✅', 'maga', ...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13237</th>\n",
       "      <td>['report', 'garbage', 'dont', 'give', 'crap']</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13238</th>\n",
       "      <td>['pussy']</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13239</th>\n",
       "      <td>['spanishrevenge', 'v', 'justice', 'human', 'r...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13240 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet subtask_a\n",
       "0                  ['ask', 'native', 'american', 'take']       OFF\n",
       "1      ['go', 'home', '’', 'drunk', 'maga', 'trump', ...       OFF\n",
       "2      ['amazon', 'investigating', 'chinese', 'employ...       NOT\n",
       "3      ['someone', 'shouldve', 'taken', 'piece', 'shi...       OFF\n",
       "4      ['obama', 'wanted', 'liberal', 'amp', 'illegal...       NOT\n",
       "...                                                  ...       ...\n",
       "13235  ['sometimes', 'get', 'strong', 'vibe', 'people...       OFF\n",
       "13236  ['benidorm', '✅', 'creamfields', '✅', 'maga', ...       NOT\n",
       "13237      ['report', 'garbage', 'dont', 'give', 'crap']       OFF\n",
       "13238                                          ['pussy']       OFF\n",
       "13239  ['spanishrevenge', 'v', 'justice', 'human', 'r...       NOT\n",
       "\n",
       "[13240 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adverse-offset",
   "metadata": {},
   "source": [
    "### Renaming Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acute-frost",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"subtask_a\": \"Offensive\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "unknown-biology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>Offensive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['ask', 'native', 'american', 'take']</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['go', 'home', '’', 'drunk', 'maga', 'trump', ...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['amazon', 'investigating', 'chinese', 'employ...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['someone', 'shouldve', 'taken', 'piece', 'shi...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['obama', 'wanted', 'liberal', 'amp', 'illegal...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13235</th>\n",
       "      <td>['sometimes', 'get', 'strong', 'vibe', 'people...</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13236</th>\n",
       "      <td>['benidorm', '✅', 'creamfields', '✅', 'maga', ...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13237</th>\n",
       "      <td>['report', 'garbage', 'dont', 'give', 'crap']</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13238</th>\n",
       "      <td>['pussy']</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13239</th>\n",
       "      <td>['spanishrevenge', 'v', 'justice', 'human', 'r...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13240 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet Offensive\n",
       "0                  ['ask', 'native', 'american', 'take']       OFF\n",
       "1      ['go', 'home', '’', 'drunk', 'maga', 'trump', ...       OFF\n",
       "2      ['amazon', 'investigating', 'chinese', 'employ...       NOT\n",
       "3      ['someone', 'shouldve', 'taken', 'piece', 'shi...       OFF\n",
       "4      ['obama', 'wanted', 'liberal', 'amp', 'illegal...       NOT\n",
       "...                                                  ...       ...\n",
       "13235  ['sometimes', 'get', 'strong', 'vibe', 'people...       OFF\n",
       "13236  ['benidorm', '✅', 'creamfields', '✅', 'maga', ...       NOT\n",
       "13237      ['report', 'garbage', 'dont', 'give', 'crap']       OFF\n",
       "13238                                          ['pussy']       OFF\n",
       "13239  ['spanishrevenge', 'v', 'justice', 'human', 'r...       NOT\n",
       "\n",
       "[13240 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "golden-swing",
   "metadata": {},
   "source": [
    "### Replacing Class with Numeric Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "female-religion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def repl(off):\n",
    "    if off == 'OFF':\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "pregnant-girlfriend",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Offensive'] = df['Offensive'].apply(repl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "assured-surveillance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>Offensive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['ask', 'native', 'american', 'take']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['go', 'home', '’', 'drunk', 'maga', 'trump', ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['amazon', 'investigating', 'chinese', 'employ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['someone', 'shouldve', 'taken', 'piece', 'shi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['obama', 'wanted', 'liberal', 'amp', 'illegal...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13235</th>\n",
       "      <td>['sometimes', 'get', 'strong', 'vibe', 'people...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13236</th>\n",
       "      <td>['benidorm', '✅', 'creamfields', '✅', 'maga', ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13237</th>\n",
       "      <td>['report', 'garbage', 'dont', 'give', 'crap']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13238</th>\n",
       "      <td>['pussy']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13239</th>\n",
       "      <td>['spanishrevenge', 'v', 'justice', 'human', 'r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13240 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet  Offensive\n",
       "0                  ['ask', 'native', 'american', 'take']          1\n",
       "1      ['go', 'home', '’', 'drunk', 'maga', 'trump', ...          1\n",
       "2      ['amazon', 'investigating', 'chinese', 'employ...          0\n",
       "3      ['someone', 'shouldve', 'taken', 'piece', 'shi...          1\n",
       "4      ['obama', 'wanted', 'liberal', 'amp', 'illegal...          0\n",
       "...                                                  ...        ...\n",
       "13235  ['sometimes', 'get', 'strong', 'vibe', 'people...          1\n",
       "13236  ['benidorm', '✅', 'creamfields', '✅', 'maga', ...          0\n",
       "13237      ['report', 'garbage', 'dont', 'give', 'crap']          1\n",
       "13238                                          ['pussy']          1\n",
       "13239  ['spanishrevenge', 'v', 'justice', 'human', 'r...          0\n",
       "\n",
       "[13240 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "automotive-december",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    ['ask', 'native', 'american', 'take']\n",
       "1        ['go', 'home', '’', 'drunk', 'maga', 'trump', ...\n",
       "2        ['amazon', 'investigating', 'chinese', 'employ...\n",
       "3        ['someone', 'shouldve', 'taken', 'piece', 'shi...\n",
       "4        ['obama', 'wanted', 'liberal', 'amp', 'illegal...\n",
       "                               ...                        \n",
       "13235    ['sometimes', 'get', 'strong', 'vibe', 'people...\n",
       "13236    ['benidorm', '✅', 'creamfields', '✅', 'maga', ...\n",
       "13237        ['report', 'garbage', 'dont', 'give', 'crap']\n",
       "13238                                            ['pussy']\n",
       "13239    ['spanishrevenge', 'v', 'justice', 'human', 'r...\n",
       "Name: tweet, Length: 13240, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acceptable-learning",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "sweet-drink",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['tweet'], df['Offensive'], stratify=df['Offensive'], shuffle=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "surprised-profession",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4874     ['bible', 'say', 'thou', 'shalt', 'kill', 'cur...\n",
       "577      ['best', 'part', 'read', 'exchange', 'thread',...\n",
       "1398     ['judge', 'roy', 'moore', 'masterbate', 'story...\n",
       "10342                                ['buck', 'buttercup']\n",
       "3777     ['socialism', 'implemented', 'historically', '...\n",
       "                               ...                        \n",
       "5105     ['’', 'got', 'many', 'new', 'york', 'liberal',...\n",
       "6650                                   ['murda', 'fucker']\n",
       "4507     ['martin', 'obsessed', 'christ', 'homosexuality']\n",
       "8948     ['welcome', 'back', 'home', 'south', 'africa',...\n",
       "7661     ['nothing', 'isolating', 'others', 'quite', 'h...\n",
       "Name: tweet, Length: 9930, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "common-jaguar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4874     0\n",
       "577      0\n",
       "1398     1\n",
       "10342    0\n",
       "3777     1\n",
       "        ..\n",
       "5105     0\n",
       "6650     1\n",
       "4507     1\n",
       "8948     0\n",
       "7661     0\n",
       "Name: Offensive, Length: 9930, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proved-machine",
   "metadata": {},
   "source": [
    "## BoW Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "instant-tennessee",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(lowercase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "persistent-position",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = vect.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "arranged-frequency",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14573"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "accomplished-enemy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<9930x14573 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 99610 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vect = vect.transform(X_train)\n",
    "\n",
    "X_train_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "crucial-apparatus",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "published-brand",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.05,\n",
       " 0.1,\n",
       " 0.15000000000000002,\n",
       " 0.2,\n",
       " 0.25,\n",
       " 0.30000000000000004,\n",
       " 0.35000000000000003,\n",
       " 0.4,\n",
       " 0.45,\n",
       " 0.5,\n",
       " 0.55,\n",
       " 0.6000000000000001,\n",
       " 0.65,\n",
       " 0.7000000000000001,\n",
       " 0.75,\n",
       " 0.8,\n",
       " 0.8500000000000001,\n",
       " 0.9,\n",
       " 0.9500000000000001]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = list(np.arange(0, 1, 0.05))\n",
    "\n",
    "C = [float(i) for i in C]\n",
    "\n",
    "C = C[1:]\n",
    "\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "mineral-lodge",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "liable-exclusive",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.05: 0.739274924471299,\n",
       " 0.1: 0.7462235649546828,\n",
       " 0.15000000000000002: 0.7498489425981874,\n",
       " 0.2: 0.751963746223565,\n",
       " 0.25: 0.7537764350453172,\n",
       " 0.30000000000000004: 0.7574018126888218,\n",
       " 0.35000000000000003: 0.7570996978851964,\n",
       " 0.4: 0.7564954682779457,\n",
       " 0.45: 0.7586102719033233,\n",
       " 0.5: 0.7577039274924471,\n",
       " 0.55: 0.7604229607250755,\n",
       " 0.6000000000000001: 0.759214501510574,\n",
       " 0.65: 0.759214501510574,\n",
       " 0.7000000000000001: 0.7586102719033233,\n",
       " 0.75: 0.7586102719033233,\n",
       " 0.8: 0.7580060422960725,\n",
       " 0.8500000000000001: 0.7580060422960725,\n",
       " 0.9: 0.7577039274924471,\n",
       " 0.9500000000000001: 0.7570996978851964}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in C:\n",
    "    clf = LogisticRegression(C= i, max_iter=1000)\n",
    "    clf.fit(X_train_vect, y_train)\n",
    "    scores[i] = clf.score(vect.transform(X_test), y_test)\n",
    "    \n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "indoor-germany",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.55\n"
     ]
    }
   ],
   "source": [
    "best_C = max(scores, key=scores.get)\n",
    "\n",
    "print(best_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dental-beast",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(C= 0.3, max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "super-shoot",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.3, max_iter=1000)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "expanded-design",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7574018126888218"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(vect.transform(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "collected-premium",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "missing-cornwall",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = clf.coef_[0].argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "early-delicious",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coefs \n",
      "['best' 'thank' 'beautiful' 'brexit' 'justice' 'sit' 'nike' 'special' 'yr'\n",
      " 'clue']\n",
      "Largest Coefs \n",
      "['crap' 'fucked' 'disgusting' 'suck' 'idiot' 'as' 'fucking' 'stupid'\n",
      " 'fuck' 'shit']\n"
     ]
    }
   ],
   "source": [
    "print(\"Smallest Coefs \\n{}\".format(features[coefs[:10]]))\n",
    "print(\"Largest Coefs \\n{}\".format(features[coefs[-11:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "light-scholarship",
   "metadata": {},
   "source": [
    "## BoW with Bigrams and Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "residential-hartford",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_gram = CountVectorizer(lowercase=False, ngram_range=(1, 3), min_df=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "superb-silly",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_gram = vect_gram.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "literary-tennessee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3942"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vect_gram.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "comprehensive-klein",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ab',\n",
       " 'abiding',\n",
       " 'abiding citizen',\n",
       " 'ability',\n",
       " 'able',\n",
       " 'abortion',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absolutely right',\n",
       " 'abuse',\n",
       " 'abuse power',\n",
       " 'abused',\n",
       " 'abuser',\n",
       " 'accept',\n",
       " 'accepting',\n",
       " 'access',\n",
       " 'accident',\n",
       " 'accomplished',\n",
       " 'accomplishment',\n",
       " 'according',\n",
       " 'account',\n",
       " 'account list',\n",
       " 'accountable',\n",
       " 'accusation',\n",
       " 'accuse',\n",
       " 'accused',\n",
       " 'accuser',\n",
       " 'accusing',\n",
       " 'achieve',\n",
       " 'achievement',\n",
       " 'acknowledge',\n",
       " 'across',\n",
       " 'act',\n",
       " 'act like',\n",
       " 'acted',\n",
       " 'acting',\n",
       " 'acting like',\n",
       " 'action',\n",
       " 'active',\n",
       " 'actively',\n",
       " 'activist',\n",
       " 'activity',\n",
       " 'actor',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'ad',\n",
       " 'adam',\n",
       " 'add',\n",
       " 'added',\n",
       " 'address',\n",
       " 'administration',\n",
       " 'admit',\n",
       " 'admitted',\n",
       " 'adorable',\n",
       " 'adult',\n",
       " 'advance',\n",
       " 'advantage',\n",
       " 'advice',\n",
       " 'advocate',\n",
       " 'advocating',\n",
       " 'af',\n",
       " 'affair',\n",
       " 'affect',\n",
       " 'affected',\n",
       " 'afford',\n",
       " 'affordable',\n",
       " 'afraid',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'ag',\n",
       " 'age',\n",
       " 'agency',\n",
       " 'agenda',\n",
       " 'agent',\n",
       " 'ago',\n",
       " 'agree',\n",
       " 'agreed',\n",
       " 'ah',\n",
       " 'ahead',\n",
       " 'aim',\n",
       " 'aint',\n",
       " 'air',\n",
       " 'aka',\n",
       " 'al',\n",
       " 'alcohol',\n",
       " 'alert',\n",
       " 'alex',\n",
       " 'alex jones',\n",
       " 'alien',\n",
       " 'alive',\n",
       " 'allegation',\n",
       " 'alleged',\n",
       " 'allegedly',\n",
       " 'alleslev',\n",
       " 'allow',\n",
       " 'allowed',\n",
       " 'allowing',\n",
       " 'allows',\n",
       " 'ally',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'already',\n",
       " 'already know',\n",
       " 'alright',\n",
       " 'also',\n",
       " 'alt',\n",
       " 'alt right',\n",
       " 'alternative',\n",
       " 'altright',\n",
       " 'always',\n",
       " 'amazing',\n",
       " 'amazing person',\n",
       " 'amendment',\n",
       " 'amental',\n",
       " 'america',\n",
       " 'america first',\n",
       " 'america first maga',\n",
       " 'america great',\n",
       " 'america maga',\n",
       " 'america url',\n",
       " 'american',\n",
       " 'american people',\n",
       " 'among',\n",
       " 'amount',\n",
       " 'amp',\n",
       " 'amp conservative',\n",
       " 'amp gun',\n",
       " 'amp liberal',\n",
       " 'amp maga',\n",
       " 'amy',\n",
       " 'anarchist',\n",
       " 'andrew',\n",
       " 'angel',\n",
       " 'anger',\n",
       " 'angry',\n",
       " 'animal',\n",
       " 'anime',\n",
       " 'anita',\n",
       " 'anita hill',\n",
       " 'announced',\n",
       " 'announcement',\n",
       " 'anonymous',\n",
       " 'another',\n",
       " 'another liberal',\n",
       " 'another one',\n",
       " 'answer',\n",
       " 'answer question',\n",
       " 'answer url',\n",
       " 'answered',\n",
       " 'anthony',\n",
       " 'anti',\n",
       " 'anti american',\n",
       " 'anti fa',\n",
       " 'antiamerican',\n",
       " 'antifa',\n",
       " 'antifa amp',\n",
       " 'antifa anarchist',\n",
       " 'antifa black',\n",
       " 'antifa blm',\n",
       " 'antifa democrat',\n",
       " 'antifa go',\n",
       " 'antifa group',\n",
       " 'antifa kkk',\n",
       " 'antifa kkk hood',\n",
       " 'antifa member',\n",
       " 'antifa one',\n",
       " 'antifa protest',\n",
       " 'antifa protestors',\n",
       " 'antifa rally',\n",
       " 'antifa target',\n",
       " 'antifa target list',\n",
       " 'antifa terrorist',\n",
       " 'antifa terrorist organization',\n",
       " 'antifa thug',\n",
       " 'antifa type',\n",
       " 'antifa url',\n",
       " 'antifa violence',\n",
       " 'antifa would',\n",
       " 'antifascist',\n",
       " 'antisemitism',\n",
       " 'anxiety',\n",
       " 'anybody',\n",
       " 'anymore',\n",
       " 'anyone',\n",
       " 'anyone else',\n",
       " 'anything',\n",
       " 'anything say',\n",
       " 'anyway',\n",
       " 'anyways',\n",
       " 'anywhere',\n",
       " 'apart',\n",
       " 'apartment',\n",
       " 'apologize',\n",
       " 'apology',\n",
       " 'app',\n",
       " 'apparently',\n",
       " 'appear',\n",
       " 'appears',\n",
       " 'apple',\n",
       " 'apply',\n",
       " 'appointed',\n",
       " 'appointment',\n",
       " 'appreciate',\n",
       " 'approach',\n",
       " 'approve',\n",
       " 'approved',\n",
       " 'ar',\n",
       " 'area',\n",
       " 'arent',\n",
       " 'argue',\n",
       " 'arguing',\n",
       " 'argument',\n",
       " 'argument gun',\n",
       " 'argument gun control',\n",
       " 'arm',\n",
       " 'armed',\n",
       " 'army',\n",
       " 'around',\n",
       " 'arrest',\n",
       " 'arrested',\n",
       " 'art',\n",
       " 'article',\n",
       " 'article sec',\n",
       " 'artist',\n",
       " 'as',\n",
       " 'asap',\n",
       " 'ashamed',\n",
       " 'asian',\n",
       " 'ask',\n",
       " 'asked',\n",
       " 'asking',\n",
       " 'aspect',\n",
       " 'aspect life',\n",
       " 'ass',\n",
       " 'assassination',\n",
       " 'assault',\n",
       " 'assault rifle',\n",
       " 'assault weapon',\n",
       " 'assaulted',\n",
       " 'asshole',\n",
       " 'associated',\n",
       " 'association',\n",
       " 'assume',\n",
       " 'assuming',\n",
       " 'ate',\n",
       " 'attack',\n",
       " 'attacked',\n",
       " 'attacking',\n",
       " 'attempt',\n",
       " 'attempted',\n",
       " 'attempting',\n",
       " 'attention',\n",
       " 'attention publicizing',\n",
       " 'attitude',\n",
       " 'attorney',\n",
       " 'audience',\n",
       " 'august',\n",
       " 'austerity',\n",
       " 'australia',\n",
       " 'australian',\n",
       " 'authoritarian',\n",
       " 'authority',\n",
       " 'available',\n",
       " 'average',\n",
       " 'awake',\n",
       " 'awakening',\n",
       " 'award',\n",
       " 'aware',\n",
       " 'away',\n",
       " 'away democrat',\n",
       " 'away liberal',\n",
       " 'away maga',\n",
       " 'away right',\n",
       " 'away url',\n",
       " 'away walk',\n",
       " 'away walk away',\n",
       " 'awesome',\n",
       " 'awful',\n",
       " 'awww',\n",
       " 'babe',\n",
       " 'baby',\n",
       " 'back',\n",
       " 'back maga',\n",
       " 'backed',\n",
       " 'background',\n",
       " 'background check',\n",
       " 'backing',\n",
       " 'bad',\n",
       " 'bad bitch',\n",
       " 'badly',\n",
       " 'bag',\n",
       " 'ball',\n",
       " 'ballot',\n",
       " 'baltimore',\n",
       " 'ban',\n",
       " 'band',\n",
       " 'bank',\n",
       " 'bankrupt',\n",
       " 'banned',\n",
       " 'banning',\n",
       " 'bar',\n",
       " 'barry',\n",
       " 'base',\n",
       " 'baseball',\n",
       " 'based',\n",
       " 'basement',\n",
       " 'bash',\n",
       " 'bashing',\n",
       " 'basic',\n",
       " 'basically',\n",
       " 'basically saying',\n",
       " 'basis',\n",
       " 'bastard',\n",
       " 'battle',\n",
       " 'bb',\n",
       " 'bbc',\n",
       " 'bc',\n",
       " 'bear',\n",
       " 'beast',\n",
       " 'beat',\n",
       " 'beating',\n",
       " 'beating stranger',\n",
       " 'beating stranger know',\n",
       " 'beautiful',\n",
       " 'beauty',\n",
       " 'became',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'becoming',\n",
       " 'bed',\n",
       " 'begin',\n",
       " 'beginning',\n",
       " 'behalf',\n",
       " 'behavior',\n",
       " 'behaviour',\n",
       " 'behind',\n",
       " 'being',\n",
       " 'belief',\n",
       " 'believe',\n",
       " 'believe gun',\n",
       " 'believe gun control',\n",
       " 'believe woman',\n",
       " 'believed',\n",
       " 'believing',\n",
       " 'bell',\n",
       " 'belong',\n",
       " 'belongs',\n",
       " 'ben',\n",
       " 'benefit',\n",
       " 'berkeley',\n",
       " 'bernie',\n",
       " 'bernier',\n",
       " 'besides',\n",
       " 'best',\n",
       " 'bet',\n",
       " 'beto',\n",
       " 'betrayal',\n",
       " 'better',\n",
       " 'better gun',\n",
       " 'better gun control',\n",
       " 'better soon',\n",
       " 'beyond',\n",
       " 'bias',\n",
       " 'biased',\n",
       " 'bible',\n",
       " 'biden',\n",
       " 'big',\n",
       " 'bigger',\n",
       " 'biggest',\n",
       " 'bigot',\n",
       " 'bill',\n",
       " 'bill clinton',\n",
       " 'billion',\n",
       " 'billionaire',\n",
       " 'billy',\n",
       " 'bio',\n",
       " 'bird',\n",
       " 'birth',\n",
       " 'birthday',\n",
       " 'bit',\n",
       " 'bitch',\n",
       " 'bitch url',\n",
       " 'bite',\n",
       " 'bitter',\n",
       " 'black',\n",
       " 'black conservative',\n",
       " 'black life',\n",
       " 'black life matter',\n",
       " 'black men',\n",
       " 'black panther',\n",
       " 'black people',\n",
       " 'black woman',\n",
       " 'blame',\n",
       " 'blame gun',\n",
       " 'blame gun control',\n",
       " 'blame trump',\n",
       " 'blaming',\n",
       " 'blanket',\n",
       " 'blasey',\n",
       " 'blasey ford',\n",
       " 'blatant',\n",
       " 'blatantly',\n",
       " 'bless',\n",
       " 'blessed',\n",
       " 'blessing',\n",
       " 'blind',\n",
       " 'blm',\n",
       " 'blm antifa',\n",
       " 'block',\n",
       " 'blocked',\n",
       " 'blocking',\n",
       " 'blog',\n",
       " 'blood',\n",
       " 'bloody',\n",
       " 'blow',\n",
       " 'blue',\n",
       " 'blue wave',\n",
       " 'bn',\n",
       " 'bo',\n",
       " 'board',\n",
       " 'bob',\n",
       " 'body',\n",
       " 'boi',\n",
       " 'bomb',\n",
       " 'bone',\n",
       " 'bono',\n",
       " 'boob',\n",
       " 'book',\n",
       " 'booker',\n",
       " 'booming',\n",
       " 'booming economy',\n",
       " 'booming economy url',\n",
       " 'booty',\n",
       " 'border',\n",
       " 'boring',\n",
       " 'born',\n",
       " 'bos',\n",
       " 'bot',\n",
       " 'bother',\n",
       " 'bottom',\n",
       " 'bought',\n",
       " 'bout',\n",
       " 'box',\n",
       " 'boy',\n",
       " 'boycott',\n",
       " 'boycott nfl',\n",
       " 'boycotting',\n",
       " 'brain',\n",
       " 'brainwashed',\n",
       " 'brand',\n",
       " 'brat',\n",
       " 'brave',\n",
       " 'bravery',\n",
       " 'break',\n",
       " 'breaking',\n",
       " 'breath',\n",
       " 'breitbart',\n",
       " 'brennan',\n",
       " 'brett',\n",
       " 'brett kavanaugh',\n",
       " 'brexit',\n",
       " 'brexit remain',\n",
       " 'brexiteers',\n",
       " 'brian',\n",
       " 'brick',\n",
       " 'brilliant',\n",
       " 'bring',\n",
       " 'bring back',\n",
       " 'bring gun',\n",
       " 'bring gun control',\n",
       " 'bringing',\n",
       " 'brings',\n",
       " 'britain',\n",
       " 'british',\n",
       " 'bro',\n",
       " 'broke',\n",
       " 'broken',\n",
       " 'brother',\n",
       " 'brought',\n",
       " 'brown',\n",
       " 'brown shirt',\n",
       " 'btw',\n",
       " 'buck',\n",
       " 'buddy',\n",
       " 'budget',\n",
       " 'build',\n",
       " 'build wall',\n",
       " 'building',\n",
       " 'built',\n",
       " 'bull',\n",
       " 'bullet',\n",
       " 'bullshit',\n",
       " 'bully',\n",
       " 'bullying',\n",
       " 'bunch',\n",
       " 'burn',\n",
       " 'burning',\n",
       " 'business',\n",
       " 'busy',\n",
       " 'butt',\n",
       " 'buy',\n",
       " 'buying',\n",
       " 'bye',\n",
       " 'ca',\n",
       " 'cage',\n",
       " 'cake',\n",
       " 'cali',\n",
       " 'california',\n",
       " 'call',\n",
       " 'call gun',\n",
       " 'call gun control',\n",
       " 'called',\n",
       " 'calling',\n",
       " 'calm',\n",
       " 'came',\n",
       " 'camera',\n",
       " 'camp',\n",
       " 'campaign',\n",
       " 'campus',\n",
       " 'canada',\n",
       " 'canadian',\n",
       " 'cancel',\n",
       " 'cancer',\n",
       " 'candidate',\n",
       " 'candy',\n",
       " 'cannot',\n",
       " 'cant',\n",
       " 'cant believe',\n",
       " 'cant even',\n",
       " 'cant help',\n",
       " 'cant stand',\n",
       " 'cap',\n",
       " 'capacity',\n",
       " 'capital',\n",
       " 'car',\n",
       " 'card',\n",
       " 'care',\n",
       " 'care gun',\n",
       " 'care gun control',\n",
       " 'care le',\n",
       " 'cared',\n",
       " 'career',\n",
       " 'careful',\n",
       " 'caring',\n",
       " 'carrey',\n",
       " 'carry',\n",
       " 'carter',\n",
       " 'cartoon',\n",
       " 'case',\n",
       " 'cash',\n",
       " 'cast',\n",
       " 'cat',\n",
       " 'catch',\n",
       " 'catholic',\n",
       " 'catholic church',\n",
       " 'caught',\n",
       " 'cause',\n",
       " 'caused',\n",
       " 'causing',\n",
       " 'cbc',\n",
       " 'cbs',\n",
       " 'ccot',\n",
       " 'cdnpoli',\n",
       " 'celebrate',\n",
       " 'celebrity',\n",
       " 'cell',\n",
       " 'censored',\n",
       " 'censoring',\n",
       " 'censoring conservative',\n",
       " 'censorship',\n",
       " 'center',\n",
       " 'centrist',\n",
       " 'century',\n",
       " 'ceo',\n",
       " 'certain',\n",
       " 'certainly',\n",
       " 'chain',\n",
       " 'chair',\n",
       " 'challenge',\n",
       " 'champion',\n",
       " 'chance',\n",
       " 'change',\n",
       " 'change mind',\n",
       " 'changed',\n",
       " 'changing',\n",
       " 'channel',\n",
       " 'chaos',\n",
       " 'character',\n",
       " 'charge',\n",
       " 'charged',\n",
       " 'charlottesville',\n",
       " 'cheap',\n",
       " 'cheat',\n",
       " 'cheating',\n",
       " 'check',\n",
       " 'check list',\n",
       " 'checked',\n",
       " 'cheer',\n",
       " 'chequer',\n",
       " 'chest',\n",
       " 'chicago',\n",
       " 'chicken',\n",
       " 'chief',\n",
       " 'child',\n",
       " 'china',\n",
       " 'chinese',\n",
       " 'chip',\n",
       " 'choice',\n",
       " 'choose',\n",
       " 'chose',\n",
       " 'chris',\n",
       " 'christ',\n",
       " 'christian',\n",
       " 'christian conservative',\n",
       " 'christine',\n",
       " 'christine blasey',\n",
       " 'christine blasey ford',\n",
       " 'christine ford',\n",
       " 'chuck',\n",
       " 'church',\n",
       " 'cia',\n",
       " 'circle',\n",
       " 'circus',\n",
       " 'citizen',\n",
       " 'city',\n",
       " 'civil',\n",
       " 'civil right',\n",
       " 'civil war',\n",
       " 'civilian',\n",
       " 'claim',\n",
       " 'claiming',\n",
       " 'clarence',\n",
       " 'clarence thomas',\n",
       " 'clarify',\n",
       " 'class',\n",
       " 'classical',\n",
       " 'clean',\n",
       " 'clear',\n",
       " 'clearly',\n",
       " 'client',\n",
       " 'climate',\n",
       " 'climate change',\n",
       " 'clinton',\n",
       " 'close',\n",
       " 'closer',\n",
       " 'closet',\n",
       " 'clown',\n",
       " 'club',\n",
       " 'clue',\n",
       " 'clueless',\n",
       " 'cnn',\n",
       " 'co',\n",
       " 'coach',\n",
       " 'coalition',\n",
       " 'cock',\n",
       " 'code',\n",
       " 'cold',\n",
       " 'colin',\n",
       " 'collective',\n",
       " 'college',\n",
       " 'collins',\n",
       " 'collusion',\n",
       " 'color',\n",
       " 'combat',\n",
       " 'come',\n",
       " 'come back',\n",
       " 'come forward',\n",
       " 'comedian',\n",
       " 'comedy',\n",
       " 'comfortable',\n",
       " 'coming',\n",
       " 'coming back',\n",
       " 'coming soon',\n",
       " 'comment',\n",
       " 'commercial',\n",
       " 'commie',\n",
       " 'commit',\n",
       " 'committed',\n",
       " 'committee',\n",
       " 'common',\n",
       " 'common sense',\n",
       " 'common sense gun',\n",
       " 'communist',\n",
       " 'community',\n",
       " 'company',\n",
       " 'compare',\n",
       " 'compared',\n",
       " 'comparing',\n",
       " 'comparison',\n",
       " 'competition',\n",
       " 'complain',\n",
       " 'complaining',\n",
       " 'complete',\n",
       " 'completely',\n",
       " 'complicit',\n",
       " 'computer',\n",
       " 'comrade',\n",
       " 'con',\n",
       " 'concept',\n",
       " 'concern',\n",
       " 'concerned',\n",
       " 'concert',\n",
       " 'conclusion',\n",
       " 'condemn',\n",
       " 'condition',\n",
       " 'conference',\n",
       " 'confidence',\n",
       " 'confirm',\n",
       " 'confirm judge',\n",
       " 'confirm judge kavanaugh',\n",
       " 'confirm kavanaugh',\n",
       " 'confirm kavanaugh maga',\n",
       " 'confirmation',\n",
       " 'confirmation hearing',\n",
       " 'confirmed',\n",
       " 'confused',\n",
       " 'congratulation',\n",
       " 'congress',\n",
       " 'congressional',\n",
       " 'connected',\n",
       " 'connecticut',\n",
       " 'connection',\n",
       " 'conscience',\n",
       " 'consequence',\n",
       " 'conservative',\n",
       " 'conservative always',\n",
       " 'conservative believe',\n",
       " 'conservative christian',\n",
       " 'conservative conservative',\n",
       " 'conservative conservative url',\n",
       " 'conservative dont',\n",
       " 'conservative know',\n",
       " 'conservative left',\n",
       " 'conservative liberal',\n",
       " 'conservative like',\n",
       " 'conservative love',\n",
       " 'conservative maga',\n",
       " 'conservative must',\n",
       " 'conservative need',\n",
       " 'conservative never',\n",
       " 'conservative party',\n",
       " 'conservative patriot',\n",
       " 'conservative patriot url',\n",
       " 'conservative republican',\n",
       " 'conservative think',\n",
       " 'conservative url',\n",
       " 'conservative vote',\n",
       " 'conservative want',\n",
       " 'conservative would',\n",
       " 'consider',\n",
       " 'considered',\n",
       " 'considering',\n",
       " 'conspiracy',\n",
       " 'constant',\n",
       " 'constantly',\n",
       " 'constituent',\n",
       " 'constitution',\n",
       " 'constitution day',\n",
       " 'constitutional',\n",
       " 'contact',\n",
       " 'contempt',\n",
       " 'content',\n",
       " 'continue',\n",
       " 'control',\n",
       " 'control amp',\n",
       " 'control debate',\n",
       " 'control doesnt',\n",
       " 'control group',\n",
       " 'control gun',\n",
       " 'control law',\n",
       " 'control law working',\n",
       " 'control legislation',\n",
       " 'control measure',\n",
       " 'control need',\n",
       " 'control nut',\n",
       " 'control people',\n",
       " 'control policy',\n",
       " 'control research',\n",
       " 'control research unethical',\n",
       " 'control right',\n",
       " 'control seems',\n",
       " 'control url',\n",
       " 'control work',\n",
       " 'control would',\n",
       " 'controlled',\n",
       " 'convenient',\n",
       " 'conversation',\n",
       " 'convicted',\n",
       " 'convince',\n",
       " 'convinced',\n",
       " 'cool',\n",
       " 'cooper',\n",
       " 'cop',\n",
       " 'copy',\n",
       " 'corbyn',\n",
       " 'core',\n",
       " 'corner',\n",
       " 'corporate',\n",
       " 'corporation',\n",
       " 'correct',\n",
       " 'corrupt',\n",
       " 'corruption',\n",
       " 'cory',\n",
       " 'cost',\n",
       " 'couch',\n",
       " 'could',\n",
       " 'could get',\n",
       " 'couldnt',\n",
       " 'council',\n",
       " 'count',\n",
       " 'counter',\n",
       " 'country',\n",
       " 'county',\n",
       " 'coup',\n",
       " 'couple',\n",
       " 'courage',\n",
       " 'course',\n",
       " 'court',\n",
       " 'cover',\n",
       " 'coverage',\n",
       " 'covering',\n",
       " 'coward',\n",
       " 'cpc',\n",
       " 'crap',\n",
       " 'crash',\n",
       " 'crazy',\n",
       " 'crazy liberal',\n",
       " 'create',\n",
       " 'created',\n",
       " 'creating',\n",
       " 'credibility',\n",
       " 'credible',\n",
       " 'credit',\n",
       " 'creepy',\n",
       " 'crew',\n",
       " 'crime',\n",
       " 'criminal',\n",
       " 'crisis',\n",
       " 'critical',\n",
       " 'criticism',\n",
       " 'crony',\n",
       " 'crook',\n",
       " 'crooked',\n",
       " 'cross',\n",
       " 'crossed',\n",
       " 'crossing',\n",
       " 'crowd',\n",
       " 'crush',\n",
       " 'cruz',\n",
       " 'cry',\n",
       " 'crybaby',\n",
       " 'cult',\n",
       " 'culture',\n",
       " 'cum',\n",
       " 'cunt',\n",
       " 'curious',\n",
       " 'current',\n",
       " 'currently',\n",
       " 'customer',\n",
       " 'cut',\n",
       " 'cute',\n",
       " 'cutie',\n",
       " 'cuz',\n",
       " 'da',\n",
       " 'dad',\n",
       " 'daddy',\n",
       " 'daily',\n",
       " 'dairy',\n",
       " 'dallas',\n",
       " 'dam',\n",
       " 'damage',\n",
       " 'damn',\n",
       " 'dana',\n",
       " 'dang',\n",
       " 'danger',\n",
       " 'dangerous',\n",
       " 'daniel',\n",
       " 'dare',\n",
       " 'dark',\n",
       " 'data',\n",
       " 'date',\n",
       " 'dating',\n",
       " 'daughter',\n",
       " 'david',\n",
       " 'day',\n",
       " 'day maga',\n",
       " 'day url',\n",
       " 'dc',\n",
       " 'de',\n",
       " 'dead',\n",
       " 'deal',\n",
       " 'dealing',\n",
       " 'dear',\n",
       " 'death',\n",
       " 'death threat',\n",
       " 'debate',\n",
       " 'debt',\n",
       " 'decade',\n",
       " 'decency',\n",
       " 'decent',\n",
       " 'decide',\n",
       " 'decided',\n",
       " 'decision',\n",
       " 'declassify',\n",
       " 'deep',\n",
       " 'deep state',\n",
       " 'def',\n",
       " 'defeat',\n",
       " 'defeated',\n",
       " 'defend',\n",
       " 'defending',\n",
       " 'defense',\n",
       " 'defensive',\n",
       " 'deficit',\n",
       " 'defined',\n",
       " 'definitely',\n",
       " 'definition',\n",
       " 'degree',\n",
       " 'delay',\n",
       " 'delete',\n",
       " 'delusional',\n",
       " 'dem',\n",
       " 'demand',\n",
       " 'demanding',\n",
       " 'demented',\n",
       " 'democ',\n",
       " 'democ rat',\n",
       " 'democracy',\n",
       " 'democrat',\n",
       " 'democrat liberal',\n",
       " 'democrat party',\n",
       " 'democrat url',\n",
       " 'democrat want',\n",
       " 'democratic',\n",
       " 'democratic party',\n",
       " 'demographic',\n",
       " 'demon',\n",
       " 'dems',\n",
       " 'dems want',\n",
       " 'denial',\n",
       " 'denounce',\n",
       " 'deny',\n",
       " 'denying',\n",
       " 'department',\n",
       " 'depend',\n",
       " 'depends',\n",
       " 'deplorable',\n",
       " 'deplorables',\n",
       " 'depression',\n",
       " 'derail',\n",
       " 'deranged',\n",
       " 'describe',\n",
       " 'description',\n",
       " 'deserve',\n",
       " 'deserved',\n",
       " 'deserves',\n",
       " 'designed',\n",
       " 'desperate',\n",
       " 'desperately',\n",
       " 'despicable',\n",
       " 'despite',\n",
       " 'destroy',\n",
       " 'destroyed',\n",
       " 'destroying',\n",
       " 'destruction',\n",
       " 'detail',\n",
       " 'determined',\n",
       " 'devil',\n",
       " 'diane',\n",
       " 'dianne',\n",
       " 'dick',\n",
       " 'dictator',\n",
       " 'dictionary',\n",
       " 'didnt',\n",
       " 'didnt know',\n",
       " 'die',\n",
       " 'died',\n",
       " 'difference',\n",
       " 'different',\n",
       " 'difficult',\n",
       " 'dig',\n",
       " 'dinner',\n",
       " 'direction',\n",
       " 'directly',\n",
       " 'dirt',\n",
       " 'dirty',\n",
       " 'dirty trick',\n",
       " 'disagree',\n",
       " 'disappear',\n",
       " 'disarm',\n",
       " 'disaster',\n",
       " 'discovered',\n",
       " 'discredit',\n",
       " 'discus',\n",
       " 'discussing',\n",
       " 'discussion',\n",
       " 'disease',\n",
       " 'disgrace',\n",
       " 'disgraceful',\n",
       " ...]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_gram.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "conditional-collective",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<9930x3942 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 91884 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vect = vect_gram.transform(X_train)\n",
    "\n",
    "X_train_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "freelance-antigua",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_gram = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cutting-touch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.05: 0.7362537764350453,\n",
       " 0.1: 0.7477341389728097,\n",
       " 0.15000000000000002: 0.7537764350453172,\n",
       " 0.2: 0.7522658610271903,\n",
       " 0.25: 0.7540785498489426,\n",
       " 0.30000000000000004: 0.7513595166163142,\n",
       " 0.35000000000000003: 0.7516616314199396,\n",
       " 0.4: 0.7516616314199396,\n",
       " 0.45: 0.7522658610271903,\n",
       " 0.5: 0.7513595166163142,\n",
       " 0.55: 0.7522658610271903,\n",
       " 0.6000000000000001: 0.751963746223565,\n",
       " 0.65: 0.751963746223565,\n",
       " 0.7000000000000001: 0.7522658610271903,\n",
       " 0.75: 0.7525679758308157,\n",
       " 0.8: 0.7525679758308157,\n",
       " 0.8500000000000001: 0.7525679758308157,\n",
       " 0.9: 0.7534743202416918,\n",
       " 0.9500000000000001: 0.751963746223565}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in C:\n",
    "    clf = LogisticRegression(C= i, max_iter=1000)\n",
    "    clf.fit(X_train_vect, y_train)\n",
    "    scores_gram[i] = clf.score(vect_gram.transform(X_test), y_test)\n",
    "    \n",
    "scores_gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "attended-auditor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.55\n"
     ]
    }
   ],
   "source": [
    "best_C_gram = max(scores_gram, key=scores.get)\n",
    "\n",
    "print(best_C_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "desirable-cyprus",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(C= 0.3, max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "noticed-munich",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.3, max_iter=1000)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "limited-method",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7513595166163142"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(vect_gram.transform(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "automatic-captain",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array(vect_gram.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "charged-measurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = clf.coef_[0].argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "canadian-steal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coefs \n",
      "['best' 'thank' 'brexit' 'beautiful' 'justice' 'nike' 'woman make'\n",
      " 'special' 'sit' 'modern']\n",
      "Largest Coefs \n",
      "['crap' 'fucked' 'disgusting' 'suck' 'idiot' 'as' 'fucking' 'stupid'\n",
      " 'bitch' 'fuck']\n"
     ]
    }
   ],
   "source": [
    "print(\"Smallest Coefs \\n{}\".format(features[coefs[:10]]))\n",
    "print(\"Largest Coefs \\n{}\".format(features[coefs[-11:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desperate-invalid",
   "metadata": {},
   "source": [
    "## SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "reflected-karaoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "referenced-ethernet",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'kernel': ['rbf', 'poly', 'sigmoid'], 'C': [0.05, 0.01, 0.1, 1, 5], 'gamma': [0.01, 0.1, 1, 5, 10,], 'degree': [1, 2, 3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "military-czech",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "distributed-colonial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "daily-colorado",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7540785498489426"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(vect_gram.transform(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executive-simpson",
   "metadata": {},
   "source": [
    "On Running GridSearch, best params found were C=0.05, kernel=poly and gamma=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "certified-meaning",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(C=0.05, kernel='poly', gamma=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naval-baptist",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
